{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OTG (Optimal Transport Grouping)\n",
    "tanaken ( Kentaro TANAKA, 2023.12- )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparation for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Required libraries ####\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install umap-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import ####\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "from matplotlib import cm as cm\n",
    "is_umap_loaded = True\n",
    "try:\n",
    "    import umap\n",
    "    # from numba import jit\n",
    "except ImportError as e:\n",
    "    is_umap_loaded = False\n",
    "    print(f\"{e} is not installed.\")\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "if os.name == 'nt':\n",
    "    import ctypes\n",
    "    ENABLE_PROCESSED_OUTPUT = 0x0001\n",
    "    ENABLE_WRAP_AT_EOL_OUTPUT = 0x0002\n",
    "    ENABLE_VIRTUAL_TERMINAL_PROCESSING = 0x0004\n",
    "    MODE = ENABLE_PROCESSED_OUTPUT + ENABLE_WRAP_AT_EOL_OUTPUT + ENABLE_VIRTUAL_TERMINAL_PROCESSING\n",
    "    kernel32 = ctypes.windll.kernel32\n",
    "    handle = kernel32.GetStdHandle(-11)\n",
    "    kernel32.SetConsoleMode(handle, MODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Functions ####\n",
    "\n",
    "## Functions for manipulating tensors\n",
    "def get_N(N_size):\n",
    "    if len(N_size) < 1:\n",
    "        raise ValueError(\"Error: N_size is invalid.\")\n",
    "    N_rank = len(N_size)\n",
    "    N_accum = np.ones(N_rank, dtype=int) # n2*n3*...*nN, n3*n4*...*nN, ... , nN, 1\n",
    "    for i in range(N_rank):\n",
    "        if i==0:\n",
    "            N_accum[N_rank-i-1] = 1\n",
    "        else:\n",
    "            N_accum[N_rank-i-1] = N_accum[N_rank-i]*N_size[N_rank-i]\n",
    "    N_size_prod = N_size[0]*N_accum[0]\n",
    "    return (N_rank, N_accum, N_size_prod)\n",
    "\n",
    "def get_tensor_flattened_index_from_multi_index(multi_index, N_rank, N_accum):\n",
    "    flattened_index = 0\n",
    "    for i in range(N_rank):\n",
    "            flattened_index = flattened_index + N_accum[i]*multi_index[i]\n",
    "    flattened_index = int(flattened_index)\n",
    "    return flattened_index\n",
    "\n",
    "def get_tensor_multi_index_from_flattened_index(flattened_index, N_rank, N_accum):\n",
    "    multi_index = []\n",
    "    remainder = flattened_index\n",
    "    for i in range(N_rank):\n",
    "        quotient, remainder = divmod(remainder, N_accum[i])\n",
    "        multi_index.append(quotient)\n",
    "    multi_index = tuple(multi_index)\n",
    "    return multi_index\n",
    "\n",
    "def get_tensor_value_from_multi_index(target_tensor, multi_index, N_rank, N_accum):\n",
    "    flattened_index = get_tensor_flattened_index_from_multi_index(multi_index, N_rank, N_accum)\n",
    "    return target_tensor[flattened_index]\n",
    "\n",
    "def get_tensor_flattened_index_list_from_value(target_tensor, value, tensor_tolerance=None):\n",
    "    if (tensor_tolerance is None) or (tensor_tolerance==0):\n",
    "        return [i for i, element in enumerate(target_tensor) if element==value]\n",
    "    else:\n",
    "        return [i for i, element in enumerate(target_tensor) if abs(element-value)<=tensor_tolerance]\n",
    "\n",
    "def get_tensor_multi_index_list_from_value(target_tensor, value, N_rank, N_accum, tensor_tolerance=None):\n",
    "    multi_index_list = []\n",
    "    flattened_index_list = get_tensor_flattened_index_list_from_value(target_tensor, value, tensor_tolerance)\n",
    "    for flattened_index in flattened_index_list:\n",
    "        multi_index_list.append(get_tensor_multi_index_from_flattened_index(flattened_index, N_rank, N_accum))\n",
    "    return multi_index_list\n",
    "\n",
    "## Function to generate marginal mass vectors\n",
    "def calc_marginal_mass_vectors(N_rank, N_size):\n",
    "    marginal_mass_vectors = []\n",
    "    for i in range(N_rank):\n",
    "        marginal_mass_vectors.append(np.ones(N_size[i])/N_size[i])\n",
    "    return marginal_mass_vectors\n",
    "\n",
    "## Function to generate grouping randomly (rand=True) or in the same order as the data_order_list (rand=False)\n",
    "def gen_grouping_indexes_list(N_size, rand=True, data_order_list=None):\n",
    "    if data_order_list is None:\n",
    "        data_order_list = list(range(sum(N_size)))\n",
    "    if rand:\n",
    "        data_order_list = random.sample(data_order_list, len(data_order_list))\n",
    "    grouping_indexes_list = [] # Double listing for grouping\n",
    "    range_from = 0\n",
    "    range_to = 0\n",
    "    for size in N_size:\n",
    "        range_to = range_from + size\n",
    "        grouping_indexes_list.append(data_order_list[range_from:range_to])\n",
    "        range_from = range_to\n",
    "    return grouping_indexes_list\n",
    "\n",
    "## Functions for the calculation of optimal transport\n",
    "# @jit\n",
    "def calc_multi_ot(marginal_mass_vectors, cost_tensor, normalized_cost_tensor,\n",
    "                  N_size, N_rank, N_accum, N_size_prod,\n",
    "                  numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200): ## ot_stopping_rule: Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ## Optrimal transport\n",
    "    K_tensor = np.exp(- normalized_cost_tensor / ot_speed) # Gibbs kernel\n",
    "    u_vec_list = []\n",
    "    for i in range(N_rank):\n",
    "        u_vec_list.append(np.ones(N_size[i]))\n",
    "    for loop in range(ot_loop_max):\n",
    "        u_diff = 0 # Variable to measure whether to exit the loop\n",
    "        for i in range(N_rank):\n",
    "            for j in range(N_size[i]):\n",
    "                temp_u_value = 0\n",
    "                temp_K_value = 1\n",
    "                temp_u_prod_value = 1\n",
    "                N_sizeub_s = list(copy.copy(N_size))\n",
    "                N_sizeub_s.pop(i)\n",
    "                for m_sub_index in np.ndindex(tuple(N_sizeub_s)):\n",
    "                    temp_m_index = list(copy.copy(m_sub_index))\n",
    "                    temp_m_index.insert(i, j)\n",
    "                    temp_K_value = get_tensor_value_from_multi_index(K_tensor, temp_m_index, N_rank, N_accum)\n",
    "                    temp_u_prod_value = 1\n",
    "                    for k in range(N_rank):\n",
    "                        if k != i:\n",
    "                            temp_u_prod_value = temp_u_prod_value * u_vec_list[k][temp_m_index[k]]\n",
    "                    temp_u_value = temp_u_value + temp_K_value * temp_u_prod_value\n",
    "                temp_u_value = (marginal_mass_vectors[i][j]) / (temp_u_value)\n",
    "                u_diff = max(u_diff, abs((u_vec_list[i][j]-temp_u_value)/(temp_u_value+numerical_precision))) \n",
    "                u_vec_list[i][j] = temp_u_value\n",
    "        if abs(u_diff) < ot_stopping_rule:\n",
    "            break\n",
    "    f_vec_list = []\n",
    "    for i in range(N_rank):\n",
    "        temp_f_vec = ot_speed * np.log(u_vec_list[i] + numerical_precision)\n",
    "        f_vec_list.append(temp_f_vec)\n",
    "    P_tensor = np.zeros(N_size_prod)\n",
    "    weighted_cost_tensor = np.zeros(N_size_prod)\n",
    "    objective_function_value = 0\n",
    "    for m_index in np.ndindex(tuple(N_size)):\n",
    "        temp_cost_value = get_tensor_value_from_multi_index(cost_tensor, m_index, N_rank, N_accum)\n",
    "        temp_P_value = get_tensor_value_from_multi_index(K_tensor, m_index, N_rank, N_accum)\n",
    "        for k in range(N_rank):\n",
    "            temp_P_value = temp_P_value * u_vec_list[k][m_index[k]]\n",
    "        P_tensor[get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)] = temp_P_value\n",
    "        weighted_cost_tensor[get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)] = temp_P_value*temp_cost_value\n",
    "        objective_function_value = objective_function_value + weighted_cost_tensor[get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)]\n",
    "    return (objective_function_value, P_tensor, weighted_cost_tensor, u_vec_list, f_vec_list)\n",
    "\n",
    "## Functions for calculating optrimal grouping with barycenter (BC)\n",
    "def calc_intergroup_cost_tensor_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "                                N_size, N_rank, N_accum, N_size_prod, order = 2.0,\n",
    "                                numerical_precision = 2e-8):\n",
    "    cost_tensor = np.zeros(N_size_prod)\n",
    "    for m_index in np.ndindex(N_size):\n",
    "        temp_data_points_nparray = []\n",
    "        temp_cost_value = 0\n",
    "        ## Cost : Sum of distances (not squared) between each point and the barycenter\n",
    "        for group in range(N_rank):\n",
    "            temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][m_index[group]]])\n",
    "        temp_barycenter = np.mean(temp_data_points_nparray, axis=0)\n",
    "        for group in range(N_rank):\n",
    "            temp_cost_value_bt2 = np.linalg.norm(temp_data_points_nparray[group] - temp_barycenter) ## Cost between two points\n",
    "            temp_cost_value = temp_cost_value + temp_cost_value_bt2\n",
    "        temp_index = get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)\n",
    "        cost_tensor[temp_index] = temp_cost_value\n",
    "    normalized_cost_tensor = copy.deepcopy(cost_tensor)\n",
    "    max_cost_value = max(cost_tensor)\n",
    "    if max_cost_value > numerical_precision:\n",
    "        normalized_cost_tensor = normalized_cost_tensor/max_cost_value\n",
    "    return (cost_tensor, normalized_cost_tensor)\n",
    "\n",
    "def calc_intergroup_cost_value_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                               N_size, N_rank, N_accum, N_size_prod, order = 2.0,\n",
    "                               numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200):\n",
    "    (intergroup_cost_tensor, normalized_intergroup_cost_tensor) = calc_intergroup_cost_tensor_with_bc(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod,\n",
    "        numerical_precision)\n",
    "    (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "     intergroup_u_vec_list, intergroup_f_vec_list) = calc_multi_ot(\n",
    "        marginal_mass_vectors, intergroup_cost_tensor, normalized_intergroup_cost_tensor, N_size, N_rank, N_accum, N_size_prod,\n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "    return (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "            intergroup_u_vec_list, intergroup_f_vec_list, intergroup_cost_tensor)\n",
    "\n",
    "def calc_intragroup_cost_nparray_list_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                                      N_size, N_rank, N_accum, N_size_prod, order = 2.0):\n",
    "    cost_nparray_list = []\n",
    "    barycenter_nparray_list = []\n",
    "    for group, size in enumerate(N_size):\n",
    "        temp_cost_nparray = np.zeros(size)\n",
    "        for element in range(size):\n",
    "            temp_data_points_nparray = []\n",
    "            ## Cost : Sum of distances (not squared) between each point and the barycenter\n",
    "            for element in range(N_size[group]): ## barycenter\n",
    "                temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][element]])\n",
    "            temp_barycenter_nparray = np.mean(temp_data_points_nparray, axis=0)\n",
    "            for element in range(N_size[group]): ## Cost between one mass point and barycenter\n",
    "                temp_cost_value_bt2 = np.linalg.norm(temp_data_points_nparray[element] - temp_barycenter_nparray, ord=order) ## Cost between two points\n",
    "                temp_cost_nparray[element] = temp_cost_value_bt2\n",
    "        cost_nparray_list.append(temp_cost_nparray)\n",
    "        barycenter_nparray_list.append(temp_barycenter_nparray)\n",
    "    return (cost_nparray_list, barycenter_nparray_list)\n",
    "\n",
    "def calc_intragroup_cost_value_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                               N_size, N_rank, N_accum, N_size_prod, order = 2.0):\n",
    "    intragroup_cost_value = 0\n",
    "    intragroup_average_cost_list = []\n",
    "    (intragroup_cost_nparray_list, intragroup_barycenter_nparray_list) = calc_intragroup_cost_nparray_list_with_bc(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod, order\n",
    "        )\n",
    "    for group in range(N_rank):\n",
    "        intragroup_average_cost = np.mean(intragroup_cost_nparray_list[group])\n",
    "        intragroup_average_cost_list.append(intragroup_average_cost)\n",
    "        intragroup_cost_value = intragroup_cost_value + intragroup_average_cost\n",
    "    intragroup_cost_value = intragroup_cost_value/N_rank\n",
    "    return (intragroup_cost_value, intragroup_cost_nparray_list, intragroup_average_cost_list, intragroup_barycenter_nparray_list)\n",
    "\n",
    "def calc_aggregate_statistical_cost_list_with_bc(intragroup_barycenter_nparray_list, intragroup_average_cost_list,\n",
    "                                         N_size, N_rank, N_accum, N_size_prod, order = 2.0):\n",
    "    center_of_intragroup_barycenter_nparray_list =  np.mean(intragroup_barycenter_nparray_list, axis=0)\n",
    "    center_of_intragroup_average_cost = np.mean(intragroup_average_cost_list, axis=0)\n",
    "    mean_cost_value = 0\n",
    "    deviation_cost_value = 0\n",
    "    for group in range(N_rank):\n",
    "        mean_cost_value = mean_cost_value + np.linalg.norm(intragroup_barycenter_nparray_list[group] - center_of_intragroup_barycenter_nparray_list, ord = order)\n",
    "        deviation_cost_value = deviation_cost_value + abs(intragroup_average_cost_list[group] - center_of_intragroup_average_cost)\n",
    "    mean_cost_value = mean_cost_value/N_rank\n",
    "    deviation_cost_value = deviation_cost_value/N_rank   \n",
    "    return (mean_cost_value, deviation_cost_value)\n",
    "\n",
    "def calc_adjusted_cost_value_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                             N_size, N_rank, N_accum, N_size_prod, \n",
    "                             mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 2.0, \n",
    "                             numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200):\n",
    "    ## intergroup_cost_value\n",
    "    (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "    intergroup_u_vec_list, intergroup_f_vec_list,\n",
    "    intergroup_cost_tensor) = calc_intergroup_cost_value_with_bc(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "        N_size, N_rank, N_accum, N_size_prod, order,\n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "        )\n",
    "    ## intragroup_cost_value\n",
    "    (intragroup_cost_value, intragroup_cost_nparray_list, intragroup_average_cost_list,\n",
    "     intragroup_barycenter_nparray_list) = calc_intragroup_cost_value_with_bc(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "        N_size, N_rank, N_accum, N_size_prod, order\n",
    "        )\n",
    "    ## aggregate_statistical_cost_value\n",
    "    (mean_cost_value, deviation_cost_value) = calc_aggregate_statistical_cost_list_with_bc(\n",
    "        intragroup_barycenter_nparray_list, intragroup_average_cost_list,\n",
    "        N_size, N_rank, N_accum, N_size_prod, order\n",
    "        )\n",
    "    ## adjusted_cost_value = (intergroup_cost_value + mean_cost_value + deviation_cost_value) / (intragroup_cost_value)\n",
    "    adjusted_cost_value = 0\n",
    "    if abs(intragroup_cost_value) < numerical_precision:\n",
    "        adjusted_cost_value = np.inf\n",
    "    else:\n",
    "        adjusted_cost_value = (intergroup_cost_value + mean_penalty_weight*mean_cost_value + deviation_penalty_weight*deviation_cost_value)/(intragroup_cost_value)\n",
    "    ## return\n",
    "    return (adjusted_cost_value, mean_cost_value, deviation_cost_value,\n",
    "            intragroup_cost_value, intragroup_cost_nparray_list, intragroup_barycenter_nparray_list, \n",
    "            intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "            intergroup_u_vec_list, intergroup_f_vec_list, intergroup_cost_tensor)\n",
    "\n",
    "def calc_optimal_grouping_with_bc(data_points_nparray, N_size,\n",
    "                           N_rank = None, N_accum = None, N_size_prod = None,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 2.0,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 10, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           show_info = False, drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## N_rank, N_accum, N_size_prod, marginal_mass_vectors\n",
    "    if (N_rank is None) or (N_accum is None) or (N_size_prod is None):\n",
    "        (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    marginal_mass_vectors = calc_marginal_mass_vectors(N_rank, N_size)\n",
    "    ## Initial value settings\n",
    "    if init_grouping_indexes_list is None:\n",
    "        init_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "    ## Calculation of optimal transportation costs under initial conditions\n",
    "    (init_adjusted_cost_value, init_mean_cost_value, init_deviation_cost_value,\n",
    "    init_intragroup_cost_value, init_intragroup_cost_nparray_list, init_intragroup_barycenter_nparray_list,\n",
    "    init_intergroup_cost_value, init_intergroup_P_tensor, init_intergroup_weighted_cost_tensor,\n",
    "    init_intergroup_u_vec_list, init_intergroup_f_vec_list,\n",
    "    init_intergroup_cost_tensor) = calc_adjusted_cost_value_with_bc(\n",
    "        init_grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod, order,\n",
    "        mean_penalty_weight, deviation_penalty_weight, \n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "    )\n",
    "    ## Preparation for recording\n",
    "    iteration_number_list = [0]\n",
    "    elapsed_time_list = [0]\n",
    "    new_adjusted_cost_trends_list = [init_adjusted_cost_value]\n",
    "    opt_adjusted_cost_trends_list = [init_adjusted_cost_value]\n",
    "    start_time = time.time()\n",
    "    ## info\n",
    "    if show_info:\n",
    "        info_func(info_args, \"---------- init\")\n",
    "        info_func(info_args, \"init_grouping_indexes_list: \" + str(init_grouping_indexes_list))\n",
    "        info_func(info_args, \"init_adjusted_cost_value: \" + str(init_adjusted_cost_value))\n",
    "        info_func(info_args, \"  (init_intergroup_cost_value, init_intragroup_cost_value: \" + str(init_intergroup_cost_value) + \", \" + str(init_intragroup_cost_value) + \")\")\n",
    "        info_func(info_args, \"  (mean_penalty_weight*init_mean_cost_value, deviation_penalty_weight*init_deviation_cost_value : \" \n",
    "              + str(mean_penalty_weight*init_mean_cost_value) + \", \" + str(deviation_penalty_weight*init_deviation_cost_value) + \")\")\n",
    "    if drawing_graphs:\n",
    "        (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "                                                                init_grouping_indexes_list, data_points_nparray, \n",
    "                                                                N_size, N_rank, N_accum, N_size_prod,\n",
    "                                                                viz2d_x, viz2d_y, init_intergroup_P_tensor)\n",
    "        # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, init_grouping_indexes_list, data_points_nparray,\n",
    "        #                             viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Initial Value\")\n",
    "        show_P_tensor(init_intergroup_P_tensor, N_size, N_rank, N_accum, f_size=(4,3), f_title=\"Initial Value\")\n",
    "    ## opt\n",
    "    opt_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "    opt_adjusted_cost_value = init_adjusted_cost_value\n",
    "    opt_mean_cost_value = init_mean_cost_value\n",
    "    opt_deviation_cost_value = init_deviation_cost_value\n",
    "    opt_intragroup_cost_value = init_intragroup_cost_value\n",
    "    opt_intergroup_cost_value = init_intergroup_cost_value\n",
    "    opt_intergroup_P_tensor = copy.deepcopy(init_intergroup_P_tensor)\n",
    "    ## new\n",
    "    new_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "    new_adjusted_cost_value = init_adjusted_cost_value\n",
    "    new_mean_cost_value = init_mean_cost_value\n",
    "    new_deviation_cost_value = init_deviation_cost_value\n",
    "    new_intragroup_cost_value = init_intragroup_cost_value\n",
    "    new_intragroup_cost_nparray_list = copy.deepcopy(init_intragroup_cost_nparray_list)\n",
    "    new_intragroup_barycenter_nparray_list = copy.deepcopy(init_intragroup_barycenter_nparray_list)\n",
    "    new_intergroup_cost_value = init_intergroup_cost_value\n",
    "    new_intergroup_P_tensor = copy.deepcopy(init_intergroup_P_tensor)\n",
    "    new_intergroup_weighted_cost_tensor = copy.deepcopy(init_intergroup_weighted_cost_tensor)\n",
    "    new_intergroup_cost_tensor = copy.deepcopy(init_intergroup_cost_tensor)\n",
    "    ## Search for optimal value\n",
    "    new_grouping_flag = True\n",
    "    search_stopping_rule_counter = 0\n",
    "    for loop in range(global_loop_max):\n",
    "        if show_info:\n",
    "            info_func(info_args, \"---------- loop: \" + str(loop+1))\n",
    "        search_stopping_rule_counter = search_stopping_rule_counter + 1\n",
    "        if search_method==\"rand\": ## search_method==\"rand\"\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=True) ## True: Random grouping, False: Grouping in order\n",
    "        else: ## search_method==\"ex\" or search_method==\"hybrid\"\n",
    "            if (search_stopping_rule_counter >= search_stopping_rule_rep):\n",
    "                opt_adjusted_cost_diff_list = opt_adjusted_cost_trends_list[(len(opt_adjusted_cost_trends_list)-search_stopping_rule_rep):]\n",
    "                old_adjusted_cost_value = opt_adjusted_cost_diff_list[0]\n",
    "                opt_adjusted_cost_diff_list = abs(np.array(opt_adjusted_cost_diff_list) - old_adjusted_cost_value)\n",
    "                opt_adjusted_cost_diff_list = opt_adjusted_cost_diff_list/(abs(old_adjusted_cost_value)+numerical_precision)\n",
    "                opt_adjusted_cost_diff_max = max(opt_adjusted_cost_diff_list)\n",
    "                if opt_adjusted_cost_diff_max <= search_stopping_rule_err:\n",
    "                    if search_method==\"hybrid\": ## search_method==\"hybrid\"\n",
    "                        search_stopping_rule_counter = 0\n",
    "                        new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=True) ## True: Random grouping, False: Grouping in order\n",
    "                        if show_info:\n",
    "                            info_func(info_args, \"Grouping has been shuffled.\")\n",
    "                    else: ## search_method==\"ex\"\n",
    "                        if show_info:\n",
    "                            info_func(info_args, \"The stopping criterion determined that convergence to the optimum value was achieved.\")\n",
    "                        break\n",
    "            ## Local grouping: Select two clusters and perform an exchange between the two clusters\n",
    "            probability_tensor = copy.deepcopy(new_intergroup_weighted_cost_tensor)\n",
    "            cluster_1_value = (random.choices(probability_tensor, k=1, weights=probability_tensor))[0]\n",
    "            cluster_1_flattened_index_list = get_tensor_flattened_index_list_from_value(probability_tensor, cluster_1_value, tensor_tolerance)\n",
    "            cluster_1_flattened_index = random.choice(cluster_1_flattened_index_list)\n",
    "            cluster_1_multi_index = get_tensor_multi_index_from_flattened_index(cluster_1_flattened_index, N_rank, N_accum)\n",
    "            probability_tensor[cluster_1_flattened_index] = 0\n",
    "            cluster_2_value = (random.choices(probability_tensor, k=1, weights=probability_tensor))[0]\n",
    "            cluster_2_flattened_index_list = get_tensor_flattened_index_list_from_value(probability_tensor, cluster_2_value, tensor_tolerance)\n",
    "            cluster_2_flattened_index = random.choice(cluster_2_flattened_index_list)\n",
    "            cluster_2_multi_index = get_tensor_multi_index_from_flattened_index(cluster_2_flattened_index, N_rank, N_accum)\n",
    "            ## Preparation for local grouping\n",
    "            local_N_size = []\n",
    "            local_data_indexes = []\n",
    "            opt_local_grouping_indexes_list = []\n",
    "            ## local_N_size, local_data_indexes, opt_local_grouping_indexes_list, local_N_rank, local_N_accum, local_N_size_prod, local_marginal_mass_vectors\n",
    "            for local_group in range(N_rank):\n",
    "                if cluster_1_multi_index[local_group] == cluster_2_multi_index[local_group]:\n",
    "                    local_N_size.append(1)\n",
    "                    temp_index = new_grouping_indexes_list[local_group][cluster_1_multi_index[local_group]]\n",
    "                    local_data_indexes.append(temp_index)\n",
    "                    opt_local_grouping_indexes_list.append([temp_index])\n",
    "                else:\n",
    "                    local_N_size.append(2)\n",
    "                    temp_index_1 = new_grouping_indexes_list[local_group][cluster_1_multi_index[local_group]]\n",
    "                    temp_index_2 = new_grouping_indexes_list[local_group][cluster_2_multi_index[local_group]]\n",
    "                    local_data_indexes.append(temp_index_1)\n",
    "                    local_data_indexes.append(temp_index_2)\n",
    "                    opt_local_grouping_indexes_list.append([temp_index_1, temp_index_2])\n",
    "            local_N_size = tuple(local_N_size)\n",
    "            (local_N_rank, local_N_accum, local_N_size_prod) = get_N(local_N_size)\n",
    "            local_marginal_mass_vectors = calc_marginal_mass_vectors(local_N_rank, local_N_size)\n",
    "            ## Calculation of current local optimal transportation costs\n",
    "            (opt_local_adjusted_cost_value, opt_local_mean_cost_value, opt_local_deviation_cost_value,\n",
    "            opt_local_intragroup_cost_value, opt_local_intragroup_cost_nparray_list, opt_local_intragroup_barycenter_nparray_list,\n",
    "            opt_local_intergroup_cost_value, opt_local_intergroup_P_tensor, opt_local_intergroup_weighted_cost_tensor,\n",
    "            opt_local_intergroup_u_vec_list, opt_local_intergroup_f_vec_list,\n",
    "            opt_local_intergroup_cost_tensor) = calc_adjusted_cost_value_with_bc(\n",
    "                opt_local_grouping_indexes_list, data_points_nparray, local_marginal_mass_vectors,\n",
    "                local_N_size, local_N_rank, local_N_accum, local_N_size_prod,\n",
    "                mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "            )\n",
    "            old_local_adjusted_cost_value = opt_local_adjusted_cost_value\n",
    "            ## Enumeration of grouping patterns\n",
    "            ## (If N_rank is 2 or 3, all enumeration is used, and more than that, random selection is used.)\n",
    "            local_grouping_indexes_list_combinations = []\n",
    "            if local_N_rank == 2: ## It might be a good idea to have all the patterns ready in advance. (2^2-1=3)\n",
    "                numbers_list = list(range(sum(local_N_size)))\n",
    "                for sub_numbers_list_1 in itertools.combinations(numbers_list, local_N_size[0]):\n",
    "                    sub_numbers_list_2 = tuple(np.delete(numbers_list, sub_numbers_list_1, 0))\n",
    "                    temp_local_grouping_indexes_list = list((np.array(local_data_indexes))[list(sub_numbers_list_1+sub_numbers_list_2)])\n",
    "                    temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                    if temp_local_grouping_indexes_list != opt_local_grouping_indexes_list:\n",
    "                        local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            elif local_N_rank == 3: ## It might be a good idea to have all the patterns ready in advance. (2^3-1=7)\n",
    "                numbers_list = list(range(sum(local_N_size)))\n",
    "                for sub_numbers_list_1 in itertools.combinations(numbers_list, local_N_size[0]):\n",
    "                    temp_numbers_list = np.delete(numbers_list, sub_numbers_list_1, 0)\n",
    "                    for sub_numbers_list_2 in itertools.combinations(temp_numbers_list, local_N_size[1]):      \n",
    "                        sub_numbers_list_3 = tuple(np.delete(numbers_list, sub_numbers_list_1+sub_numbers_list_2, 0))\n",
    "                        temp_local_grouping_indexes_list = list((np.array(local_data_indexes))[list(sub_numbers_list_1+sub_numbers_list_2+sub_numbers_list_3)])\n",
    "                        temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                        if temp_local_grouping_indexes_list!= opt_local_grouping_indexes_list:\n",
    "                                local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            else:\n",
    "                for i in range(local_loop_max):\n",
    "                    temp_local_grouping_indexes_list = random.sample(local_data_indexes, len(local_data_indexes))\n",
    "                    temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                    if (temp_local_grouping_indexes_list!= opt_local_grouping_indexes_list) and (temp_local_grouping_indexes_list not in local_grouping_indexes_list_combinations):\n",
    "                                local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            ## Calculate the cost of local optimal transportation for each pattern of local grouping\n",
    "            opt_local_adjusted_cost_value = float('inf')\n",
    "            opt_local_grouping_indexes_list_list = []\n",
    "            for new_local_grouping_indexes_list in local_grouping_indexes_list_combinations:\n",
    "                (new_local_adjusted_cost_value, new_local_mean_cost_value, new_local_deviation_cost_value,\n",
    "                new_local_intragroup_cost_value, new_local_intragroup_cost_nparray_list, new_local_intragroup_barycenter_nparray_list,\n",
    "                new_local_intergroup_cost_value, new_local_intergroup_P_tensor, new_local_intergroup_weighted_cost_tenso,\n",
    "                new_local_intergroup_u_vec_list, new_local_intergroup_f_vec_list,\n",
    "                new_local_intergroup_cost_tensor) = calc_adjusted_cost_value_with_bc(\n",
    "                        new_local_grouping_indexes_list, data_points_nparray, local_marginal_mass_vectors,\n",
    "                        local_N_size, local_N_rank, local_N_accum, local_N_size_prod,\n",
    "                        mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "                )\n",
    "                if new_local_adjusted_cost_value < opt_local_adjusted_cost_value:\n",
    "                    opt_local_adjusted_cost_value = new_local_adjusted_cost_value\n",
    "                    opt_local_grouping_indexes_list_list = [new_local_grouping_indexes_list]\n",
    "                elif new_local_adjusted_cost_value == opt_local_adjusted_cost_value:\n",
    "                    opt_local_grouping_indexes_list_list.append(new_local_grouping_indexes_list)\n",
    "            opt_local_grouping_indexes_list = random.choice(opt_local_grouping_indexes_list_list)\n",
    "            random_number = random.random()\n",
    "            new_grouping_flag = (opt_local_adjusted_cost_value==0) or (random_number <= (old_local_adjusted_cost_value/opt_local_adjusted_cost_value))\n",
    "            if new_grouping_flag:\n",
    "                for group in range(local_N_rank):\n",
    "                    if local_N_size[group] == 1:\n",
    "                        new_grouping_indexes_list[group][cluster_1_multi_index[group]] = opt_local_grouping_indexes_list[group][0]\n",
    "                    else:\n",
    "                        new_grouping_indexes_list[group][cluster_1_multi_index[group]] = opt_local_grouping_indexes_list[group][0]\n",
    "                        new_grouping_indexes_list[group][cluster_2_multi_index[group]] = opt_local_grouping_indexes_list[group][1]\n",
    "        if new_grouping_flag:\n",
    "            ## Calculation of the cost of optimal transport\n",
    "            (new_adjusted_cost_value, new_mean_cost_value, new_deviation_cost_value,\n",
    "            new_intragroup_cost_value, new_intragroup_cost_nparray_list, new_intragroup_barycenter_nparray_list, \n",
    "            new_intergroup_cost_value, new_intergroup_P_tensor, \n",
    "            new_intergroup_weighted_cost_tensor, new_intergroup_u_vec_list, new_intergroup_f_vec_list, \n",
    "            new_intergroup_cost_tensor) = calc_adjusted_cost_value_with_bc(\n",
    "                    new_grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                    N_size, N_rank, N_accum, N_size_prod,\n",
    "                    mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                    numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "            )\n",
    "        if show_info:\n",
    "            info_func(info_args, \"new_grouping_indexes_list: \" + str(new_grouping_indexes_list))\n",
    "            info_func(info_args, \"new_adjusted_cost_value: \" + str(new_adjusted_cost_value))\n",
    "        # if drawing_graphs:\n",
    "        #     (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "        #                                                 new_grouping_indexes_list, data_points_nparray, \n",
    "        #                                                 N_size, N_rank, N_accum, N_size_prod,\n",
    "        #                                                 viz2d_x, viz2d_y, new_intergroup_P_tensor)\n",
    "        #     # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "        #     #                             viz2d_x, viz2d_y, line_width = 1, f_size=(4,3,1), f_title=\"Mid-calculation\")\n",
    "        if new_adjusted_cost_value <= opt_adjusted_cost_value:\n",
    "            opt_grouping_indexes_list = copy.deepcopy(new_grouping_indexes_list)\n",
    "            opt_adjusted_cost_value = new_adjusted_cost_value\n",
    "            opt_mean_cost_value = new_mean_cost_value\n",
    "            opt_deviation_cost_value = new_deviation_cost_value\n",
    "            opt_intragroup_cost_value = new_intragroup_cost_value\n",
    "            opt_intragroup_cost_nparray_list = copy.deepcopy(new_intragroup_cost_nparray_list)\n",
    "            opt_intragroup_barycenter_nparray_list = copy.deepcopy(new_intragroup_barycenter_nparray_list)\n",
    "            opt_intergroup_cost_value = new_intergroup_cost_value\n",
    "            opt_intergroup_P_tensor = copy.deepcopy(new_intergroup_P_tensor)\n",
    "            opt_intergroup_weighted_cost_tensor = copy.deepcopy(new_intergroup_weighted_cost_tensor)\n",
    "            opt_intergroup_cost_tensor = copy.deepcopy(new_intergroup_cost_tensor)\n",
    "        ## Recording\n",
    "        iteration_number_list.append(loop+1)\n",
    "        elapsed_time = float(time.time() - start_time)\n",
    "        elapsed_time_list.append(elapsed_time)\n",
    "        new_adjusted_cost_trends_list.append(new_adjusted_cost_value)\n",
    "        opt_adjusted_cost_trends_list.append(opt_adjusted_cost_value)\n",
    "    ## info\n",
    "    if show_info:\n",
    "        info_func(info_args, \"---------- opt\")\n",
    "        info_func(info_args, \"opt_grouping_indexes_list: \" + str(init_grouping_indexes_list))\n",
    "        info_func(info_args, \"opt_adjusted_cost_value: \" + str(opt_adjusted_cost_value))\n",
    "        info_func(info_args, \"  (opt_intergroup_cost_value, opt_intragroup_cost_value: \" + str(opt_intergroup_cost_value) + \", \" + str(opt_intragroup_cost_value) + \")\")\n",
    "        info_func(info_args, \"  (mean_penalty_weight*opt_mean_cost_value, deviation_penalty_weight*opt_deviation_cost_value : \"\n",
    "              + str(mean_penalty_weight*opt_mean_cost_value) + \", \" + str(deviation_penalty_weight*opt_deviation_cost_value) + \")\")\n",
    "        ## Computation time\n",
    "        elapsed_hour = elapsed_time // 3600\n",
    "        elapsed_minute = (elapsed_time % 3600) // 60\n",
    "        elapsed_second = (elapsed_time % 3600 % 60)\n",
    "        info_func(info_args, \"computation time:\" + str(elapsed_hour).zfill(2) + \":\" + str(elapsed_minute).zfill(2) + \":\" + str(elapsed_second).zfill(2))\n",
    "    if drawing_graphs:\n",
    "        (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "                                            opt_grouping_indexes_list, data_points_nparray, \n",
    "                                            N_size, N_rank, N_accum, N_size_prod,\n",
    "                                            viz2d_x, viz2d_y, opt_intergroup_P_tensor)\n",
    "        # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, opt_grouping_indexes_list, data_points_nparray,\n",
    "        #                             viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "        show_P_tensor(opt_intergroup_P_tensor, N_size, N_rank, N_accum, f_size=(4,3), f_title=\"Optimal value\")\n",
    "     ## return\n",
    "    return (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "            opt_adjusted_cost_value,\n",
    "            opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "            opt_mean_cost_value, opt_deviation_cost_value,\n",
    "            iteration_number_list, elapsed_time_list,\n",
    "            new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "            viz2d_x, viz2d_y\n",
    "            )\n",
    "\n",
    "def gen_optimal_grouping_with_bc(data_points_nparray, N_size = None, standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 2.0, \n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## ## data_points_nparray: NumPy array consisting of data points\n",
    "    ## N_size: Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "    ## standardization = True ## Standardization\n",
    "    ## mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "    ## deviation_penalty_weight = 0.1 ## Weight of deviation_cost_value\n",
    "    ## order = 2.0 ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "    ## numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "    ## ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "    ## ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ## ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot_with_bc\n",
    "    ## tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "    ## global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "    ## local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "    ## init_grouping_indexes_list = None ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## search_method = \"ex\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "    ## search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "    ## search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "    ## main_show_info = True ## Flag whether information is displayed or not\n",
    "    ## main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "    ## sub_show_info = False ## Flag whether information is displayed or not\n",
    "    ## sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "    ## info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "    ## info_args = None ## Arguments for info_func\n",
    "    ## tensor_size_max = 4000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "    ## group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "    ## loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "    ## viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## N_size\n",
    "    data_size = len(data_points_nparray)\n",
    "    if N_size is None:\n",
    "        info_func(info_args, \"Warning: N_size is None.\")\n",
    "        N_size = tuple(data_size)\n",
    "    if (type(N_size) == int):\n",
    "        if data_size > N_size:\n",
    "            (quotient, remainder) = divmod(data_size, N_size)\n",
    "            N_size = np.full(N_size, quotient)\n",
    "            for i in range(remainder):\n",
    "                N_size[i] = N_size[i] + 1\n",
    "            N_size = tuple(N_size)\n",
    "        else:\n",
    "            N_size = tuple(data_size)\n",
    "    elif (type(N_size) == tuple) or (type(N_size) == list):\n",
    "        N_size = tuple(N_size)\n",
    "        if data_size != sum(N_size):\n",
    "            info_func(info_args, \"Warning: The sum of N_size does not match sample size.\")\n",
    "            N_size = tuple(data_size)\n",
    "    else:\n",
    "        info_func(info_args, \"Warning: N_size must be of type integer or tuple.\")\n",
    "        N_size = tuple(data_size)\n",
    "    (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    res_calc_optimal_grouping = None\n",
    "    ## Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    ## Setting Parameters\n",
    "    if (N_size_prod > tensor_size_max) or (min(N_size) > group_size_max): ## If True, use \"approximate solution\".\n",
    "        ## Initial value settings\n",
    "        if init_grouping_indexes_list is None:\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "        else:\n",
    "            new_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "        if main_show_info:\n",
    "            info_func(info_args, \"---------- new_grouping_indexes_list (initial value): \" + str(new_grouping_indexes_list))\n",
    "        if main_drawing_graphs:\n",
    "            (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                        viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Initial value\")\n",
    "        for loop in range( loop_max_multiplier*N_rank ):\n",
    "            (group_1, group_2) = random.sample(list(range(N_rank)), 2)\n",
    "            sub_N_size = [N_size[group_1], N_size[group_2]]\n",
    "            group_1_sub_index = []\n",
    "            group_2_sub_index = []\n",
    "            if sub_N_size[0] > group_size_max:\n",
    "                group_1_sub_index = random.sample(list(range(sub_N_size[0])), group_size_max)\n",
    "                sub_N_size[0] = group_size_max\n",
    "            else:\n",
    "                group_1_sub_index = list(range(sub_N_size[0]))\n",
    "            if sub_N_size[1] > group_size_max:\n",
    "                group_2_sub_index = random.sample(list(range(sub_N_size[1])), group_size_max)\n",
    "                sub_N_size[1] = group_size_max\n",
    "            else:\n",
    "                group_2_sub_index = list(range(sub_N_size[1]))\n",
    "            sub_N_size = tuple(sub_N_size)\n",
    "            sub_data_index = list(np.array(new_grouping_indexes_list[group_1])[group_1_sub_index]) + list(np.array(new_grouping_indexes_list[group_2])[group_2_sub_index])\n",
    "            sub_data_points_nparray = data_points_nparray[sub_data_index]\n",
    "            (sub_N_rank, sub_N_accum, sub_N_size_prod) = get_N(sub_N_size)\n",
    "            res_calc_optimal_grouping = calc_optimal_grouping_with_bc(\n",
    "                sub_data_points_nparray, sub_N_size,\n",
    "                sub_N_rank, sub_N_accum, sub_N_size_prod,\n",
    "                mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                numerical_precision,\n",
    "                ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                None, True, ## init_grouping_indexes_list, init_grouping_rand,\n",
    "                search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                sub_show_info, sub_drawing_graphs,\n",
    "                info_func,\n",
    "                info_args,\n",
    "                viz2d_x, viz2d_y)\n",
    "            sub_opt_grouping_indexes_list = res_calc_optimal_grouping[0]\n",
    "            group_1_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[0]])\n",
    "            group_2_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[1]])\n",
    "            for i, index in enumerate(group_1_sub_index):\n",
    "                new_grouping_indexes_list[group_1][index] = group_1_sub_grouping_indexes_list[i]\n",
    "            for i, index in enumerate(group_2_sub_index):\n",
    "                new_grouping_indexes_list[group_2][index] = group_2_sub_grouping_indexes_list[i]\n",
    "            if main_show_info:\n",
    "                info_func(info_args, \"---------- loop (partial optimization): \" + str(loop+1))\n",
    "                info_func(info_args, \"---------- new_grouping_indexes_list (partial optimization): \" + str(new_grouping_indexes_list))\n",
    "            if (main_drawing_graphs) and (loop == (2*N_rank-1)):\n",
    "                (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                            viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "        res_calc_optimal_grouping = (new_grouping_indexes_list, \n",
    "                                     None, # opt_intergroup_P_tensor,\n",
    "                                     None, # opt_adjusted_cost_value,\n",
    "                                     None, # opt_intergroup_cost_value,\n",
    "                                     None, # opt_intragroup_cost_value,\n",
    "                                     None, # opt_mean_cost_value,\n",
    "                                     None, # opt_deviation_cost_value,\n",
    "                                     None, # iteration_number_list,\n",
    "                                     None, # elapsed_time_list,\n",
    "                                     None, # new_adjusted_cost_trends_list,\n",
    "                                     None, # opt_adjusted_cost_trends_list,\n",
    "                                     viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_bc(data_points_nparray, N_size,\n",
    "                            N_rank, N_accum, N_size_prod,\n",
    "                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_indexes_list, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            info_func,\n",
    "                            info_args,\n",
    "                            viz2d_x, viz2d_y)\n",
    "    ## res_calc_optimal_grouping:\n",
    "    ## (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "    ##  opt_adjusted_cost_value,\n",
    "    ##  opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "    ##  opt_mean_cost_value, opt_deviation_cost_value,\n",
    "    ##  iteration_number_list, elapsed_time_list,\n",
    "    ##  new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "    ##  viz2d_x, viz2d_y)\n",
    "    return res_calc_optimal_grouping\n",
    "\n",
    "def gen_optimal_grouping_from_csv_file_with_bc(input_filepath= \"./members.csv\", input_index_col = 0, output_filepath = \"./grouping.csv\",\n",
    "                           N_size = None,\n",
    "                           standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 2.0, \n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## input_filepath = \"./members.csv\" ## File path of the input file, in csv format.\n",
    "    ## input_index_col = 0 ## Column number with column name or column number in the csv file\n",
    "    ## output_filepath = \"./grouping.csv\" ##  File path of the output file, in csv format.\n",
    "    ############################\n",
    "    ## Loading data: loading csv files\n",
    "    df = pd.read_csv(filepath_or_buffer=input_filepath, index_col=input_index_col)\n",
    "    output_data = copy.deepcopy(df)\n",
    "    data_size = len(df)\n",
    "    ############################\n",
    "    ## Dummy variable processing: dummy variable for columns where dtype is object\n",
    "    df = pd.get_dummies(df, drop_first=True, dtype=\"float\") # float64, uint8, bool\n",
    "    ############################\n",
    "    ##  Handling missing values: interpolate by median\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    ############################\n",
    "    ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray_org = np.array(df.values)\n",
    "    data_points_nparray = copy.deepcopy(data_points_nparray_org) ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray = data_points_nparray.astype(float)\n",
    "    ###########################################\n",
    "    ## Data Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    ###########################################\n",
    "    ## Division and Search\n",
    "    (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "     opt_adjusted_cost_value,\n",
    "     opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "     opt_mean_cost_value, opt_deviation_cost_value,\n",
    "     iteration_number_list, elapsed_time_list,\n",
    "     new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "     viz2d_x, viz2d_y\n",
    "    ) = gen_optimal_grouping_with_bc(data_points_nparray, N_size, standardization,\n",
    "                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_indexes_list, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            sub_show_info, sub_drawing_graphs,\n",
    "                            info_func, info_args,\n",
    "                            tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                            viz2d_x, viz2d_y)\n",
    "    ###########################################\n",
    "    ## Output grouping results to csv file\n",
    "    group_labels_list = np.zeros(data_size)\n",
    "    group = 0\n",
    "    for members_list in opt_grouping_indexes_list:\n",
    "        for member in members_list:\n",
    "            group_labels_list[member] = int(group)\n",
    "        group = group + 1\n",
    "    output_data.insert(loc=0, column=\"Group\", value=group_labels_list.astype(int), allow_duplicates=True)\n",
    "    if (viz2d_x is not None) and (viz2d_y is not None):\n",
    "        output_data.insert(loc=1, column=\"viz2d_x\", value=viz2d_x.astype(float), allow_duplicates=True)\n",
    "        output_data.insert(loc=2, column=\"viz2d_y\", value=viz2d_y.astype(float), allow_duplicates=True)\n",
    "    output_data.to_csv(output_filepath)\n",
    "    ###########################################\n",
    "    ## Return\n",
    "    return (opt_grouping_indexes_list,\n",
    "            opt_intergroup_P_tensor,\n",
    "            opt_adjusted_cost_value,\n",
    "            opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "            opt_mean_cost_value, opt_deviation_cost_value,\n",
    "            iteration_number_list, elapsed_time_list,\n",
    "            new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "            output_data, viz2d_x, viz2d_y\n",
    "    )\n",
    "\n",
    "## Functions for calculating optrimal grouping with minimum spanning tree (MST)\n",
    "def calc_distance_matrix(data_points: List[np.ndarray], order: float) -> np.ndarray:\n",
    "    n = len(data_points)\n",
    "    p = len(data_points[0]) ## Assuming all points have the same dimensionality\n",
    "    ## Initialize an empty distance matrix\n",
    "    distance_matrix = np.zeros((n, n))\n",
    "    ## Calculate pairwise distances\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            distance = np.linalg.norm(np.array(data_points[i]) - np.array(data_points[j]), ord = order)\n",
    "            distance_matrix[i, j] = distance\n",
    "            distance_matrix[j, i] = distance\n",
    "    return distance_matrix\n",
    "\n",
    "def calc_minimum_spanning_tree(distance_matrix: np.ndarray) -> Tuple[np.ndarray, float]:\n",
    "    n = distance_matrix.shape[0]\n",
    "    visited = [False] * n\n",
    "    adjacency_matrix = np.zeros((n, n))\n",
    "    total_weight = 0.0\n",
    "    ## Start with the first node\n",
    "    visited[0] = True\n",
    "    for _ in range(n - 1):\n",
    "        min_edge_weight = float('inf')\n",
    "        u, v = -1, -1\n",
    "        ## Find the minimum weight edge connecting visited and unvisited nodes\n",
    "        for i in range(n):\n",
    "            if visited[i]:\n",
    "                for j in range(n):\n",
    "                    if not visited[j] and distance_matrix[i, j] < min_edge_weight:\n",
    "                        min_edge_weight = distance_matrix[i, j]\n",
    "                        u, v = i, j\n",
    "        ## Add the edge to the MST\n",
    "        adjacency_matrix[u, v] = 1\n",
    "        adjacency_matrix[v, u] = 1\n",
    "        total_weight += min_edge_weight\n",
    "        visited[v] = True\n",
    "    return adjacency_matrix, total_weight\n",
    "\n",
    "def calc_distance_matrix_and_minimum_spanning_tree(data_points: List[np.ndarray], order: float) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    distance_matrix = calc_distance_matrix(data_points, order)\n",
    "    (adjacency_matrix, total_weight) = calc_minimum_spanning_tree(distance_matrix)\n",
    "    return (distance_matrix, adjacency_matrix, total_weight)\n",
    "\n",
    "def calc_intergroup_cost_tensor_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "                                N_size, N_rank, N_accum, N_size_prod, order = 1.0,\n",
    "                                numerical_precision = 2e-8):\n",
    "    cost_tensor = np.zeros(N_size_prod)\n",
    "    for m_index in np.ndindex(N_size):\n",
    "        temp_data_points_nparray = []\n",
    "        temp_cost_value = 0\n",
    "        for group in range(N_rank):\n",
    "            temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][m_index[group]]])\n",
    "        ## Cost: MST\n",
    "        (distance_nparray, adjacency_nparray,\n",
    "         total_weight) = calc_distance_matrix_and_minimum_spanning_tree(\n",
    "             temp_data_points_nparray, order)\n",
    "        temp_cost_value = total_weight\n",
    "        temp_index = get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)\n",
    "        cost_tensor[temp_index] = temp_cost_value\n",
    "    normalized_cost_tensor = copy.deepcopy(cost_tensor)\n",
    "    max_cost_value = max(cost_tensor)\n",
    "    if max_cost_value > numerical_precision:\n",
    "        normalized_cost_tensor = normalized_cost_tensor/max_cost_value\n",
    "    return (cost_tensor, normalized_cost_tensor)\n",
    "\n",
    "def calc_intergroup_cost_value_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                               N_size, N_rank, N_accum, N_size_prod, order = 1.0,\n",
    "                               numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200):\n",
    "    (intergroup_cost_tensor, normalized_intergroup_cost_tensor) = calc_intergroup_cost_tensor_with_mst(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod, order,\n",
    "        numerical_precision)\n",
    "    (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "     intergroup_u_vec_list, intergroup_f_vec_list) = calc_multi_ot(\n",
    "        marginal_mass_vectors, intergroup_cost_tensor, normalized_intergroup_cost_tensor, N_size, N_rank, N_accum, N_size_prod,\n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "    return (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "            intergroup_u_vec_list, intergroup_f_vec_list, intergroup_cost_tensor)\n",
    "\n",
    "def calc_intragroup_cost_list_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                                      N_size, N_rank, N_accum, N_size_prod, order = 1.0):\n",
    "    distance_nparray_list = []\n",
    "    adjacency_nparray_list = []\n",
    "    cost_list = []\n",
    "    for group, size in enumerate(N_size):\n",
    "        temp_data_points_nparray = []\n",
    "        for element in range(size):\n",
    "            temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][element]])\n",
    "        ## Cost : MST\n",
    "        (distance_nparray, adjacency_nparray,\n",
    "         total_weight) = calc_distance_matrix_and_minimum_spanning_tree(\n",
    "            temp_data_points_nparray, order)\n",
    "        distance_nparray_list.append(distance_nparray)\n",
    "        adjacency_nparray_list.append(adjacency_nparray)\n",
    "        cost_list.append(total_weight)\n",
    "    return (distance_nparray_list, adjacency_nparray_list, cost_list)\n",
    "\n",
    "def calc_intragroup_cost_value_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                               N_size, N_rank, N_accum, N_size_prod, order = 1.0):\n",
    "    intragroup_cost_value = 0\n",
    "    (intragroup_distance_nparray_list, intragroup_adjacency_nparray_list,\n",
    "     intragroup_cost_list) = calc_intragroup_cost_list_with_mst(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod, order)\n",
    "    intragroup_cost_value = sum(intragroup_cost_list)/N_rank\n",
    "    return (intragroup_distance_nparray_list, intragroup_adjacency_nparray_list,\n",
    "            intragroup_cost_list, intragroup_cost_value)\n",
    "\n",
    "def calc_mean_cost_value_with_mst(grouping_indexes_list, data_points_nparray,\n",
    "                            N_size, N_rank, N_accum, N_size_prod, order = 1.0):\n",
    "    barycenter_nparray_list = []\n",
    "    for group, size in enumerate(N_size):\n",
    "        temp_data_points_nparray = []\n",
    "        for element in range(size):\n",
    "            temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][element]])\n",
    "        temp_barycenter_nparray = np.mean(temp_data_points_nparray, axis=0)\n",
    "        barycenter_nparray_list.append(temp_barycenter_nparray)\n",
    "    barycenter_nparray_list = np.array(barycenter_nparray_list)\n",
    "    ## Cost: MST\n",
    "    (distance_nparray, adjacency_nparray,\n",
    "        mean_cost_value) = calc_distance_matrix_and_minimum_spanning_tree(\n",
    "            barycenter_nparray_list, order)\n",
    "    mean_cost_value = mean_cost_value/N_rank\n",
    "    return (barycenter_nparray_list, mean_cost_value)\n",
    "\n",
    "def calc_deviation_cost_value_with_mst(intragroup_distance_nparray_list):\n",
    "    return (max(intragroup_distance_nparray_list) - min(intragroup_distance_nparray_list))\n",
    "\n",
    "def calc_aggregate_statistical_cost_list_with_mst(grouping_indexes_list, data_points_nparray,\n",
    "                                                  intragroup_distance_nparray_list, intragroup_adjacency_nparray_list, intragroup_cost_list,\n",
    "                                                  N_size, N_rank, N_accum, N_size_prod, order = 1.0):\n",
    "    (barycenter_nparray_list, mean_cost_value) = calc_mean_cost_value_with_mst(grouping_indexes_list, data_points_nparray,\n",
    "                                                                               N_size, N_rank, N_accum, N_size_prod, order)\n",
    "    deviation_cost_value = calc_deviation_cost_value_with_mst(intragroup_cost_list)\n",
    "    return (mean_cost_value, deviation_cost_value)\n",
    "\n",
    "def calc_adjusted_cost_value_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                             N_size, N_rank, N_accum, N_size_prod, \n",
    "                             mean_penalty_weight = 0.1, deviation_penalty_weight=0.8, order = 1.0,\n",
    "                             numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200):\n",
    "    ## intergroup_cost_value\n",
    "    (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "    intergroup_u_vec_list, intergroup_f_vec_list,\n",
    "    intergroup_cost_tensor) = calc_intergroup_cost_value_with_mst(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "        N_size, N_rank, N_accum, N_size_prod, order,\n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "        )\n",
    "    ## intragroup_cost_value\n",
    "    (intragroup_distance_nparray_list, intragroup_adjacency_nparray_list,\n",
    "            intragroup_cost_list, intragroup_cost_value) = calc_intragroup_cost_value_with_mst(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "        N_size, N_rank, N_accum, N_size_prod\n",
    "        )\n",
    "    ## aggregate_statistical_cost_value\n",
    "    (mean_cost_value, deviation_cost_value) = calc_aggregate_statistical_cost_list_with_mst(grouping_indexes_list, data_points_nparray,\n",
    "                                                                                            intragroup_distance_nparray_list, intragroup_adjacency_nparray_list, intragroup_cost_list, \n",
    "                                                                                            N_size, N_rank, N_accum, N_size_prod, order = 1.0)\n",
    "    ## adjusted_cost_value = (intergroup_cost_value + mean_cost_value + deviation_cost_value) / (intragroup_cost_value)\n",
    "    adjusted_cost_value = 0\n",
    "    if abs(intragroup_cost_value) < numerical_precision:\n",
    "        adjusted_cost_value = np.inf\n",
    "    else:\n",
    "        adjusted_cost_value = (intergroup_cost_value + mean_penalty_weight*mean_cost_value + deviation_penalty_weight*deviation_cost_value)/(intragroup_cost_value)\n",
    "    ## return\n",
    "    return (adjusted_cost_value, mean_cost_value, deviation_cost_value,\n",
    "            intragroup_cost_value, intragroup_distance_nparray_list, intragroup_adjacency_nparray_list, intragroup_cost_list,\n",
    "            intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "            intergroup_u_vec_list, intergroup_f_vec_list, intergroup_cost_tensor)\n",
    "\n",
    "def calc_optimal_grouping_with_mst(data_points_nparray, N_size,\n",
    "                           N_rank = None, N_accum = None, N_size_prod = None,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.8, order = 1.0,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 10, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           show_info = False, drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## N_rank, N_accum, N_size_prod, marginal_mass_vectors\n",
    "    if (N_rank is None) or (N_accum is None) or (N_size_prod is None):\n",
    "        (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    marginal_mass_vectors = calc_marginal_mass_vectors(N_rank, N_size)\n",
    "    ## Initial value settings\n",
    "    if init_grouping_indexes_list is None:\n",
    "        init_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "    ## Calculation of optimal transportation costs under initial conditions\n",
    "    (init_adjusted_cost_value, init_mean_cost_value, init_deviation_cost_value,\n",
    "    init_intragroup_cost_value, init_intragroup_distance_nparray_list, init_intragroup_adjacency_nparray_list, init_intragroup_cost_list,\n",
    "    init_intergroup_cost_value, init_intergroup_P_tensor, init_intergroup_weighted_cost_tensor,\n",
    "    init_intergroup_u_vec_list, init_intergroup_f_vec_list,\n",
    "    init_intergroup_cost_tensor) = calc_adjusted_cost_value_with_mst(init_grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                             N_size, N_rank, N_accum, N_size_prod, \n",
    "                             mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                             numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "    ## Preparation for recording\n",
    "    iteration_number_list = [0]\n",
    "    elapsed_time_list = [0]\n",
    "    new_adjusted_cost_trends_list = [init_adjusted_cost_value]\n",
    "    opt_adjusted_cost_trends_list = [init_adjusted_cost_value]\n",
    "    start_time = time.time()\n",
    "    ## info\n",
    "    if show_info:\n",
    "        info_func(info_args, \"---------- init\")\n",
    "        info_func(info_args, \"init_grouping_indexes_list: \" + str(init_grouping_indexes_list))\n",
    "        info_func(info_args, \"init_adjusted_cost_value: \" + str(init_adjusted_cost_value))\n",
    "        info_func(info_args, \"  (init_intergroup_cost_value, init_intragroup_cost_value: \" + str(init_intergroup_cost_value) + \", \" + str(init_intragroup_cost_value) + \")\")\n",
    "        info_func(info_args, \"  (mean_penalty_weight*init_mean_cost_value, deviation_penalty_weight*init_deviation_cost_value : \" \n",
    "              + str(mean_penalty_weight*init_mean_cost_value) + \", \" + str(deviation_penalty_weight*init_deviation_cost_value) + \")\")\n",
    "    if drawing_graphs:\n",
    "        (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "                                                                init_grouping_indexes_list, data_points_nparray, \n",
    "                                                                N_size, N_rank, N_accum, N_size_prod,\n",
    "                                                                viz2d_x, viz2d_y, init_intergroup_P_tensor)\n",
    "        # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, init_grouping_indexes_list, data_points_nparray,\n",
    "        #                             viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Initial Value\")\n",
    "        show_P_tensor(init_intergroup_P_tensor, N_size, N_rank, N_accum, f_size=(4,3), f_title=\"Initial Value\")\n",
    "    ## opt\n",
    "    opt_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "    opt_adjusted_cost_value = init_adjusted_cost_value\n",
    "    opt_mean_cost_value = init_mean_cost_value\n",
    "    opt_deviation_cost_value = init_deviation_cost_value\n",
    "    opt_intragroup_cost_value = init_intragroup_cost_value\n",
    "    opt_intergroup_cost_value = init_intergroup_cost_value\n",
    "    opt_intergroup_P_tensor = copy.deepcopy(init_intergroup_P_tensor)\n",
    "    ## new\n",
    "    new_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "    new_adjusted_cost_value = init_adjusted_cost_value\n",
    "    new_mean_cost_value = init_mean_cost_value\n",
    "    new_deviation_cost_value = init_deviation_cost_value\n",
    "    new_intragroup_cost_value = init_intragroup_cost_value\n",
    "    new_intergroup_cost_value = init_intergroup_cost_value\n",
    "    new_intergroup_P_tensor = copy.deepcopy(init_intergroup_P_tensor)\n",
    "    new_intergroup_weighted_cost_tensor = copy.deepcopy(init_intergroup_weighted_cost_tensor)\n",
    "    new_intergroup_cost_tensor = copy.deepcopy(init_intergroup_cost_tensor)\n",
    "    ## Search for optimal value\n",
    "    new_grouping_flag = True\n",
    "    search_stopping_rule_counter = 0\n",
    "    for loop in range(global_loop_max):\n",
    "        if show_info:\n",
    "            info_func(info_args, \"---------- loop: \" + str(loop+1))\n",
    "        search_stopping_rule_counter = search_stopping_rule_counter + 1\n",
    "        if search_method==\"rand\": ## search_method==\"rand\"\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=True) ## True: Random grouping, False: Grouping in order\n",
    "        else: ## search_method==\"ex\" or search_method==\"hybrid\"\n",
    "            if (search_stopping_rule_counter >= search_stopping_rule_rep):\n",
    "                opt_adjusted_cost_diff_list = opt_adjusted_cost_trends_list[(len(opt_adjusted_cost_trends_list)-search_stopping_rule_rep):]\n",
    "                old_adjusted_cost_value = opt_adjusted_cost_diff_list[0]\n",
    "                opt_adjusted_cost_diff_list = abs(np.array(opt_adjusted_cost_diff_list) - old_adjusted_cost_value)\n",
    "                opt_adjusted_cost_diff_list = opt_adjusted_cost_diff_list/(abs(old_adjusted_cost_value)+numerical_precision)\n",
    "                opt_adjusted_cost_diff_max = max(opt_adjusted_cost_diff_list)\n",
    "                if opt_adjusted_cost_diff_max <= search_stopping_rule_err:\n",
    "                    if search_method==\"hybrid\": ## search_method==\"hybrid\"\n",
    "                        search_stopping_rule_counter = 0\n",
    "                        new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=True) ## True: Random grouping, False: Grouping in order\n",
    "                        if show_info:\n",
    "                            info_func(info_args, \"Grouping has been shuffled.\")\n",
    "                    else: ## search_method==\"ex\"\n",
    "                        if show_info:\n",
    "                            info_func(info_args, \"The stopping criterion determined that convergence to the optimum value was achieved.\")\n",
    "                        break\n",
    "            ## Local grouping: Select two clusters and perform an exchange between the two clusters\n",
    "            probability_tensor = copy.deepcopy(new_intergroup_weighted_cost_tensor)\n",
    "            cluster_1_value = (random.choices(probability_tensor, k=1, weights=probability_tensor))[0]\n",
    "            cluster_1_flattened_index_list = get_tensor_flattened_index_list_from_value(probability_tensor, cluster_1_value, tensor_tolerance)\n",
    "            cluster_1_flattened_index = random.choice(cluster_1_flattened_index_list)\n",
    "            cluster_1_multi_index = get_tensor_multi_index_from_flattened_index(cluster_1_flattened_index, N_rank, N_accum)\n",
    "            probability_tensor[cluster_1_flattened_index] = 0\n",
    "            cluster_2_value = (random.choices(probability_tensor, k=1, weights=probability_tensor))[0]\n",
    "            cluster_2_flattened_index_list = get_tensor_flattened_index_list_from_value(probability_tensor, cluster_2_value, tensor_tolerance)\n",
    "            cluster_2_flattened_index = random.choice(cluster_2_flattened_index_list)\n",
    "            cluster_2_multi_index = get_tensor_multi_index_from_flattened_index(cluster_2_flattened_index, N_rank, N_accum)\n",
    "            ## Preparation for local grouping\n",
    "            local_N_size = []\n",
    "            local_data_indexes = []\n",
    "            opt_local_grouping_indexes_list = []\n",
    "            ## local_N_size, local_data_indexes, opt_local_grouping_indexes_list, local_N_rank, local_N_accum, local_N_size_prod, local_marginal_mass_vectors\n",
    "            for local_group in range(N_rank):\n",
    "                if cluster_1_multi_index[local_group] == cluster_2_multi_index[local_group]:\n",
    "                    local_N_size.append(1)\n",
    "                    temp_index = new_grouping_indexes_list[local_group][cluster_1_multi_index[local_group]]\n",
    "                    local_data_indexes.append(temp_index)\n",
    "                    opt_local_grouping_indexes_list.append([temp_index])\n",
    "                else:\n",
    "                    local_N_size.append(2)\n",
    "                    temp_index_1 = new_grouping_indexes_list[local_group][cluster_1_multi_index[local_group]]\n",
    "                    temp_index_2 = new_grouping_indexes_list[local_group][cluster_2_multi_index[local_group]]\n",
    "                    local_data_indexes.append(temp_index_1)\n",
    "                    local_data_indexes.append(temp_index_2)\n",
    "                    opt_local_grouping_indexes_list.append([temp_index_1, temp_index_2])\n",
    "            local_N_size = tuple(local_N_size)\n",
    "            (local_N_rank, local_N_accum, local_N_size_prod) = get_N(local_N_size)\n",
    "            local_marginal_mass_vectors = calc_marginal_mass_vectors(local_N_rank, local_N_size)\n",
    "            ## Calculation of current local optimal transportation costs\n",
    "            (opt_local_adjusted_cost_value, opt_local_mean_cost_value, opt_local_deviation_cost_value,\n",
    "            opt_local_intragroup_cost_value, opt_local_intragroup_distance_nparray_list, opt_local_intragroup_adjacency_nparray_list, opt_local_intragroup_cost_list,\n",
    "            opt_local_intergroup_cost_value, opt_local_intergroup_P_tensor, opt_local_intergroup_weighted_cost_tensor,\n",
    "            opt_local_intergroup_u_vec_list, opt_local_intergroup_f_vec_list,\n",
    "            opt_local_intergroup_cost_tensor) = calc_adjusted_cost_value_with_mst(opt_local_grouping_indexes_list, data_points_nparray,\n",
    "                                                                                  local_marginal_mass_vectors,\n",
    "                                                                                  local_N_size, local_N_rank, local_N_accum, local_N_size_prod,\n",
    "                                                                                  mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                                                                                  numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "            old_local_adjusted_cost_value = opt_local_adjusted_cost_value\n",
    "            ## Enumeration of grouping patterns\n",
    "            ## (If N_rank is 2 or 3, all enumeration is used, and more than that, random selection is used.)\n",
    "            local_grouping_indexes_list_combinations = []\n",
    "            if local_N_rank == 2: ## It might be a good idea to have all the patterns ready in advance. (2^2-1=3)\n",
    "                numbers_list = list(range(sum(local_N_size)))\n",
    "                for sub_numbers_list_1 in itertools.combinations(numbers_list, local_N_size[0]):\n",
    "                    sub_numbers_list_2 = tuple(np.delete(numbers_list, sub_numbers_list_1, 0))\n",
    "                    temp_local_grouping_indexes_list = list((np.array(local_data_indexes))[list(sub_numbers_list_1+sub_numbers_list_2)])\n",
    "                    temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                    if temp_local_grouping_indexes_list != opt_local_grouping_indexes_list:\n",
    "                        local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            elif local_N_rank == 3: ## It might be a good idea to have all the patterns ready in advance. (2^3-1=7)\n",
    "                numbers_list = list(range(sum(local_N_size)))\n",
    "                for sub_numbers_list_1 in itertools.combinations(numbers_list, local_N_size[0]):\n",
    "                    temp_numbers_list = np.delete(numbers_list, sub_numbers_list_1, 0)\n",
    "                    for sub_numbers_list_2 in itertools.combinations(temp_numbers_list, local_N_size[1]):      \n",
    "                        sub_numbers_list_3 = tuple(np.delete(numbers_list, sub_numbers_list_1+sub_numbers_list_2, 0))\n",
    "                        temp_local_grouping_indexes_list = list((np.array(local_data_indexes))[list(sub_numbers_list_1+sub_numbers_list_2+sub_numbers_list_3)])\n",
    "                        temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                        if temp_local_grouping_indexes_list!= opt_local_grouping_indexes_list:\n",
    "                                local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            else:\n",
    "                for i in range(local_loop_max):\n",
    "                    temp_local_grouping_indexes_list = random.sample(local_data_indexes, len(local_data_indexes))\n",
    "                    temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                    if (temp_local_grouping_indexes_list!= opt_local_grouping_indexes_list) and (temp_local_grouping_indexes_list not in local_grouping_indexes_list_combinations):\n",
    "                                local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            ## Calculate the cost of local optimal transportation for each pattern of local grouping\n",
    "            opt_local_adjusted_cost_value = float('inf')\n",
    "            opt_local_grouping_indexes_list_list = []\n",
    "            for new_local_grouping_indexes_list in local_grouping_indexes_list_combinations:\n",
    "                (new_local_adjusted_cost_value, new_local_mean_cost_value, new_local_deviation_cost_value,\n",
    "                new_local_intragroup_cost_value, new_local_intragroup_distance_nparray_list, new_local_intragroup_adjacency_nparray_list, new_local_intragroup_cost_list,\n",
    "                new_local_intergroup_cost_value, new_local_intergroup_P_tensor, new_local_intergroup_weighted_cost_tenso,\n",
    "                new_local_intergroup_u_vec_list, new_local_intergroup_f_vec_list,\n",
    "                new_local_intergroup_cost_tensor) = calc_adjusted_cost_value_with_mst(new_local_grouping_indexes_list, data_points_nparray,\n",
    "                                                                                  local_marginal_mass_vectors,\n",
    "                                                                                  local_N_size, local_N_rank, local_N_accum, local_N_size_prod,\n",
    "                                                                                  mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                                                                                  numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "                if new_local_adjusted_cost_value < opt_local_adjusted_cost_value:\n",
    "                    opt_local_adjusted_cost_value = new_local_adjusted_cost_value\n",
    "                    opt_local_grouping_indexes_list_list = [new_local_grouping_indexes_list]\n",
    "                elif new_local_adjusted_cost_value == opt_local_adjusted_cost_value:\n",
    "                    opt_local_grouping_indexes_list_list.append(new_local_grouping_indexes_list)\n",
    "            opt_local_grouping_indexes_list = random.choice(opt_local_grouping_indexes_list_list)\n",
    "            random_number = random.random()\n",
    "            new_grouping_flag = (opt_local_adjusted_cost_value==0) or (random_number <= (old_local_adjusted_cost_value/opt_local_adjusted_cost_value))\n",
    "            if new_grouping_flag:\n",
    "                for group in range(local_N_rank):\n",
    "                    if local_N_size[group] == 1:\n",
    "                        new_grouping_indexes_list[group][cluster_1_multi_index[group]] = opt_local_grouping_indexes_list[group][0]\n",
    "                    else:\n",
    "                        new_grouping_indexes_list[group][cluster_1_multi_index[group]] = opt_local_grouping_indexes_list[group][0]\n",
    "                        new_grouping_indexes_list[group][cluster_2_multi_index[group]] = opt_local_grouping_indexes_list[group][1]\n",
    "        if new_grouping_flag:\n",
    "            ## Calculation of the cost of optimal transport\n",
    "            (new_adjusted_cost_value, new_mean_cost_value, new_deviation_cost_value,\n",
    "            new_intragroup_cost_value, new_intragroup_distance_nparray_list, new_intragroup_adjacency_nparray_list, new_intragroup_cost_list,\n",
    "            new_intergroup_cost_value, new_intergroup_P_tensor, \n",
    "            new_intergroup_weighted_cost_tensor, new_intergroup_u_vec_list, new_intergroup_f_vec_list, \n",
    "            new_intergroup_cost_tensor) = calc_adjusted_cost_value_with_mst(new_grouping_indexes_list, data_points_nparray,\n",
    "                                                                            marginal_mass_vectors,\n",
    "                                                                            N_size, N_rank, N_accum, N_size_prod,\n",
    "                                                                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                                                                            numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "        if show_info:\n",
    "            info_func(info_args, \"new_grouping_indexes_list: \" + str(new_grouping_indexes_list))\n",
    "            info_func(info_args, \"new_adjusted_cost_value: \" + str(new_adjusted_cost_value))\n",
    "        # if drawing_graphs:\n",
    "        #     (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "        #                                                 new_grouping_indexes_list, data_points_nparray, \n",
    "        #                                                 N_size, N_rank, N_accum, N_size_prod,\n",
    "        #                                                 viz2d_x, viz2d_y, new_intergroup_P_tensor)\n",
    "        #     # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "        #     #                             viz2d_x, viz2d_y, line_width = 1, f_size=(4,3,1), f_title=\"Mid-calculation\")\n",
    "        if new_adjusted_cost_value <= opt_adjusted_cost_value:\n",
    "            opt_grouping_indexes_list = copy.deepcopy(new_grouping_indexes_list)\n",
    "            opt_adjusted_cost_value = new_adjusted_cost_value\n",
    "            opt_mean_cost_value = new_mean_cost_value\n",
    "            opt_deviation_cost_value = new_deviation_cost_value\n",
    "            opt_intragroup_cost_value = new_intragroup_cost_value\n",
    "            opt_intergroup_cost_value = new_intergroup_cost_value\n",
    "            opt_intergroup_P_tensor = copy.deepcopy(new_intergroup_P_tensor)\n",
    "        ## Recording\n",
    "        iteration_number_list.append(loop+1)\n",
    "        elapsed_time = float(time.time() - start_time)\n",
    "        elapsed_time_list.append(elapsed_time)\n",
    "        new_adjusted_cost_trends_list.append(new_adjusted_cost_value)\n",
    "        opt_adjusted_cost_trends_list.append(opt_adjusted_cost_value)\n",
    "    ## info\n",
    "    if show_info:\n",
    "        info_func(info_args, \"---------- opt\")\n",
    "        info_func(info_args, \"opt_grouping_indexes_list: \" + str(init_grouping_indexes_list))\n",
    "        info_func(info_args, \"opt_adjusted_cost_value: \" + str(opt_adjusted_cost_value))\n",
    "        info_func(info_args, \"  (opt_intergroup_cost_value, opt_intragroup_cost_value: \" + str(opt_intergroup_cost_value) + \", \" + str(opt_intragroup_cost_value) + \")\")\n",
    "        info_func(info_args, \"  (mean_penalty_weight*opt_mean_cost_value, deviation_penalty_weight*opt_deviation_cost_value : \"\n",
    "              + str(mean_penalty_weight*opt_mean_cost_value) + \", \" + str(deviation_penalty_weight*opt_deviation_cost_value) + \")\")\n",
    "        ## Computation time\n",
    "        elapsed_hour = elapsed_time // 3600\n",
    "        elapsed_minute = (elapsed_time % 3600) // 60\n",
    "        elapsed_second = (elapsed_time % 3600 % 60)\n",
    "        info_func(info_args, \"computation time:\" + str(elapsed_hour).zfill(2) + \":\" + str(elapsed_minute).zfill(2) + \":\" + str(elapsed_second).zfill(2))\n",
    "    if drawing_graphs:\n",
    "        (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "                                            opt_grouping_indexes_list, data_points_nparray, \n",
    "                                            N_size, N_rank, N_accum, N_size_prod,\n",
    "                                            viz2d_x, viz2d_y, opt_intergroup_P_tensor)\n",
    "        # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, opt_grouping_indexes_list, data_points_nparray,\n",
    "        #                             viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "        show_P_tensor(opt_intergroup_P_tensor, N_size, N_rank, N_accum, f_size=(4,3), f_title=\"Optimal value\")\n",
    "     ## return\n",
    "    return (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "            opt_adjusted_cost_value,\n",
    "            opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "            opt_mean_cost_value, opt_deviation_cost_value,\n",
    "            iteration_number_list, elapsed_time_list,\n",
    "            new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "            viz2d_x, viz2d_y\n",
    "            )\n",
    "\n",
    "def gen_optimal_grouping_with_mst(data_points_nparray, N_size = None, standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 1.0,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## ## data_points_nparray: NumPy array consisting of data points\n",
    "    ## N_size: Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "    ## standardization = True ## Standardization\n",
    "    ## mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "    ## deviation_penalty_weight = 0.8 ## Weight of deviation_cost_value\n",
    "    ## order = 1.0 ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "    ## numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "    ## ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "    ## ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ## ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot\n",
    "    ## tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "    ## global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "    ## local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "    ## init_grouping_indexes_list = None ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## search_method = \"ex\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "    ## search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "    ## search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "    ## main_show_info = True ## Flag whether information is displayed or not\n",
    "    ## main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "    ## sub_show_info = False ## Flag whether information is displayed or not\n",
    "    ## sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "    ## info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "    ## info_args = None ## Arguments for info_func\n",
    "    ## tensor_size_max = 4000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "    ## group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "    ## loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "    ## viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## N_size\n",
    "    data_size = len(data_points_nparray)\n",
    "    if N_size is None:\n",
    "        info_func(info_args, \"Warning: N_size is None.\")\n",
    "        N_size = tuple(data_size)\n",
    "    if (type(N_size) == int):\n",
    "        if data_size > N_size:\n",
    "            (quotient, remainder) = divmod(data_size, N_size)\n",
    "            N_size = np.full(N_size, quotient)\n",
    "            for i in range(remainder):\n",
    "                N_size[i] = N_size[i] + 1\n",
    "            N_size = tuple(N_size)\n",
    "        else:\n",
    "            N_size = tuple(data_size)\n",
    "    elif (type(N_size) == tuple) or (type(N_size) == list):\n",
    "        N_size = tuple(N_size)\n",
    "        if data_size != sum(N_size):\n",
    "            info_func(info_args, \"Warning: The sum of N_size does not match sample size.\")\n",
    "            N_size = tuple(data_size)\n",
    "    else:\n",
    "        info_func(info_args, \"Warning: N_size must be of type integer or tuple.\")\n",
    "        N_size = tuple(data_size)\n",
    "    (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    res_calc_optimal_grouping = None\n",
    "    ## Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    ## Setting Parameters\n",
    "    if (N_size_prod > tensor_size_max) or (min(N_size) > group_size_max): ## If True, use \"approximate solution\".\n",
    "        ## Initial value settings\n",
    "        if init_grouping_indexes_list is None:\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "        else:\n",
    "            new_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "        if main_show_info:\n",
    "            info_func(info_args, \"---------- new_grouping_indexes_list (initial value): \" + str(new_grouping_indexes_list))\n",
    "        if main_drawing_graphs:\n",
    "            (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                        viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Initial value\")\n",
    "        for loop in range( loop_max_multiplier*N_rank ):\n",
    "            (group_1, group_2) = random.sample(list(range(N_rank)), 2)\n",
    "            sub_N_size = [N_size[group_1], N_size[group_2]]\n",
    "            group_1_sub_index = []\n",
    "            group_2_sub_index = []\n",
    "            if sub_N_size[0] > group_size_max:\n",
    "                group_1_sub_index = random.sample(list(range(sub_N_size[0])), group_size_max)\n",
    "                sub_N_size[0] = group_size_max\n",
    "            else:\n",
    "                group_1_sub_index = list(range(sub_N_size[0]))\n",
    "            if sub_N_size[1] > group_size_max:\n",
    "                group_2_sub_index = random.sample(list(range(sub_N_size[1])), group_size_max)\n",
    "                sub_N_size[1] = group_size_max\n",
    "            else:\n",
    "                group_2_sub_index = list(range(sub_N_size[1]))\n",
    "            sub_N_size = tuple(sub_N_size)\n",
    "            sub_data_index = list(np.array(new_grouping_indexes_list[group_1])[group_1_sub_index]) + list(np.array(new_grouping_indexes_list[group_2])[group_2_sub_index])\n",
    "            sub_data_points_nparray = data_points_nparray[sub_data_index]\n",
    "            (sub_N_rank, sub_N_accum, sub_N_size_prod) = get_N(sub_N_size)\n",
    "            res_calc_optimal_grouping = calc_optimal_grouping_with_mst(\n",
    "                sub_data_points_nparray, sub_N_size,\n",
    "                sub_N_rank, sub_N_accum, sub_N_size_prod,\n",
    "                mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                numerical_precision,\n",
    "                ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                None, True, ## init_grouping_indexes_list, init_grouping_rand,\n",
    "                search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                sub_show_info, sub_drawing_graphs,\n",
    "                info_func,\n",
    "                info_args,\n",
    "                viz2d_x, viz2d_y)\n",
    "            sub_opt_grouping_indexes_list = res_calc_optimal_grouping[0]\n",
    "            group_1_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[0]])\n",
    "            group_2_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[1]])\n",
    "            for i, index in enumerate(group_1_sub_index):\n",
    "                new_grouping_indexes_list[group_1][index] = group_1_sub_grouping_indexes_list[i]\n",
    "            for i, index in enumerate(group_2_sub_index):\n",
    "                new_grouping_indexes_list[group_2][index] = group_2_sub_grouping_indexes_list[i]\n",
    "            if main_show_info:\n",
    "                info_func(info_args, \"---------- loop (partial optimization): \" + str(loop+1))\n",
    "                info_func(info_args, \"---------- new_grouping_indexes_list (partial optimization): \" + str(new_grouping_indexes_list))\n",
    "            if (main_drawing_graphs) and (loop == (2*N_rank-1)):\n",
    "                (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                            viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "        res_calc_optimal_grouping = (new_grouping_indexes_list, \n",
    "                                     None, # opt_intergroup_P_tensor,\n",
    "                                     None, # opt_adjusted_cost_value,\n",
    "                                     None, # opt_intergroup_cost_value,\n",
    "                                     None, # opt_intragroup_cost_value,\n",
    "                                     None, # opt_mean_cost_value,\n",
    "                                     None, # opt_deviation_cost_value,\n",
    "                                     None, # iteration_number_list,\n",
    "                                     None, # elapsed_time_list,\n",
    "                                     None, # new_adjusted_cost_trends_list,\n",
    "                                     None, # opt_adjusted_cost_trends_list,\n",
    "                                     viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_mst(data_points_nparray, N_size,\n",
    "                            N_rank, N_accum, N_size_prod,\n",
    "                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_indexes_list, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            info_func,\n",
    "                            info_args,\n",
    "                            viz2d_x, viz2d_y)\n",
    "    ## res_calc_optimal_grouping:\n",
    "    ## (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "    ##  opt_adjusted_cost_value,\n",
    "    ##  opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "    ##  opt_mean_cost_value, opt_deviation_cost_value,\n",
    "    ##  iteration_number_list, elapsed_time_list,\n",
    "    ##  new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "    ##  viz2d_x, viz2d_y)\n",
    "    return res_calc_optimal_grouping\n",
    "\n",
    "def gen_optimal_grouping_from_csv_file_with_mst(input_filepath= \"./members.csv\", input_index_col = 0, output_filepath = \"./grouping.csv\",\n",
    "                           N_size = None,\n",
    "                           standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 1.0,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## input_filepath = \"./members.csv\" ## File path of the input file, in csv format.\n",
    "    ## input_index_col = 0 ## Column number with column name or column number in the csv file\n",
    "    ## output_filepath = \"./grouping.csv\" ##  File path of the output file, in csv format.\n",
    "    ############################\n",
    "    ## Loading data: loading csv files\n",
    "    df = pd.read_csv(filepath_or_buffer=input_filepath, index_col=input_index_col)\n",
    "    output_data = copy.deepcopy(df)\n",
    "    data_size = len(df)\n",
    "    ############################\n",
    "    ## Dummy variable processing: dummy variable for columns where dtype is object\n",
    "    df = pd.get_dummies(df, drop_first=True, dtype=\"float\") # float64, uint8, bool\n",
    "    ############################\n",
    "    ##  Handling missing values: interpolate by median\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    ############################\n",
    "    ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray_org = np.array(df.values)\n",
    "    data_points_nparray = copy.deepcopy(data_points_nparray_org) ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray = data_points_nparray.astype(float)\n",
    "    ###########################################\n",
    "    ## Data Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    ###########################################\n",
    "    ## Division and Search\n",
    "    (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "     opt_adjusted_cost_value,\n",
    "     opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "     opt_mean_cost_value, opt_deviation_cost_value,\n",
    "     iteration_number_list, elapsed_time_list,\n",
    "     new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "     viz2d_x, viz2d_y\n",
    "    ) = gen_optimal_grouping_with_mst(data_points_nparray, N_size, standardization,\n",
    "                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_indexes_list, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            sub_show_info, sub_drawing_graphs,\n",
    "                            info_func, info_args,\n",
    "                            tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                            viz2d_x, viz2d_y)\n",
    "    ###########################################\n",
    "    ## Output grouping results to csv file\n",
    "    group_labels_list = np.zeros(data_size)\n",
    "    group = 0\n",
    "    for members_list in opt_grouping_indexes_list:\n",
    "        for member in members_list:\n",
    "            group_labels_list[member] = int(group)\n",
    "        group = group + 1\n",
    "    output_data.insert(loc=0, column=\"Group\", value=group_labels_list.astype(int), allow_duplicates=True)\n",
    "    if (viz2d_x is not None) and (viz2d_y is not None):\n",
    "        output_data.insert(loc=1, column=\"viz2d_x\", value=viz2d_x.astype(float), allow_duplicates=True)\n",
    "        output_data.insert(loc=2, column=\"viz2d_y\", value=viz2d_y.astype(float), allow_duplicates=True)\n",
    "    output_data.to_csv(output_filepath)\n",
    "    ###########################################\n",
    "    ## Return\n",
    "    return (opt_grouping_indexes_list,\n",
    "            opt_intergroup_P_tensor,\n",
    "            opt_adjusted_cost_value,\n",
    "            opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "            opt_mean_cost_value, opt_deviation_cost_value,\n",
    "            iteration_number_list, elapsed_time_list,\n",
    "            new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "            output_data, viz2d_x, viz2d_y\n",
    "    )\n",
    "\n",
    "## Functions for calculating optrimal grouping\n",
    "\n",
    "def calc_optimal_grouping(data_points_nparray, N_size,\n",
    "                           N_rank = None, N_accum = None, N_size_prod = None,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.8,\n",
    "                           cost_type = \"mst\", order = None,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 10, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           show_info = False, drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    res_calc_optimal_grouping = None\n",
    "    if (cost_type == \"mst\"):\n",
    "        if(order == None):\n",
    "            order = 1.0\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_mst(data_points_nparray, N_size,\n",
    "                           N_rank, N_accum, N_size_prod,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           show_info, drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    elif(cost_type == \"bc\"):\n",
    "        if(order == None):\n",
    "            order = 2.0\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_bc(data_points_nparray, N_size,\n",
    "                           N_rank, N_accum, N_size_prod,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           show_info, drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        cost_type = \"mst\"\n",
    "        order = 1.0\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_mst(data_points_nparray, N_size,\n",
    "                           N_rank, N_accum, N_size_prod,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           show_info, drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    return res_calc_optimal_grouping\n",
    "\n",
    "def gen_optimal_grouping(data_points_nparray, N_size = None, standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1,\n",
    "                           cost_type = \"mst\", order = None,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## ## data_points_nparray: NumPy array consisting of data points\n",
    "    ## N_size: Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "    ## standardization = True ## Standardization\n",
    "    ## mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "    ## deviation_penalty_weight = 0.8 ## Weight of deviation_cost_value\n",
    "    ## cost_type = \"mst\" ## \"mst\": minimum spanning tree, \"bc\": barycenter\n",
    "    ## order = None ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "    ## numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "    ## ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "    ## ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ## ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot\n",
    "    ## tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "    ## global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "    ## local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "    ## init_grouping_indexes_list = None ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## search_method = \"ex\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "    ## search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "    ## search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "    ## main_show_info = True ## Flag whether information is displayed or not\n",
    "    ## main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "    ## sub_show_info = False ## Flag whether information is displayed or not\n",
    "    ## sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "    ## info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "    ## info_args = None ## Arguments for info_func\n",
    "    ## tensor_size_max = 4000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "    ## group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "    ## loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "    ## viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## N_size\n",
    "    res_gen_optimal_grouping = None\n",
    "    if (cost_type == \"mst\"):\n",
    "        if(order == None):\n",
    "            order = 1.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_with_mst(data_points_nparray, N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    elif(cost_type == \"bc\"):\n",
    "        if(order == None):\n",
    "            order = 2.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_with_bc(data_points_nparray, N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        cost_type = \"mst\"\n",
    "        order = 1.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_with_mst(data_points_nparray, N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    return res_gen_optimal_grouping\n",
    "\n",
    "def gen_optimal_grouping_from_csv_file(input_filepath= \"./members.csv\", input_index_col = 0, output_filepath = \"./grouping.csv\",\n",
    "                           N_size = None,\n",
    "                           standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1,\n",
    "                           cost_type = \"mst\", order = None,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## input_filepath = \"./members.csv\" ## File path of the input file, in csv format.\n",
    "    ## input_index_col = 0 ## Column number with column name or column number in the csv file\n",
    "    ## output_filepath = \"./grouping.csv\" ##  File path of the output file, in csv format.\n",
    "    res_gen_optimal_grouping = None\n",
    "    if (cost_type == \"mst\"):\n",
    "        if(order == None):\n",
    "            order = 1.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_from_csv_file_with_mst(input_filepath, input_index_col, output_filepath,\n",
    "                           N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    elif(cost_type == \"bc\"):\n",
    "        if(order == None):\n",
    "            order = 2.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_from_csv_file_with_bc(input_filepath, input_index_col, output_filepath,\n",
    "                           N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        cost_type = \"mst\"\n",
    "        order = 1.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_from_csv_file_with_mst(input_filepath, input_index_col, output_filepath,\n",
    "                           N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    return res_gen_optimal_grouping\n",
    "\n",
    "## Functions for displaying information and drawing graphs\n",
    "\n",
    "def cprint(txt, color=\"BRIGHT_CYAN\", end=\"\\n\"):\n",
    "    if os.name == 'nt':\n",
    "        COLORS = {\n",
    "        \"BLACK\": \"\\033[30m\",\n",
    "        \"RED\": \"\\033[31m\",\n",
    "        \"GREEN\": \"\\033[32m\",\n",
    "        \"YELLOW\": \"\\033[33m\",\n",
    "        \"BLUE\": \"\\033[34m\",\n",
    "        \"MAGENTA\": \"\\033[35m\",\n",
    "        \"CYAN\": \"\\033[36m\",\n",
    "        \"WHITE\": \"\\033[37m\",\n",
    "        \"DEFAULT_COLOR\": \"\\033[39m\",\n",
    "        \"GRAY\": \"\\033[90m\",\n",
    "        \"BRIGHT_RED\": \"\\033[91m\",\n",
    "        \"BRIGHT_GREEN\": \"\\033[92m\",\n",
    "        \"BRIGHT_YELLOW\": \"\\033[93m\",\n",
    "        \"BRIGHT_BLUE\": \"\\033[94m\",\n",
    "        \"BRIGHT_MAGENTA\": \"\\033[95m\",\n",
    "        \"BRIGHT_CYAN\": \"\\033[96m\",\n",
    "        \"BRIGHT_WHITE\": \"\\033[97m\",\n",
    "        }\n",
    "        END = \"\\033[0m\"\n",
    "        print(COLORS[color] + txt + END, end=end)\n",
    "    else:\n",
    "        print(txt)\n",
    "\n",
    "def get_rank_vec(v):\n",
    "    n = len(v)\n",
    "    rank = [0]*n\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if v[i]>v[j]:\n",
    "                rank[j] = rank[j] + 1\n",
    "            else:\n",
    "                rank[i] = rank[i] + 1\n",
    "    return rank\n",
    "\n",
    "def get_points_list_in_non_intersecting_order(x, y):\n",
    "    n = len(x)\n",
    "    qcos_vec = [0]*n\n",
    "    reference_index = y.index(min(y))\n",
    "    qcos_vec[reference_index] = 2\n",
    "    indices_rem = (list(range(n)))\n",
    "    indices_rem.pop(reference_index)\n",
    "    range_x = max(x)-min(x)\n",
    "    for i in indices_rem:\n",
    "        dx = (x[i]-x[reference_index])\n",
    "        dy = (y[i]-y[reference_index])\n",
    "        dr = math.sqrt(dx*dx + dy*dy)\n",
    "        if dr == 0:\n",
    "            qcos_vec[i] = 2\n",
    "        elif dx == dr:\n",
    "            qcos_vec[i] = 2 - dx/range_x\n",
    "        elif dx == -dr:\n",
    "            qcos_vec[i] = -2 - dx/range_x\n",
    "        else:\n",
    "            qcos_vec[i] = dx/dr\n",
    "    rank_cos = get_rank_vec(qcos_vec)\n",
    "    points = [[]]*n\n",
    "    for i in range(n):\n",
    "        points[rank_cos[i]] = [x[i], y[i]]\n",
    "    return points\n",
    "\n",
    "def show_P_tensor(P_tensor, N_size, N_rank, N_accum, f_size=(6,4), numerical_precision=1e-8, f_title=\"\"):\n",
    "    ## Draw the graph of the tensor of the solution of the grouping\n",
    "    ## The horizontal axis is the groups (1～N_rank) and the vertical axis is the number of elements belonging to each group (N_size).\n",
    "    ## A single line corresponds to one element of the tensor. The higher the value, the thicker the line.\n",
    "    ## ------------------------------\n",
    "    ## Visualization of P_tensor\n",
    "    x = list(range(N_rank))\n",
    "    x = [element+1 for element in x]\n",
    "    fig = plt.figure(figsize = (f_size[0], f_size[1]), facecolor=\"mistyrose\")\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(f_title)\n",
    "    ax.set_xlim((0, N_rank+1))\n",
    "    ax.set_ylim((0, max(N_size)+1))\n",
    "    P_max = max(P_tensor)\n",
    "    for m_index in np.ndindex(tuple(N_size)):\n",
    "        temp_y = list(m_index)\n",
    "        temp_y = [element+1 for element in temp_y]\n",
    "        temp_P_ratio = P_tensor[get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)] / (P_max + numerical_precision)\n",
    "        lwd = 10*math.sqrt(temp_P_ratio) # 10 * math.log( math.exp(1) - 1 + temp_P_ratio　)\n",
    "        ax.plot(x, temp_y, linewidth=lwd, alpha=0.5)\n",
    "\n",
    "def gen_2d_data(is_umap_loaded, data_points_nparray):\n",
    "    if len(data_points_nparray[0,:]) > 2:\n",
    "        if is_umap_loaded:\n",
    "            ## Umap\n",
    "            print(\"Umapping...\", flush=\"True\")\n",
    "            mapper = umap.UMAP(random_state=0)\n",
    "            embedding = mapper.fit_transform(data_points_nparray)\n",
    "            return (embedding[:,0], embedding[:,1])\n",
    "        else:\n",
    "            print(\"For two-dimensional visualization, use only the first and second variables.\")\n",
    "            return (data_points_nparray[:,0], data_points_nparray[:,1])\n",
    "    elif len(data_points_nparray[0,:]) == 2:\n",
    "        return (data_points_nparray[:,0], data_points_nparray[:,1])\n",
    "    elif len(data_points_nparray[0,:]) == 1:\n",
    "        return (data_points_nparray[:,0], np.zeros(len(data_points_nparray[:,0])))\n",
    "    else:\n",
    "        return ([0], [0])\n",
    "\n",
    "def show_2d_data(is_umap_loaded, grouping_indexes_list, data_points_nparray,\n",
    "                 viz2d_x = None, viz2d_y = None, line_width = 1, f_size=(8,6,4), f_title=\"\"):\n",
    "    ## Visualization of two-dimensional data\n",
    "    ## Each group is arranged in order of starting point (tau) to ending point (nu).\n",
    "    len_data_points_nparray = len(data_points_nparray)\n",
    "    if len_data_points_nparray > 20:\n",
    "        line_width = 0\n",
    "    if grouping_indexes_list is None:\n",
    "        grouping_indexes_list = [list(range(len_data_points_nparray))]\n",
    "    if (viz2d_x is None) or (viz2d_y is None):\n",
    "        viz2d_x, viz2d_y = gen_2d_data(is_umap_loaded, data_points_nparray)\n",
    "    x_min = min(viz2d_x)\n",
    "    x_max = max(viz2d_x)\n",
    "    x_range = x_max - x_min\n",
    "    y_min = 0\n",
    "    y_max = 0\n",
    "    y_range = 0\n",
    "    if len(data_points_nparray[0,:]) > 1:\n",
    "        viz2d_y = viz2d_y\n",
    "        y_min = min(viz2d_y)\n",
    "        y_max = max(viz2d_y)\n",
    "        y_range = y_max - y_min\n",
    "    figsize_x = f_size[0]\n",
    "    figsize_y = f_size[1]\n",
    "    if max(x_range, y_range) <= 0:\n",
    "        figsize_x = f_size[0]\n",
    "        figsize_y = f_size[1]\n",
    "    elif x_range > y_range:\n",
    "        figsize_x = f_size[0]\n",
    "        figsize_y = max(f_size[2] ,min(f_size[1], f_size[1]*(y_range/x_range)))\n",
    "    else:\n",
    "        figsize_y = f_size[1]\n",
    "        figsize_x = max(f_size[2] ,min(f_size[1], f_size[1]*(x_range/y_range)))\n",
    "    fig = plt.figure(figsize = (figsize_x, figsize_y), facecolor=\"mistyrose\")\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim((x_min-2, x_max+2))\n",
    "    ax.set_ylim((y_min-2, y_max+2))\n",
    "    colors = cm.tab10 # cm.tab20\n",
    "    len_colors = 10\n",
    "    markers = [\"o\", \"^\", \"s\", \"p\", \"D\", \"H\", \"*\", \"v\", \"<\", \">\",  \n",
    "                \"+\", \"x\", \".\", \",\", \"d\", \"h\", \"1\", \"2\", \"3\", \"4\", \"8\", \"|\", \"_\"]\n",
    "    for group, index_list in enumerate(grouping_indexes_list):\n",
    "        if len(index_list)>0:\n",
    "            x = []\n",
    "            y = []\n",
    "            x_start = [] # Starting point: tau\n",
    "            y_start = [] # Starting point: tau\n",
    "            x_end = [] # Ending point: nu\n",
    "            y_end = [] # Ending point: nu\n",
    "            p_color = colors(int(group)%len_colors)\n",
    "            p_marker = markers[int(group)%len(markers)]\n",
    "            for j, element in enumerate(index_list):\n",
    "                x.append(viz2d_x[element])\n",
    "                y.append(viz2d_y[element])\n",
    "                if j==0:\n",
    "                    x_start = [viz2d_x[element]]\n",
    "                    y_start = [viz2d_y[element]]\n",
    "                elif j==(len(index_list)-1):\n",
    "                    x_end = [viz2d_x[element]]\n",
    "                    y_end = [viz2d_y[element]]\n",
    "            ax.plot(x, y, alpha=0.5, color=p_color, marker=p_marker, markersize=12, linewidth=line_width)\n",
    "            ax.set_title(f_title)\n",
    "            if line_width > 0:\n",
    "                ## Starting point: tau\n",
    "                ax.plot(x_start, y_start, alpha=0.5, marker=\"$\\\\tau$\", markersize=6, color=\"black\")\n",
    "                ## Ending point: nu\n",
    "                ax.plot(x_end, y_end, alpha=0.5, marker=\"$\\\\nu$\", markersize=6, color=\"black\")\n",
    "    return (fig, ax, viz2d_x, viz2d_y)\n",
    "\n",
    "def show_2d_data_with_patches(is_umap_loaded, grouping_indexes_list, data_points_nparray, \n",
    "                              N_size, N_rank, N_accum, N_size_prod,\n",
    "                              viz2d_x = None, viz2d_y = None, patch_weight = None, line_width = 1, f_size=(8,6,4), f_title=\"\"):\n",
    "    (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, grouping_indexes_list, data_points_nparray,\n",
    "                                               viz2d_x, viz2d_y,\n",
    "                                               line_width = 1, f_size=(8,6,4), f_title=\"\")\n",
    "    if patch_weight is not None:\n",
    "        patch_weight_max = max(patch_weight)\n",
    "        if patch_weight_max > 0:\n",
    "            if (N_rank is None) or (N_accum is None) or (N_size_prod is None):\n",
    "                (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "            for m_index in np.ndindex(N_size):\n",
    "                w = get_tensor_value_from_multi_index(patch_weight, m_index, N_rank, N_accum)\n",
    "                alp = w / patch_weight_max\n",
    "                alp = 0.5 * alp / N_rank\n",
    "                if alp > 0.001:\n",
    "                    x_vec = []\n",
    "                    y_vec = []\n",
    "                    for group in range(N_rank):\n",
    "                        index_value = grouping_indexes_list[group][m_index[group]]\n",
    "                        x_vec.append(viz2d_x[index_value])\n",
    "                        y_vec.append(viz2d_y[index_value])\n",
    "                    if N_rank > 2:\n",
    "                        points = get_points_list_in_non_intersecting_order(x_vec, y_vec)\n",
    "                        patch = patches.Polygon(xy=points, closed=True, alpha=alp, color='black')\n",
    "                        ax.add_patch(patch)\n",
    "                    elif N_rank == 2:\n",
    "                        ax.plot(x_vec, y_vec, alpha=alp, color='black',\n",
    "                                marker=None, linestyle='solid', linewidth=2)\n",
    "    return (fig, ax, viz2d_x, viz2d_y)\n",
    "\n",
    "def get_argmax_list(target_tensor, fixed_group_list, fixed_element_list, \n",
    "                    N_size, N_rank, N_accum):\n",
    "    N_size_partially_fixed = copy.deepcopy(N_size)\n",
    "    N_size_partially_fixed = list(N_size_partially_fixed)\n",
    "    if (len(fixed_group_list)!=0) and (len(fixed_group_list)==len(fixed_element_list)):\n",
    "        for group in fixed_group_list:\n",
    "            N_size_partially_fixed[group] = 1\n",
    "    N_size_partially_fixed = tuple(N_size_partially_fixed)\n",
    "    temp_max = 0\n",
    "    argmax_list = []\n",
    "    for m_index in np.ndindex(N_size_partially_fixed):\n",
    "        m_index_list = list(m_index)\n",
    "        if (len(fixed_group_list)!=0) and (len(fixed_group_list)==len(fixed_element_list)):\n",
    "            for element, group in enumerate(fixed_group_list):\n",
    "                m_index_list[group] = fixed_element_list[element]\n",
    "        temp_value = target_tensor[get_tensor_flattened_index_from_multi_index(m_index_list, N_rank, N_accum)]\n",
    "        if temp_value == temp_max:\n",
    "            argmax_list.append(m_index_list)\n",
    "        elif temp_value > temp_max:\n",
    "            temp_max = temp_value\n",
    "            argmax_list = [m_index_list]\n",
    "    return argmax_list\n",
    "\n",
    "def get_marginal_value(target_tensor, fixed_group_list, fixed_element_list, \n",
    "                       N_size, N_rank, N_accum):\n",
    "    N_size_partially_fixed = copy.deepcopy(N_size)\n",
    "    N_size_partially_fixed = list(N_size_partially_fixed)\n",
    "    if (len(fixed_group_list)!=0) and (len(fixed_group_list)==len(fixed_element_list)):\n",
    "        for group in fixed_group_list:\n",
    "            N_size_partially_fixed[group] = 1\n",
    "    N_size_partially_fixed = tuple(N_size_partially_fixed)\n",
    "    marginal_value = 0\n",
    "    for m_index in np.ndindex(N_size_partially_fixed):\n",
    "        m_index_list = list(m_index)\n",
    "        if (len(fixed_group_list)!=0) and (len(fixed_group_list)==len(fixed_element_list)):\n",
    "            for element, group in enumerate(fixed_group_list):\n",
    "                m_index_list[group] = fixed_element_list[element]\n",
    "        temp_value = target_tensor[get_tensor_flattened_index_from_multi_index(m_index_list, N_rank, N_accum)]\n",
    "        marginal_value = marginal_value + temp_value\n",
    "    return marginal_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program usage examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Example of optimization execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting arguments\n",
    "data_points_nparray = np.array( # List consisting of data points\n",
    "    [\n",
    "        [0.0, 0.0], [0.0,10.0], [0.0,20.0], [0.0,30.0], [0.0,40.0],\n",
    "        [1.0, 0.0], [1.0,10.0], [1.0,20.0], [1.0,30.0], [1.0,40.0],\n",
    "        [2.0, 0.0], [2.0,10.0], [2.0,20.0], [2.0,30.0], [2.0,40.0],\n",
    "        [3.0, 0.0], [3.0,10.0], [3.0,20.0], [3.0,30.0]\n",
    "    ]\n",
    "    )\n",
    "N_size = (5, 5, 5, 4) # Tensor dimensions: n1, n2, n3, ... : tuple consisting of the number of data belonging to each group\n",
    "standardization = True ## Standardization\n",
    "mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "deviation_penalty_weight = 0.1 ## Weight of deviation_cost_value\n",
    "cost_type = \"mst\" ## \"mst\": minimum spanning tree, \"bc\": barycenter\n",
    "order = 1.0 ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot\n",
    "tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "init_grouping_index = None ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "search_method = \"hybrid\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "main_show_info = True ## Flag whether information is displayed or not\n",
    "main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "sub_show_info = False ## Flag whether information is displayed or not\n",
    "sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "info_args = None ## Arguments for info_func\n",
    "tensor_size_max = 4000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "## Division and Search\n",
    "(opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    " opt_adjusted_cost_value,\n",
    " opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    " opt_mean_cost_value, opt_deviation_cost_value,\n",
    " iteration_number_list, elapsed_time_list,\n",
    " new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    " viz2d_x, viz2d_y\n",
    ") = gen_optimal_grouping(data_points_nparray,  N_size, standardization,\n",
    "                          mean_penalty_weight, deviation_penalty_weight,\n",
    "                          cost_type, order,\n",
    "                          numerical_precision,\n",
    "                          ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                          tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                          init_grouping_index, init_grouping_rand,\n",
    "                          search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                          main_show_info, main_drawing_graphs,\n",
    "                          sub_show_info, sub_drawing_graphs,\n",
    "                          info_func, info_args,\n",
    "                          tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                          viz2d_x, viz2d_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Reading data from a file and outputting calculation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting arguments\n",
    "input_filepath = \"./members.csv\" ## File path of the input file, in csv format.\n",
    "input_index_col = 0 ## Column number with column name or column number in the csv file\n",
    "output_filepath = \"./grouping.\" + (datetime.datetime.now()).strftime('%Y%m%d%H%M%S') + \".csv\" ##  File path of the output file, in csv format.\n",
    "N_size = 3  ## N_size: Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "standardization = True ## Standardization\n",
    "mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "deviation_penalty_weight = 0.1 ## Weight of deviation_cost_value\n",
    "cost_type = \"mst\" ## \"mst\": minimum spanning tree, \"bc\": barycenter\n",
    "order = 1.0 ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot\n",
    "tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "init_grouping_index = None ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "search_method = \"ex\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "main_show_info = True ## Flag whether information is displayed or not\n",
    "main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "sub_show_info = False ## Flag whether information is displayed or not\n",
    "sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "info_args = None ## Arguments for info_func\n",
    "tensor_size_max = 4000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "## Generating grouping from csv file\n",
    "(opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "    opt_adjusted_cost_value,\n",
    "    opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "    opt_mean_cost_value, opt_deviation_cost_value,\n",
    "    iteration_number_list, elapsed_time_list,\n",
    "    new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "    output_data, viz2d_x, viz2d_y\n",
    "    ) = gen_optimal_grouping_from_csv_file(input_filepath, input_index_col, output_filepath,\n",
    "                             N_size, standardization,\n",
    "                             mean_penalty_weight, deviation_penalty_weight,\n",
    "                             cost_type, order,\n",
    "                             numerical_precision,\n",
    "                             ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                             tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                             init_grouping_index, init_grouping_rand,\n",
    "                             search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                             main_show_info, main_drawing_graphs,\n",
    "                             sub_show_info, sub_drawing_graphs,\n",
    "                             info_func, info_args,\n",
    "                             tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                             viz2d_x, viz2d_y)\n",
    "print(output_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Comparison of optimization methods\n",
    "Comparison of methods: random sampling, exchange algorithm and their hybrid methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Data examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data examples ##\n",
    "\n",
    "# ## Data Example 1\n",
    "# N_size = (2, 2) # Tensor dimensions: n1, n2, n3, ... : tuple consisting of the number of data belonging to each group\n",
    "# data_points_nparray = np.array( # List consisting of data points\n",
    "#     [\n",
    "#         [0.0], [10.0],\n",
    "#         [1.0], [11.0]\n",
    "#     ]\n",
    "#     )\n",
    "\n",
    "# ## Data Example 2\n",
    "# N_size = (4, 4) # Tensor dimensions: n1, n2, n3, ... : tuple consisting of the number of data belonging to each group\n",
    "# data_points_nparray = np.array( # List consisting of data points\n",
    "#     [\n",
    "#         [0.0, 0.0], [1.0, 0.0], [20.0, 0.0], [21.0, 0.0], \n",
    "#         [0.0,10.0], [1.0,10.0], [20.0, 10.0], [21.0, 10.0]\n",
    "#     ]\n",
    "#     )\n",
    "\n",
    "# ## Data Example 3\n",
    "# N_size = (3, 3, 3) # Tensor dimensions: n1, n2, n3, ... : tuple consisting of the number of data belonging to each group\n",
    "# data_points_nparray = np.array( # List consisting of data points\n",
    "#     [\n",
    "#         [0.0, 0.0], [0.0,10.0], [0.0,20.0],\n",
    "#         [1.0, 0.0], [1.0,10.0], [1.0,20.0],\n",
    "#         [2.0, 0.0], [2.0,10.0], [2.0,20.0]\n",
    "#     ]\n",
    "#     )\n",
    "\n",
    "# ## Data Example 4\n",
    "# N_size = (5, 5, 5, 5) # Tensor dimensions: n1, n2, n3, ... : tuple consisting of the number of data belonging to each group\n",
    "# data_points_nparray = np.array( # List consisting of data points\n",
    "#     [\n",
    "#         [0.0, 0.0], [0.0,10.0], [0.0,20.0], [0.0,30.0], [0.0,40.0],\n",
    "#         [1.0, 0.0], [1.0,10.0], [1.0,20.0], [1.0,30.0], [1.0,40.0],\n",
    "#         [2.0, 0.0], [2.0,10.0], [2.0,20.0], [2.0,30.0], [2.0,40.0],\n",
    "#         [3.0, 0.0], [3.0,10.0], [3.0,20.0], [3.0,30.0], [3.0,40.0]\n",
    "#     ]\n",
    "#     )\n",
    "\n",
    "# ## Data Example 5\n",
    "# N_size = (1, 4) # Tensor dimensions: n1, n2, n3, ... : tuple consisting of the number of data belonging to each group\n",
    "# data_points_nparray = np.array( # List consisting of data points\n",
    "#     [\n",
    "#         [-1.0, 10.0], [1.0, 10.0], \n",
    "#         [0.0, 0.0], \n",
    "#         [-1.0, -10.0], [1.0, -10.0]\n",
    "#     ]\n",
    "#     )\n",
    "\n",
    "# ## Data Example 6\n",
    "# N_size = (2, 8) # Tensor dimensions: n1, n2, n3, ... : tuple consisting of the number of data belonging to each group\n",
    "# data_points_nparray = np.array( # List consisting of data points\n",
    "#     [\n",
    "#         [-11.0, 10.0], [-10.0, 10.0], [0.0, 10.0], \n",
    "#         [ 10.0, 10.0], [ 11.0, 10.0], \n",
    "#         [-11.0,-10.0], [-10.0,-10.0], [0.0,-10.0], [10.0,-10.0], [11.0,-10.0]\n",
    "#     ]\n",
    "#     )\n",
    "\n",
    "## Data Example 7\n",
    "N_size = (5, 5, 5, 4) # Tensor dimensions: n1, n2, n3, ... : tuple consisting of the number of data belonging to each group\n",
    "data_points_nparray = np.array( # List consisting of data points\n",
    "    [\n",
    "        [0.0, 0.0], [0.0, 10.0], [0.0, 20.0], [0.0, 30.0], [0.0, 40.0],\n",
    "        [1.0, 0.0], [1.0, 10.0], [1.0, 20.0], [1.0, 30.0], [1.0, 40.0],\n",
    "        [2.0, 0.0], [2.0, 10.0], [2.0, 20.0], [2.0, 30.0], [2.0, 40.0],\n",
    "        [3.0, 0.0], [3.0, 10.0], [3.0, 20.0], [3.0, 30.0]\n",
    "    ]\n",
    "    )\n",
    "\n",
    "# ## Data Example 8\n",
    "# N_size = (5, 5, 5, 5, 4) # Tensor dimensions: n1, n2, n3, ... : tuple consisting of the number of data belonging to each group\n",
    "# data_points_nparray = np.array( # List consisting of data points\n",
    "#     [\n",
    "#         [0.0, 0.0], [0.0, 10.0], [0.0, 20.0], [0.0, 30.0], [0.0, 40.0],\n",
    "#         [1.0, 0.0], [1.0, 10.0], [1.0, 20.0], [1.0, 30.0], [1.0, 40.0],\n",
    "#         [2.0, 0.0], [2.0, 10.0], [2.0, 20.0], [2.0, 30.0], [2.0, 40.0],\n",
    "#         [3.0, 0.0], [3.0, 10.0], [3.0, 20.0], [3.0, 30.0], [3.0, 40.0],\n",
    "#         [4.0, 0.0], [4.0, 10.0], [4.0, 20.0], [4.0, 30.0] \n",
    "#     ]\n",
    "#     )\n",
    "\n",
    "# ## Data Example 9\n",
    "# N_size = (30, 30) # Tensor dimensions: n1, n2, n3, ... : tuple consisting of the number of data belonging to each group\n",
    "# ## Mixed multivariate normal distribution\n",
    "# mean_1 = np.array([0.0, 0.0])\n",
    "# cov_1 = np.array([[4.0, 0.0], [0.0, 4.0]])\n",
    "# mean_2 = np.array([4.0, 4.0])\n",
    "# cov_2 = np.array([[4.0, 0.0], [0.0, 4.0]])\n",
    "# data_1 = np.random.multivariate_normal(mean_1, cov_1, size=N_size[0])\n",
    "# data_2 = np.random.multivariate_normal(mean_2, cov_2, size=N_size[1])\n",
    "# data_points_nparray = np.array( np.concatenate([data_1, data_2]) ) # List consisting of data points\n",
    "\n",
    "# ## Data Example 10\n",
    "# N_size = (100, 100, 100) # Tensor dimensions: n1, n2, n3, ... : tuple consisting of the number of data belonging to each group\n",
    "# ## Mixed multivariate normal distribution\n",
    "# mean_1 = np.array([0.0, 0.0])\n",
    "# cov_1 = np.array([[4.0, 0.0], [0.0, 4.0]])\n",
    "# mean_2 = np.array([4.0, 0.0])\n",
    "# cov_2 = np.array([[4.0, 0.0], [0.0, 4.0]])\n",
    "# mean_3 = np.array([4.0, 4.0])\n",
    "# cov_3 = np.array([[4.0, 0.0], [0.0, 4.0]])\n",
    "# data_1 = np.random.multivariate_normal(mean_1, cov_1, size=N_size[0])\n",
    "# data_2 = np.random.multivariate_normal(mean_2, cov_2, size=N_size[1])\n",
    "# data_3 = np.random.multivariate_normal(mean_3, cov_3, size=N_size[2])\n",
    "# data_points_nparray = np.array( np.concatenate([data_1, data_2, data_3]) ) # List consisting of data points\n",
    "\n",
    "# ## Data Example 11\n",
    "# import sklearn.datasets\n",
    "# N_size = (40, 40, 40) # Tensor dimensions: n1, n2, n3, ... : tuple consisting of the number of data belonging to each group\n",
    "# data_points_nparray, Y = sklearn.datasets.make_swiss_roll(noise=0.1, n_samples=N_size[0]+N_size[1]+N_size[2], random_state = 0) # List consisting of data points\n",
    "\n",
    "########################################################\n",
    "### Data Size and Dimensions ###\n",
    "data_size = len(data_points_nparray)\n",
    "if data_size == sum(N_size) :\n",
    "    print(\"data_size (len(data_points_nparray)): \"+str(data_size))\n",
    "else:\n",
    "    print(\"Error:  Data size is incorrect.\")\n",
    "data_dim = len(data_points_nparray[0])\n",
    "if data_dim == len(data_points_nparray[data_size-1]) :\n",
    "    print(\"data_dim: \"+str(data_dim))\n",
    "else:\n",
    "    print(\"Error:  Data dimension is incorrect.\")\n",
    "(fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, None, data_points_nparray,\n",
    "                            viz2d_x=None, viz2d_y=None, f_size=(5,4,2), f_title=\"Before computation\")\n",
    "# (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, gen_grouping_index(N_size, False), data_points_nparray, \n",
    "#                             viz2d_x=None, viz2d_y=None, f_size=(5,4,2), f_title=\"Before computation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Initial value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Initial value ####\n",
    "common_init_grouping_index = gen_grouping_indexes_list(N_size, rand=True) ## True:ランダムなグループ分け, False:順番通りのグループ分け\n",
    "print(\"common_init_grouping_index: \" + str(common_init_grouping_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Calculations using methods to be compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Random sampling method ####\n",
    "## Setting Arguments\n",
    "## data_points_nparray: NumPy array consisting of data points\n",
    "## N_size: Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "standardization = True ## Standardization\n",
    "mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "deviation_penalty_weight = 0.1 ## Weight of deviation_cost_value\n",
    "cost_type = \"mst\" ## \"mst\": minimum spanning tree, \"bc\": barycenter\n",
    "order = 1.0 ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot\n",
    "tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "init_grouping_index = copy.deepcopy(common_init_grouping_index) ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "search_method = \"rand\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "main_show_info = True ## Flag whether information is displayed or not\n",
    "main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "sub_show_info = False ## Flag whether information is displayed or not\n",
    "sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "info_args = None ## Arguments for info_func\n",
    "tensor_size_max = 1000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "## Division and Search\n",
    "res_rand_1 = gen_optimal_grouping(data_points_nparray, N_size, standardization,\n",
    "                          mean_penalty_weight, deviation_penalty_weight,\n",
    "                          cost_type, order,\n",
    "                          numerical_precision,\n",
    "                          ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                          tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                          init_grouping_index, init_grouping_rand,\n",
    "                          search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                          main_show_info, main_drawing_graphs,\n",
    "                          sub_show_info, sub_drawing_graphs,\n",
    "                          info_func, info_args,\n",
    "                          tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                          viz2d_x, viz2d_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Exchange algorithm ####\n",
    "## Setting Arguments\n",
    "## data_points_nparray: NumPy array consisting of data points\n",
    "## N_size: Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "standardization = True ## Standardization\n",
    "mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "deviation_penalty_weight = 0.1 ## Weight of deviation_cost_value\n",
    "cost_type = \"mst\" ## \"mst\": minimum spanning tree, \"bc\": barycenter\n",
    "order = 1.0 ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot\n",
    "tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "init_grouping_index = copy.deepcopy(common_init_grouping_index) ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "search_method = \"ex\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "main_show_info = True ## Flag whether information is displayed or not\n",
    "main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "sub_show_info = False ## Flag whether information is displayed or not\n",
    "sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "info_args = None ## Arguments for info_func\n",
    "tensor_size_max = 1000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "group_size_max = 10 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "## Division and Search\n",
    "res_ex_1 = gen_optimal_grouping(data_points_nparray, N_size, standardization,\n",
    "                          mean_penalty_weight, deviation_penalty_weight,\n",
    "                          cost_type, order,\n",
    "                          numerical_precision,\n",
    "                          ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                          tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                          init_grouping_index, init_grouping_rand,\n",
    "                          search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                          main_show_info, main_drawing_graphs,\n",
    "                          sub_show_info, sub_drawing_graphs,\n",
    "                          info_func, info_args,\n",
    "                          tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                          viz2d_x, viz2d_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Hybrid method（exchange algorithm + random sampling） ####\n",
    "## Setting Arguments\n",
    "## data_points_nparray: NumPy array consisting of data points\n",
    "## N_size: Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "standardization = True ## Standardization\n",
    "mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "deviation_penalty_weight = 0.1 ## Weight of deviation_cost_value\n",
    "cost_type = \"mst\" ## \"mst\": minimum spanning tree, \"bc\": barycenter\n",
    "order = 1.0 ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot\n",
    "tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "init_grouping_index = copy.deepcopy(common_init_grouping_index) ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "search_method = \"hybrid\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "main_show_info = True ## Flag whether information is displayed or not\n",
    "main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "sub_show_info = False ## Flag whether information is displayed or not\n",
    "sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "info_args = None ## Arguments for info_func\n",
    "tensor_size_max = 1000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "group_size_max = 10 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "## Division and Search\n",
    "res_hybrid_1 = gen_optimal_grouping(data_points_nparray, N_size, standardization,\n",
    "                          mean_penalty_weight, deviation_penalty_weight,\n",
    "                          cost_type, order, \n",
    "                          numerical_precision,\n",
    "                          ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                          tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                          init_grouping_index, init_grouping_rand,\n",
    "                          search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                          main_show_info, main_drawing_graphs,\n",
    "                          sub_show_info, sub_drawing_graphs,\n",
    "                          info_func, info_args,\n",
    "                          tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                          viz2d_x, viz2d_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Drawing graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Graph drawing settings ####\n",
    "\n",
    "iteration_number = list(range(len(res_rand_1[7])))\n",
    "col_rand_1 = \"red\" ## color\n",
    "lab_rand_1 = \"Random sampling\" ## label\n",
    "lty_rand_1 = \"solid\" ## line type: \"solid\", \"dashed\", \"dotted\", \"dashdot\"\n",
    "col_ex_1 = \"blue\" ## color\n",
    "lab_ex_1 = \"Exchange algorithm\" ## label\n",
    "lty_ex_1 = \"dashed\" ## line type: \"solid\", \"dashed\", \"dotted\", \"dashdot\"\n",
    "col_hybrid_1 = \"orange\" ## color\n",
    "lab_hybrid_1 = \"Hybrid method\" ## label\n",
    "lty_hybrid_1 = \"dashdot\" ## line type: \"solid\", \"dashed\", \"dotted\", \"dashdot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Drawing a graph of number of calculations and cost trends ####\n",
    "fig, ax = plt.subplots(figsize = (4, 3))\n",
    "ax.set_xlabel(\"$n$ (number of calculations)\") ## x-axis label\n",
    "ax.set_ylabel(\"cost\") ## y-axis label\n",
    "ax.set_title(\"\") ## Graph Title\n",
    "ax.grid() ## ruled line\n",
    "ax.plot(res_rand_1[7], res_rand_1[10], color=col_rand_1, linestyle=lty_rand_1, label=lab_rand_1)\n",
    "ax.plot(res_ex_1[7], res_ex_1[10], color=col_ex_1, linestyle=lty_ex_1, label=lab_ex_1)\n",
    "ax.plot(res_hybrid_1[7], res_hybrid_1[10], color=col_hybrid_1, linestyle=lty_hybrid_1, label=lab_hybrid_1)\n",
    "ax.legend(loc=0) ## legend\n",
    "fig.tight_layout() ## Layout Settings\n",
    "# plt.savefig(\"nc.png\") ## Saving Graph Image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Drawing a graph of computation time and cost trends ####\n",
    "fig, ax = plt.subplots(figsize = (4, 3))\n",
    "ax.set_xlabel(\"$t$ (computation time)\") ## x-axis label\n",
    "ax.set_ylabel(\"cost\") ## y-axis label\n",
    "ax.set_title(\"\") ## Graph Title\n",
    "ax.grid() ## ruled line\n",
    "ax.plot(res_rand_1[8], res_rand_1[10], color=col_rand_1, linestyle=lty_rand_1, label=lab_rand_1)\n",
    "ax.plot(res_ex_1[8], res_ex_1[10], color=col_ex_1, linestyle=lty_ex_1, label=lab_ex_1)\n",
    "ax.plot(res_hybrid_1[8], res_hybrid_1[10], color=col_hybrid_1, linestyle=lty_hybrid_1, label=lab_hybrid_1)\n",
    "ax.legend(loc=0) ## legend\n",
    "fig.tight_layout() ## Layout Settings\n",
    "# plt.savefig(\"tc.png\") ## Saving Graph Image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. GUI with Flet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\univ\\miniconda3\\envs\\dev\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2628\u001b[0m\n\u001b[0;32m   2489\u001b[0m     page\u001b[38;5;241m.\u001b[39moverlay\u001b[38;5;241m.\u001b[39mappend(pick_files_dialog)\n\u001b[0;32m   2490\u001b[0m     page\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m   2491\u001b[0m         ft\u001b[38;5;241m.\u001b[39mColumn([\n\u001b[0;32m   2492\u001b[0m             ft\u001b[38;5;241m.\u001b[39mContainer(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2625\u001b[0m         ]),\n\u001b[0;32m   2626\u001b[0m     )\n\u001b[1;32m-> 2628\u001b[0m \u001b[43mft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\univ\\miniconda3\\envs\\dev\\Lib\\site-packages\\flet_runtime\\app.py:70\u001b[0m, in \u001b[0;36mapp\u001b[1;34m(target, name, host, port, view, assets_dir, upload_dir, web_renderer, use_color_emoji, route_url_strategy, export_asgi_app)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve_fastapi_web_app\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_fastapi_web_app\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_fastapi_web_app(\n\u001b[0;32m     61\u001b[0m         session_handler\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m     62\u001b[0m         page_name\u001b[38;5;241m=\u001b[39m__get_page_name(name),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m         route_url_strategy\u001b[38;5;241m=\u001b[39mroute_url_strategy,\n\u001b[0;32m     68\u001b[0m     )\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapp_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mview\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43massets_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massets_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupload_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupload_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweb_renderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweb_renderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_color_emoji\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_color_emoji\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroute_url_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroute_url_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\univ\\miniconda3\\envs\\dev\\Lib\\asyncio\\runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "##### OTG (Optimal Transport Grouping)\n",
    "## tanaken ( Kentaro TANAKA, 2024.2- )\n",
    "\n",
    "## Running this program in a Jupyter notebook may result in an error.\n",
    "## If it doesn’t work, please run the program from the command line interface.\n",
    "\n",
    "############################################################\n",
    "#### Required libraries ####\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install umap-learn\n",
    "# !pip install flet\n",
    "\n",
    "############################################################\n",
    "#### Import ####\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "from matplotlib import cm as cm\n",
    "is_umap_loaded = True\n",
    "try:\n",
    "    import umap\n",
    "    # from numba import jit\n",
    "except ImportError as e:\n",
    "    is_umap_loaded = False\n",
    "    print(f\"{e} is not installed.\")\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "if os.name == 'nt':\n",
    "    import ctypes\n",
    "    ENABLE_PROCESSED_OUTPUT = 0x0001\n",
    "    ENABLE_WRAP_AT_EOL_OUTPUT = 0x0002\n",
    "    ENABLE_VIRTUAL_TERMINAL_PROCESSING = 0x0004\n",
    "    MODE = ENABLE_PROCESSED_OUTPUT + ENABLE_WRAP_AT_EOL_OUTPUT + ENABLE_VIRTUAL_TERMINAL_PROCESSING\n",
    "    kernel32 = ctypes.windll.kernel32\n",
    "    handle = kernel32.GetStdHandle(-11)\n",
    "    kernel32.SetConsoleMode(handle, MODE)\n",
    "import flet as ft\n",
    "from flet.matplotlib_chart import MatplotlibChart\n",
    "is_umap_loaded = True\n",
    "try:\n",
    "    import umap\n",
    "    # from numba import jit\n",
    "except ImportError as e:\n",
    "    is_umap_loaded = False\n",
    "    print(f\"{e} is not installed.\")\n",
    "\n",
    "############################################################\n",
    "#### Functions ####\n",
    "\n",
    "## Functions for manipulating tensors\n",
    "def get_N(N_size):\n",
    "    if len(N_size) < 1:\n",
    "        raise ValueError(\"Error: N_size is invalid.\")\n",
    "    N_rank = len(N_size)\n",
    "    N_accum = np.ones(N_rank, dtype=int) # n2*n3*...*nN, n3*n4*...*nN, ... , nN, 1\n",
    "    for i in range(N_rank):\n",
    "        if i==0:\n",
    "            N_accum[N_rank-i-1] = 1\n",
    "        else:\n",
    "            N_accum[N_rank-i-1] = N_accum[N_rank-i]*N_size[N_rank-i]\n",
    "    N_size_prod = N_size[0]*N_accum[0]\n",
    "    return (N_rank, N_accum, N_size_prod)\n",
    "\n",
    "def get_tensor_flattened_index_from_multi_index(multi_index, N_rank, N_accum):\n",
    "    flattened_index = 0\n",
    "    for i in range(N_rank):\n",
    "            flattened_index = flattened_index + N_accum[i]*multi_index[i]\n",
    "    flattened_index = int(flattened_index)\n",
    "    return flattened_index\n",
    "\n",
    "def get_tensor_multi_index_from_flattened_index(flattened_index, N_rank, N_accum):\n",
    "    multi_index = []\n",
    "    remainder = flattened_index\n",
    "    for i in range(N_rank):\n",
    "        quotient, remainder = divmod(remainder, N_accum[i])\n",
    "        multi_index.append(quotient)\n",
    "    multi_index = tuple(multi_index)\n",
    "    return multi_index\n",
    "\n",
    "def get_tensor_value_from_multi_index(target_tensor, multi_index, N_rank, N_accum):\n",
    "    flattened_index = get_tensor_flattened_index_from_multi_index(multi_index, N_rank, N_accum)\n",
    "    return target_tensor[flattened_index]\n",
    "\n",
    "def get_tensor_flattened_index_list_from_value(target_tensor, value, tensor_tolerance=None):\n",
    "    if (tensor_tolerance is None) or (tensor_tolerance==0):\n",
    "        return [i for i, element in enumerate(target_tensor) if element==value]\n",
    "    else:\n",
    "        return [i for i, element in enumerate(target_tensor) if abs(element-value)<=tensor_tolerance]\n",
    "\n",
    "def get_tensor_multi_index_list_from_value(target_tensor, value, N_rank, N_accum, tensor_tolerance=None):\n",
    "    multi_index_list = []\n",
    "    flattened_index_list = get_tensor_flattened_index_list_from_value(target_tensor, value, tensor_tolerance)\n",
    "    for flattened_index in flattened_index_list:\n",
    "        multi_index_list.append(get_tensor_multi_index_from_flattened_index(flattened_index, N_rank, N_accum))\n",
    "    return multi_index_list\n",
    "\n",
    "## Function to generate marginal mass vectors\n",
    "def calc_marginal_mass_vectors(N_rank, N_size):\n",
    "    marginal_mass_vectors = []\n",
    "    for i in range(N_rank):\n",
    "        marginal_mass_vectors.append(np.ones(N_size[i])/N_size[i])\n",
    "    return marginal_mass_vectors\n",
    "\n",
    "## Function to generate grouping randomly (rand=True) or in the same order as the data_order_list (rand=False)\n",
    "def gen_grouping_indexes_list(N_size, rand=True, data_order_list=None):\n",
    "    if data_order_list is None:\n",
    "        data_order_list = list(range(sum(N_size)))\n",
    "    if rand:\n",
    "        data_order_list = random.sample(data_order_list, len(data_order_list))\n",
    "    grouping_indexes_list = [] # Double listing for grouping\n",
    "    range_from = 0\n",
    "    range_to = 0\n",
    "    for size in N_size:\n",
    "        range_to = range_from + size\n",
    "        grouping_indexes_list.append(data_order_list[range_from:range_to])\n",
    "        range_from = range_to\n",
    "    return grouping_indexes_list\n",
    "\n",
    "## Functions for the calculation of optimal transport\n",
    "# @jit\n",
    "def calc_multi_ot(marginal_mass_vectors, cost_tensor, normalized_cost_tensor,\n",
    "                  N_size, N_rank, N_accum, N_size_prod,\n",
    "                  numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200): ## ot_stopping_rule: Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ## Optrimal transport\n",
    "    K_tensor = np.exp(- normalized_cost_tensor / ot_speed) # Gibbs kernel\n",
    "    u_vec_list = []\n",
    "    for i in range(N_rank):\n",
    "        u_vec_list.append(np.ones(N_size[i]))\n",
    "    for loop in range(ot_loop_max):\n",
    "        u_diff = 0 # Variable to measure whether to exit the loop\n",
    "        for i in range(N_rank):\n",
    "            for j in range(N_size[i]):\n",
    "                temp_u_value = 0\n",
    "                temp_K_value = 1\n",
    "                temp_u_prod_value = 1\n",
    "                N_sizeub_s = list(copy.copy(N_size))\n",
    "                N_sizeub_s.pop(i)\n",
    "                for m_sub_index in np.ndindex(tuple(N_sizeub_s)):\n",
    "                    temp_m_index = list(copy.copy(m_sub_index))\n",
    "                    temp_m_index.insert(i, j)\n",
    "                    temp_K_value = get_tensor_value_from_multi_index(K_tensor, temp_m_index, N_rank, N_accum)\n",
    "                    temp_u_prod_value = 1\n",
    "                    for k in range(N_rank):\n",
    "                        if k != i:\n",
    "                            temp_u_prod_value = temp_u_prod_value * u_vec_list[k][temp_m_index[k]]\n",
    "                    temp_u_value = temp_u_value + temp_K_value * temp_u_prod_value\n",
    "                temp_u_value = (marginal_mass_vectors[i][j]) / (temp_u_value)\n",
    "                u_diff = max(u_diff, abs((u_vec_list[i][j]-temp_u_value)/(temp_u_value+numerical_precision))) \n",
    "                u_vec_list[i][j] = temp_u_value\n",
    "        if abs(u_diff) < ot_stopping_rule:\n",
    "            break\n",
    "    f_vec_list = []\n",
    "    for i in range(N_rank):\n",
    "        temp_f_vec = ot_speed * np.log(u_vec_list[i] + numerical_precision)\n",
    "        f_vec_list.append(temp_f_vec)\n",
    "    P_tensor = np.zeros(N_size_prod)\n",
    "    weighted_cost_tensor = np.zeros(N_size_prod)\n",
    "    objective_function_value = 0\n",
    "    for m_index in np.ndindex(tuple(N_size)):\n",
    "        temp_cost_value = get_tensor_value_from_multi_index(cost_tensor, m_index, N_rank, N_accum)\n",
    "        temp_P_value = get_tensor_value_from_multi_index(K_tensor, m_index, N_rank, N_accum)\n",
    "        for k in range(N_rank):\n",
    "            temp_P_value = temp_P_value * u_vec_list[k][m_index[k]]\n",
    "        P_tensor[get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)] = temp_P_value\n",
    "        weighted_cost_tensor[get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)] = temp_P_value*temp_cost_value\n",
    "        objective_function_value = objective_function_value + weighted_cost_tensor[get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)]\n",
    "    return (objective_function_value, P_tensor, weighted_cost_tensor, u_vec_list, f_vec_list)\n",
    "\n",
    "## Functions for calculating optrimal grouping with barycenter (BC)\n",
    "def calc_intergroup_cost_tensor_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "                                N_size, N_rank, N_accum, N_size_prod, order = 2.0,\n",
    "                                numerical_precision = 2e-8):\n",
    "    cost_tensor = np.zeros(N_size_prod)\n",
    "    for m_index in np.ndindex(N_size):\n",
    "        temp_data_points_nparray = []\n",
    "        temp_cost_value = 0\n",
    "        ## Cost : Sum of distances (not squared) between each point and the barycenter\n",
    "        for group in range(N_rank):\n",
    "            temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][m_index[group]]])\n",
    "        temp_barycenter = np.mean(temp_data_points_nparray, axis=0)\n",
    "        for group in range(N_rank):\n",
    "            temp_cost_value_bt2 = np.linalg.norm(temp_data_points_nparray[group] - temp_barycenter) ## Cost between two points\n",
    "            temp_cost_value = temp_cost_value + temp_cost_value_bt2\n",
    "        temp_index = get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)\n",
    "        cost_tensor[temp_index] = temp_cost_value\n",
    "    normalized_cost_tensor = copy.deepcopy(cost_tensor)\n",
    "    max_cost_value = max(cost_tensor)\n",
    "    if max_cost_value > numerical_precision:\n",
    "        normalized_cost_tensor = normalized_cost_tensor/max_cost_value\n",
    "    return (cost_tensor, normalized_cost_tensor)\n",
    "\n",
    "def calc_intergroup_cost_value_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                               N_size, N_rank, N_accum, N_size_prod, order = 2.0,\n",
    "                               numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200):\n",
    "    (intergroup_cost_tensor, normalized_intergroup_cost_tensor) = calc_intergroup_cost_tensor_with_bc(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod,\n",
    "        numerical_precision)\n",
    "    (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "     intergroup_u_vec_list, intergroup_f_vec_list) = calc_multi_ot(\n",
    "        marginal_mass_vectors, intergroup_cost_tensor, normalized_intergroup_cost_tensor, N_size, N_rank, N_accum, N_size_prod,\n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "    return (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "            intergroup_u_vec_list, intergroup_f_vec_list, intergroup_cost_tensor)\n",
    "\n",
    "def calc_intragroup_cost_nparray_list_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                                      N_size, N_rank, N_accum, N_size_prod, order = 2.0):\n",
    "    cost_nparray_list = []\n",
    "    barycenter_nparray_list = []\n",
    "    for group, size in enumerate(N_size):\n",
    "        temp_cost_nparray = np.zeros(size)\n",
    "        for element in range(size):\n",
    "            temp_data_points_nparray = []\n",
    "            ## Cost : Sum of distances (not squared) between each point and the barycenter\n",
    "            for element in range(N_size[group]): ## barycenter\n",
    "                temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][element]])\n",
    "            temp_barycenter_nparray = np.mean(temp_data_points_nparray, axis=0)\n",
    "            for element in range(N_size[group]): ## Cost between one mass point and barycenter\n",
    "                temp_cost_value_bt2 = np.linalg.norm(temp_data_points_nparray[element] - temp_barycenter_nparray, ord=order) ## Cost between two points\n",
    "                temp_cost_nparray[element] = temp_cost_value_bt2\n",
    "        cost_nparray_list.append(temp_cost_nparray)\n",
    "        barycenter_nparray_list.append(temp_barycenter_nparray)\n",
    "    return (cost_nparray_list, barycenter_nparray_list)\n",
    "\n",
    "def calc_intragroup_cost_value_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                               N_size, N_rank, N_accum, N_size_prod, order = 2.0):\n",
    "    intragroup_cost_value = 0\n",
    "    intragroup_average_cost_list = []\n",
    "    (intragroup_cost_nparray_list, intragroup_barycenter_nparray_list) = calc_intragroup_cost_nparray_list_with_bc(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod, order\n",
    "        )\n",
    "    for group in range(N_rank):\n",
    "        intragroup_average_cost = np.mean(intragroup_cost_nparray_list[group])\n",
    "        intragroup_average_cost_list.append(intragroup_average_cost)\n",
    "        intragroup_cost_value = intragroup_cost_value + intragroup_average_cost\n",
    "    intragroup_cost_value = intragroup_cost_value/N_rank\n",
    "    return (intragroup_cost_value, intragroup_cost_nparray_list, intragroup_average_cost_list, intragroup_barycenter_nparray_list)\n",
    "\n",
    "def calc_aggregate_statistical_cost_list_with_bc(intragroup_barycenter_nparray_list, intragroup_average_cost_list,\n",
    "                                         N_size, N_rank, N_accum, N_size_prod, order = 2.0):\n",
    "    center_of_intragroup_barycenter_nparray_list =  np.mean(intragroup_barycenter_nparray_list, axis=0)\n",
    "    center_of_intragroup_average_cost = np.mean(intragroup_average_cost_list, axis=0)\n",
    "    mean_cost_value = 0\n",
    "    deviation_cost_value = 0\n",
    "    for group in range(N_rank):\n",
    "        mean_cost_value = mean_cost_value + np.linalg.norm(intragroup_barycenter_nparray_list[group] - center_of_intragroup_barycenter_nparray_list, ord = order)\n",
    "        deviation_cost_value = deviation_cost_value + abs(intragroup_average_cost_list[group] - center_of_intragroup_average_cost)\n",
    "    mean_cost_value = mean_cost_value/N_rank\n",
    "    deviation_cost_value = deviation_cost_value/N_rank   \n",
    "    return (mean_cost_value, deviation_cost_value)\n",
    "\n",
    "def calc_adjusted_cost_value_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                             N_size, N_rank, N_accum, N_size_prod, \n",
    "                             mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 2.0, \n",
    "                             numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200):\n",
    "    ## intergroup_cost_value\n",
    "    (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "    intergroup_u_vec_list, intergroup_f_vec_list,\n",
    "    intergroup_cost_tensor) = calc_intergroup_cost_value_with_bc(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "        N_size, N_rank, N_accum, N_size_prod, order,\n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "        )\n",
    "    ## intragroup_cost_value\n",
    "    (intragroup_cost_value, intragroup_cost_nparray_list, intragroup_average_cost_list,\n",
    "     intragroup_barycenter_nparray_list) = calc_intragroup_cost_value_with_bc(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "        N_size, N_rank, N_accum, N_size_prod, order\n",
    "        )\n",
    "    ## aggregate_statistical_cost_value\n",
    "    (mean_cost_value, deviation_cost_value) = calc_aggregate_statistical_cost_list_with_bc(\n",
    "        intragroup_barycenter_nparray_list, intragroup_average_cost_list,\n",
    "        N_size, N_rank, N_accum, N_size_prod, order\n",
    "        )\n",
    "    ## adjusted_cost_value = (intergroup_cost_value + mean_cost_value + deviation_cost_value) / (intragroup_cost_value)\n",
    "    adjusted_cost_value = 0\n",
    "    if abs(intragroup_cost_value) < numerical_precision:\n",
    "        adjusted_cost_value = np.inf\n",
    "    else:\n",
    "        adjusted_cost_value = (intergroup_cost_value + mean_penalty_weight*mean_cost_value + deviation_penalty_weight*deviation_cost_value)/(intragroup_cost_value)\n",
    "    ## return\n",
    "    return (adjusted_cost_value, mean_cost_value, deviation_cost_value,\n",
    "            intragroup_cost_value, intragroup_cost_nparray_list, intragroup_barycenter_nparray_list, \n",
    "            intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "            intergroup_u_vec_list, intergroup_f_vec_list, intergroup_cost_tensor)\n",
    "\n",
    "def calc_optimal_grouping_with_bc(data_points_nparray, N_size,\n",
    "                           N_rank = None, N_accum = None, N_size_prod = None,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 2.0,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 10, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           show_info = False, drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## N_rank, N_accum, N_size_prod, marginal_mass_vectors\n",
    "    if (N_rank is None) or (N_accum is None) or (N_size_prod is None):\n",
    "        (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    marginal_mass_vectors = calc_marginal_mass_vectors(N_rank, N_size)\n",
    "    ## Initial value settings\n",
    "    if init_grouping_indexes_list is None:\n",
    "        init_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "    ## Calculation of optimal transportation costs under initial conditions\n",
    "    (init_adjusted_cost_value, init_mean_cost_value, init_deviation_cost_value,\n",
    "    init_intragroup_cost_value, init_intragroup_cost_nparray_list, init_intragroup_barycenter_nparray_list,\n",
    "    init_intergroup_cost_value, init_intergroup_P_tensor, init_intergroup_weighted_cost_tensor,\n",
    "    init_intergroup_u_vec_list, init_intergroup_f_vec_list,\n",
    "    init_intergroup_cost_tensor) = calc_adjusted_cost_value_with_bc(\n",
    "        init_grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod, order,\n",
    "        mean_penalty_weight, deviation_penalty_weight, \n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "    )\n",
    "    ## Preparation for recording\n",
    "    iteration_number_list = [0]\n",
    "    elapsed_time_list = [0]\n",
    "    new_adjusted_cost_trends_list = [init_adjusted_cost_value]\n",
    "    opt_adjusted_cost_trends_list = [init_adjusted_cost_value]\n",
    "    start_time = time.time()\n",
    "    ## info\n",
    "    if show_info:\n",
    "        info_func(info_args, \"---------- init\")\n",
    "        info_func(info_args, \"init_grouping_indexes_list: \" + str(init_grouping_indexes_list))\n",
    "        info_func(info_args, \"init_adjusted_cost_value: \" + str(init_adjusted_cost_value))\n",
    "        info_func(info_args, \"  (init_intergroup_cost_value, init_intragroup_cost_value: \" + str(init_intergroup_cost_value) + \", \" + str(init_intragroup_cost_value) + \")\")\n",
    "        info_func(info_args, \"  (mean_penalty_weight*init_mean_cost_value, deviation_penalty_weight*init_deviation_cost_value : \" \n",
    "              + str(mean_penalty_weight*init_mean_cost_value) + \", \" + str(deviation_penalty_weight*init_deviation_cost_value) + \")\")\n",
    "    if drawing_graphs:\n",
    "        (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "                                                                init_grouping_indexes_list, data_points_nparray, \n",
    "                                                                N_size, N_rank, N_accum, N_size_prod,\n",
    "                                                                viz2d_x, viz2d_y, init_intergroup_P_tensor)\n",
    "        # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, init_grouping_indexes_list, data_points_nparray,\n",
    "        #                             viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Initial Value\")\n",
    "        show_P_tensor(init_intergroup_P_tensor, N_size, N_rank, N_accum, f_size=(4,3), f_title=\"Initial Value\")\n",
    "    ## opt\n",
    "    opt_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "    opt_adjusted_cost_value = init_adjusted_cost_value\n",
    "    opt_mean_cost_value = init_mean_cost_value\n",
    "    opt_deviation_cost_value = init_deviation_cost_value\n",
    "    opt_intragroup_cost_value = init_intragroup_cost_value\n",
    "    opt_intergroup_cost_value = init_intergroup_cost_value\n",
    "    opt_intergroup_P_tensor = copy.deepcopy(init_intergroup_P_tensor)\n",
    "    ## new\n",
    "    new_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "    new_adjusted_cost_value = init_adjusted_cost_value\n",
    "    new_mean_cost_value = init_mean_cost_value\n",
    "    new_deviation_cost_value = init_deviation_cost_value\n",
    "    new_intragroup_cost_value = init_intragroup_cost_value\n",
    "    new_intragroup_cost_nparray_list = copy.deepcopy(init_intragroup_cost_nparray_list)\n",
    "    new_intragroup_barycenter_nparray_list = copy.deepcopy(init_intragroup_barycenter_nparray_list)\n",
    "    new_intergroup_cost_value = init_intergroup_cost_value\n",
    "    new_intergroup_P_tensor = copy.deepcopy(init_intergroup_P_tensor)\n",
    "    new_intergroup_weighted_cost_tensor = copy.deepcopy(init_intergroup_weighted_cost_tensor)\n",
    "    new_intergroup_cost_tensor = copy.deepcopy(init_intergroup_cost_tensor)\n",
    "    ## Search for optimal value\n",
    "    new_grouping_flag = True\n",
    "    search_stopping_rule_counter = 0\n",
    "    for loop in range(global_loop_max):\n",
    "        if show_info:\n",
    "            info_func(info_args, \"---------- loop: \" + str(loop+1))\n",
    "        search_stopping_rule_counter = search_stopping_rule_counter + 1\n",
    "        if search_method==\"rand\": ## search_method==\"rand\"\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=True) ## True: Random grouping, False: Grouping in order\n",
    "        else: ## search_method==\"ex\" or search_method==\"hybrid\"\n",
    "            if (search_stopping_rule_counter >= search_stopping_rule_rep):\n",
    "                opt_adjusted_cost_diff_list = opt_adjusted_cost_trends_list[(len(opt_adjusted_cost_trends_list)-search_stopping_rule_rep):]\n",
    "                old_adjusted_cost_value = opt_adjusted_cost_diff_list[0]\n",
    "                opt_adjusted_cost_diff_list = abs(np.array(opt_adjusted_cost_diff_list) - old_adjusted_cost_value)\n",
    "                opt_adjusted_cost_diff_list = opt_adjusted_cost_diff_list/(abs(old_adjusted_cost_value)+numerical_precision)\n",
    "                opt_adjusted_cost_diff_max = max(opt_adjusted_cost_diff_list)\n",
    "                if opt_adjusted_cost_diff_max <= search_stopping_rule_err:\n",
    "                    if search_method==\"hybrid\": ## search_method==\"hybrid\"\n",
    "                        search_stopping_rule_counter = 0\n",
    "                        new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=True) ## True: Random grouping, False: Grouping in order\n",
    "                        if show_info:\n",
    "                            info_func(info_args, \"Grouping has been shuffled.\")\n",
    "                    else: ## search_method==\"ex\"\n",
    "                        if show_info:\n",
    "                            info_func(info_args, \"The stopping criterion determined that convergence to the optimum value was achieved.\")\n",
    "                        break\n",
    "            ## Local grouping: Select two clusters and perform an exchange between the two clusters\n",
    "            probability_tensor = copy.deepcopy(new_intergroup_weighted_cost_tensor)\n",
    "            cluster_1_value = (random.choices(probability_tensor, k=1, weights=probability_tensor))[0]\n",
    "            cluster_1_flattened_index_list = get_tensor_flattened_index_list_from_value(probability_tensor, cluster_1_value, tensor_tolerance)\n",
    "            cluster_1_flattened_index = random.choice(cluster_1_flattened_index_list)\n",
    "            cluster_1_multi_index = get_tensor_multi_index_from_flattened_index(cluster_1_flattened_index, N_rank, N_accum)\n",
    "            probability_tensor[cluster_1_flattened_index] = 0\n",
    "            cluster_2_value = (random.choices(probability_tensor, k=1, weights=probability_tensor))[0]\n",
    "            cluster_2_flattened_index_list = get_tensor_flattened_index_list_from_value(probability_tensor, cluster_2_value, tensor_tolerance)\n",
    "            cluster_2_flattened_index = random.choice(cluster_2_flattened_index_list)\n",
    "            cluster_2_multi_index = get_tensor_multi_index_from_flattened_index(cluster_2_flattened_index, N_rank, N_accum)\n",
    "            ## Preparation for local grouping\n",
    "            local_N_size = []\n",
    "            local_data_indexes = []\n",
    "            opt_local_grouping_indexes_list = []\n",
    "            ## local_N_size, local_data_indexes, opt_local_grouping_indexes_list, local_N_rank, local_N_accum, local_N_size_prod, local_marginal_mass_vectors\n",
    "            for local_group in range(N_rank):\n",
    "                if cluster_1_multi_index[local_group] == cluster_2_multi_index[local_group]:\n",
    "                    local_N_size.append(1)\n",
    "                    temp_index = new_grouping_indexes_list[local_group][cluster_1_multi_index[local_group]]\n",
    "                    local_data_indexes.append(temp_index)\n",
    "                    opt_local_grouping_indexes_list.append([temp_index])\n",
    "                else:\n",
    "                    local_N_size.append(2)\n",
    "                    temp_index_1 = new_grouping_indexes_list[local_group][cluster_1_multi_index[local_group]]\n",
    "                    temp_index_2 = new_grouping_indexes_list[local_group][cluster_2_multi_index[local_group]]\n",
    "                    local_data_indexes.append(temp_index_1)\n",
    "                    local_data_indexes.append(temp_index_2)\n",
    "                    opt_local_grouping_indexes_list.append([temp_index_1, temp_index_2])\n",
    "            local_N_size = tuple(local_N_size)\n",
    "            (local_N_rank, local_N_accum, local_N_size_prod) = get_N(local_N_size)\n",
    "            local_marginal_mass_vectors = calc_marginal_mass_vectors(local_N_rank, local_N_size)\n",
    "            ## Calculation of current local optimal transportation costs\n",
    "            (opt_local_adjusted_cost_value, opt_local_mean_cost_value, opt_local_deviation_cost_value,\n",
    "            opt_local_intragroup_cost_value, opt_local_intragroup_cost_nparray_list, opt_local_intragroup_barycenter_nparray_list,\n",
    "            opt_local_intergroup_cost_value, opt_local_intergroup_P_tensor, opt_local_intergroup_weighted_cost_tensor,\n",
    "            opt_local_intergroup_u_vec_list, opt_local_intergroup_f_vec_list,\n",
    "            opt_local_intergroup_cost_tensor) = calc_adjusted_cost_value_with_bc(\n",
    "                opt_local_grouping_indexes_list, data_points_nparray, local_marginal_mass_vectors,\n",
    "                local_N_size, local_N_rank, local_N_accum, local_N_size_prod,\n",
    "                mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "            )\n",
    "            old_local_adjusted_cost_value = opt_local_adjusted_cost_value\n",
    "            ## Enumeration of grouping patterns\n",
    "            ## (If N_rank is 2 or 3, all enumeration is used, and more than that, random selection is used.)\n",
    "            local_grouping_indexes_list_combinations = []\n",
    "            if local_N_rank == 2: ## It might be a good idea to have all the patterns ready in advance. (2^2-1=3)\n",
    "                numbers_list = list(range(sum(local_N_size)))\n",
    "                for sub_numbers_list_1 in itertools.combinations(numbers_list, local_N_size[0]):\n",
    "                    sub_numbers_list_2 = tuple(np.delete(numbers_list, sub_numbers_list_1, 0))\n",
    "                    temp_local_grouping_indexes_list = list((np.array(local_data_indexes))[list(sub_numbers_list_1+sub_numbers_list_2)])\n",
    "                    temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                    if temp_local_grouping_indexes_list != opt_local_grouping_indexes_list:\n",
    "                        local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            elif local_N_rank == 3: ## It might be a good idea to have all the patterns ready in advance. (2^3-1=7)\n",
    "                numbers_list = list(range(sum(local_N_size)))\n",
    "                for sub_numbers_list_1 in itertools.combinations(numbers_list, local_N_size[0]):\n",
    "                    temp_numbers_list = np.delete(numbers_list, sub_numbers_list_1, 0)\n",
    "                    for sub_numbers_list_2 in itertools.combinations(temp_numbers_list, local_N_size[1]):      \n",
    "                        sub_numbers_list_3 = tuple(np.delete(numbers_list, sub_numbers_list_1+sub_numbers_list_2, 0))\n",
    "                        temp_local_grouping_indexes_list = list((np.array(local_data_indexes))[list(sub_numbers_list_1+sub_numbers_list_2+sub_numbers_list_3)])\n",
    "                        temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                        if temp_local_grouping_indexes_list!= opt_local_grouping_indexes_list:\n",
    "                                local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            else:\n",
    "                for i in range(local_loop_max):\n",
    "                    temp_local_grouping_indexes_list = random.sample(local_data_indexes, len(local_data_indexes))\n",
    "                    temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                    if (temp_local_grouping_indexes_list!= opt_local_grouping_indexes_list) and (temp_local_grouping_indexes_list not in local_grouping_indexes_list_combinations):\n",
    "                                local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            ## Calculate the cost of local optimal transportation for each pattern of local grouping\n",
    "            opt_local_adjusted_cost_value = float('inf')\n",
    "            opt_local_grouping_indexes_list_list = []\n",
    "            for new_local_grouping_indexes_list in local_grouping_indexes_list_combinations:\n",
    "                (new_local_adjusted_cost_value, new_local_mean_cost_value, new_local_deviation_cost_value,\n",
    "                new_local_intragroup_cost_value, new_local_intragroup_cost_nparray_list, new_local_intragroup_barycenter_nparray_list,\n",
    "                new_local_intergroup_cost_value, new_local_intergroup_P_tensor, new_local_intergroup_weighted_cost_tenso,\n",
    "                new_local_intergroup_u_vec_list, new_local_intergroup_f_vec_list,\n",
    "                new_local_intergroup_cost_tensor) = calc_adjusted_cost_value_with_bc(\n",
    "                        new_local_grouping_indexes_list, data_points_nparray, local_marginal_mass_vectors,\n",
    "                        local_N_size, local_N_rank, local_N_accum, local_N_size_prod,\n",
    "                        mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "                )\n",
    "                if new_local_adjusted_cost_value < opt_local_adjusted_cost_value:\n",
    "                    opt_local_adjusted_cost_value = new_local_adjusted_cost_value\n",
    "                    opt_local_grouping_indexes_list_list = [new_local_grouping_indexes_list]\n",
    "                elif new_local_adjusted_cost_value == opt_local_adjusted_cost_value:\n",
    "                    opt_local_grouping_indexes_list_list.append(new_local_grouping_indexes_list)\n",
    "            opt_local_grouping_indexes_list = random.choice(opt_local_grouping_indexes_list_list)\n",
    "            random_number = random.random()\n",
    "            new_grouping_flag = (opt_local_adjusted_cost_value==0) or (random_number <= (old_local_adjusted_cost_value/opt_local_adjusted_cost_value))\n",
    "            if new_grouping_flag:\n",
    "                for group in range(local_N_rank):\n",
    "                    if local_N_size[group] == 1:\n",
    "                        new_grouping_indexes_list[group][cluster_1_multi_index[group]] = opt_local_grouping_indexes_list[group][0]\n",
    "                    else:\n",
    "                        new_grouping_indexes_list[group][cluster_1_multi_index[group]] = opt_local_grouping_indexes_list[group][0]\n",
    "                        new_grouping_indexes_list[group][cluster_2_multi_index[group]] = opt_local_grouping_indexes_list[group][1]\n",
    "        if new_grouping_flag:\n",
    "            ## Calculation of the cost of optimal transport\n",
    "            (new_adjusted_cost_value, new_mean_cost_value, new_deviation_cost_value,\n",
    "            new_intragroup_cost_value, new_intragroup_cost_nparray_list, new_intragroup_barycenter_nparray_list, \n",
    "            new_intergroup_cost_value, new_intergroup_P_tensor, \n",
    "            new_intergroup_weighted_cost_tensor, new_intergroup_u_vec_list, new_intergroup_f_vec_list, \n",
    "            new_intergroup_cost_tensor) = calc_adjusted_cost_value_with_bc(\n",
    "                    new_grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                    N_size, N_rank, N_accum, N_size_prod,\n",
    "                    mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                    numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "            )\n",
    "        if show_info:\n",
    "            info_func(info_args, \"new_grouping_indexes_list: \" + str(new_grouping_indexes_list))\n",
    "            info_func(info_args, \"new_adjusted_cost_value: \" + str(new_adjusted_cost_value))\n",
    "        # if drawing_graphs:\n",
    "        #     (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "        #                                                 new_grouping_indexes_list, data_points_nparray, \n",
    "        #                                                 N_size, N_rank, N_accum, N_size_prod,\n",
    "        #                                                 viz2d_x, viz2d_y, new_intergroup_P_tensor)\n",
    "        #     # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "        #     #                             viz2d_x, viz2d_y, line_width = 1, f_size=(4,3,1), f_title=\"Mid-calculation\")\n",
    "        if new_adjusted_cost_value <= opt_adjusted_cost_value:\n",
    "            opt_grouping_indexes_list = copy.deepcopy(new_grouping_indexes_list)\n",
    "            opt_adjusted_cost_value = new_adjusted_cost_value\n",
    "            opt_mean_cost_value = new_mean_cost_value\n",
    "            opt_deviation_cost_value = new_deviation_cost_value\n",
    "            opt_intragroup_cost_value = new_intragroup_cost_value\n",
    "            opt_intragroup_cost_nparray_list = copy.deepcopy(new_intragroup_cost_nparray_list)\n",
    "            opt_intragroup_barycenter_nparray_list = copy.deepcopy(new_intragroup_barycenter_nparray_list)\n",
    "            opt_intergroup_cost_value = new_intergroup_cost_value\n",
    "            opt_intergroup_P_tensor = copy.deepcopy(new_intergroup_P_tensor)\n",
    "            opt_intergroup_weighted_cost_tensor = copy.deepcopy(new_intergroup_weighted_cost_tensor)\n",
    "            opt_intergroup_cost_tensor = copy.deepcopy(new_intergroup_cost_tensor)\n",
    "        ## Recording\n",
    "        iteration_number_list.append(loop+1)\n",
    "        elapsed_time = float(time.time() - start_time)\n",
    "        elapsed_time_list.append(elapsed_time)\n",
    "        new_adjusted_cost_trends_list.append(new_adjusted_cost_value)\n",
    "        opt_adjusted_cost_trends_list.append(opt_adjusted_cost_value)\n",
    "    ## info\n",
    "    if show_info:\n",
    "        info_func(info_args, \"---------- opt\")\n",
    "        info_func(info_args, \"opt_grouping_indexes_list: \" + str(init_grouping_indexes_list))\n",
    "        info_func(info_args, \"opt_adjusted_cost_value: \" + str(opt_adjusted_cost_value))\n",
    "        info_func(info_args, \"  (opt_intergroup_cost_value, opt_intragroup_cost_value: \" + str(opt_intergroup_cost_value) + \", \" + str(opt_intragroup_cost_value) + \")\")\n",
    "        info_func(info_args, \"  (mean_penalty_weight*opt_mean_cost_value, deviation_penalty_weight*opt_deviation_cost_value : \"\n",
    "              + str(mean_penalty_weight*opt_mean_cost_value) + \", \" + str(deviation_penalty_weight*opt_deviation_cost_value) + \")\")\n",
    "        ## Computation time\n",
    "        elapsed_hour = elapsed_time // 3600\n",
    "        elapsed_minute = (elapsed_time % 3600) // 60\n",
    "        elapsed_second = (elapsed_time % 3600 % 60)\n",
    "        info_func(info_args, \"computation time:\" + str(elapsed_hour).zfill(2) + \":\" + str(elapsed_minute).zfill(2) + \":\" + str(elapsed_second).zfill(2))\n",
    "    if drawing_graphs:\n",
    "        (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "                                            opt_grouping_indexes_list, data_points_nparray, \n",
    "                                            N_size, N_rank, N_accum, N_size_prod,\n",
    "                                            viz2d_x, viz2d_y, opt_intergroup_P_tensor)\n",
    "        # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, opt_grouping_indexes_list, data_points_nparray,\n",
    "        #                             viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "        show_P_tensor(opt_intergroup_P_tensor, N_size, N_rank, N_accum, f_size=(4,3), f_title=\"Optimal value\")\n",
    "     ## return\n",
    "    return (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "            opt_adjusted_cost_value,\n",
    "            opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "            opt_mean_cost_value, opt_deviation_cost_value,\n",
    "            iteration_number_list, elapsed_time_list,\n",
    "            new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "            viz2d_x, viz2d_y\n",
    "            )\n",
    "\n",
    "def gen_optimal_grouping_with_bc(data_points_nparray, N_size = None, standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 2.0, \n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## ## data_points_nparray: NumPy array consisting of data points\n",
    "    ## N_size: Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "    ## standardization = True ## Standardization\n",
    "    ## mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "    ## deviation_penalty_weight = 0.1 ## Weight of deviation_cost_value\n",
    "    ## order = 2.0 ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "    ## numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "    ## ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "    ## ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ## ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot_with_bc\n",
    "    ## tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "    ## global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "    ## local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "    ## init_grouping_indexes_list = None ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## search_method = \"ex\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "    ## search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "    ## search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "    ## main_show_info = True ## Flag whether information is displayed or not\n",
    "    ## main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "    ## sub_show_info = False ## Flag whether information is displayed or not\n",
    "    ## sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "    ## info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "    ## info_args = None ## Arguments for info_func\n",
    "    ## tensor_size_max = 4000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "    ## group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "    ## loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "    ## viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## N_size\n",
    "    data_size = len(data_points_nparray)\n",
    "    if N_size is None:\n",
    "        info_func(info_args, \"Warning: N_size is None.\")\n",
    "        N_size = tuple(data_size)\n",
    "    if (type(N_size) == int):\n",
    "        if data_size > N_size:\n",
    "            (quotient, remainder) = divmod(data_size, N_size)\n",
    "            N_size = np.full(N_size, quotient)\n",
    "            for i in range(remainder):\n",
    "                N_size[i] = N_size[i] + 1\n",
    "            N_size = tuple(N_size)\n",
    "        else:\n",
    "            N_size = tuple(data_size)\n",
    "    elif (type(N_size) == tuple) or (type(N_size) == list):\n",
    "        N_size = tuple(N_size)\n",
    "        if data_size != sum(N_size):\n",
    "            info_func(info_args, \"Warning: The sum of N_size does not match sample size.\")\n",
    "            N_size = tuple(data_size)\n",
    "    else:\n",
    "        info_func(info_args, \"Warning: N_size must be of type integer or tuple.\")\n",
    "        N_size = tuple(data_size)\n",
    "    (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    res_calc_optimal_grouping = None\n",
    "    ## Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    ## Setting Parameters\n",
    "    if (N_size_prod > tensor_size_max) or (min(N_size) > group_size_max): ## If True, use \"approximate solution\".\n",
    "        ## Initial value settings\n",
    "        if init_grouping_indexes_list is None:\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "        else:\n",
    "            new_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "        if main_show_info:\n",
    "            info_func(info_args, \"---------- new_grouping_indexes_list (initial value): \" + str(new_grouping_indexes_list))\n",
    "        if main_drawing_graphs:\n",
    "            (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                        viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Initial value\")\n",
    "        for loop in range( loop_max_multiplier*N_rank ):\n",
    "            (group_1, group_2) = random.sample(list(range(N_rank)), 2)\n",
    "            sub_N_size = [N_size[group_1], N_size[group_2]]\n",
    "            group_1_sub_index = []\n",
    "            group_2_sub_index = []\n",
    "            if sub_N_size[0] > group_size_max:\n",
    "                group_1_sub_index = random.sample(list(range(sub_N_size[0])), group_size_max)\n",
    "                sub_N_size[0] = group_size_max\n",
    "            else:\n",
    "                group_1_sub_index = list(range(sub_N_size[0]))\n",
    "            if sub_N_size[1] > group_size_max:\n",
    "                group_2_sub_index = random.sample(list(range(sub_N_size[1])), group_size_max)\n",
    "                sub_N_size[1] = group_size_max\n",
    "            else:\n",
    "                group_2_sub_index = list(range(sub_N_size[1]))\n",
    "            sub_N_size = tuple(sub_N_size)\n",
    "            sub_data_index = list(np.array(new_grouping_indexes_list[group_1])[group_1_sub_index]) + list(np.array(new_grouping_indexes_list[group_2])[group_2_sub_index])\n",
    "            sub_data_points_nparray = data_points_nparray[sub_data_index]\n",
    "            (sub_N_rank, sub_N_accum, sub_N_size_prod) = get_N(sub_N_size)\n",
    "            res_calc_optimal_grouping = calc_optimal_grouping_with_bc(\n",
    "                sub_data_points_nparray, sub_N_size,\n",
    "                sub_N_rank, sub_N_accum, sub_N_size_prod,\n",
    "                mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                numerical_precision,\n",
    "                ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                None, True, ## init_grouping_indexes_list, init_grouping_rand,\n",
    "                search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                sub_show_info, sub_drawing_graphs,\n",
    "                info_func,\n",
    "                info_args,\n",
    "                viz2d_x, viz2d_y)\n",
    "            sub_opt_grouping_indexes_list = res_calc_optimal_grouping[0]\n",
    "            group_1_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[0]])\n",
    "            group_2_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[1]])\n",
    "            for i, index in enumerate(group_1_sub_index):\n",
    "                new_grouping_indexes_list[group_1][index] = group_1_sub_grouping_indexes_list[i]\n",
    "            for i, index in enumerate(group_2_sub_index):\n",
    "                new_grouping_indexes_list[group_2][index] = group_2_sub_grouping_indexes_list[i]\n",
    "            if main_show_info:\n",
    "                info_func(info_args, \"---------- loop (partial optimization): \" + str(loop+1))\n",
    "                info_func(info_args, \"---------- new_grouping_indexes_list (partial optimization): \" + str(new_grouping_indexes_list))\n",
    "            if (main_drawing_graphs) and (loop == (2*N_rank-1)):\n",
    "                (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                            viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "        res_calc_optimal_grouping = (new_grouping_indexes_list, \n",
    "                                     None, # opt_intergroup_P_tensor,\n",
    "                                     None, # opt_adjusted_cost_value,\n",
    "                                     None, # opt_intergroup_cost_value,\n",
    "                                     None, # opt_intragroup_cost_value,\n",
    "                                     None, # opt_mean_cost_value,\n",
    "                                     None, # opt_deviation_cost_value,\n",
    "                                     None, # iteration_number_list,\n",
    "                                     None, # elapsed_time_list,\n",
    "                                     None, # new_adjusted_cost_trends_list,\n",
    "                                     None, # opt_adjusted_cost_trends_list,\n",
    "                                     viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_bc(data_points_nparray, N_size,\n",
    "                            N_rank, N_accum, N_size_prod,\n",
    "                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_indexes_list, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            info_func,\n",
    "                            info_args,\n",
    "                            viz2d_x, viz2d_y)\n",
    "    ## res_calc_optimal_grouping:\n",
    "    ## (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "    ##  opt_adjusted_cost_value,\n",
    "    ##  opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "    ##  opt_mean_cost_value, opt_deviation_cost_value,\n",
    "    ##  iteration_number_list, elapsed_time_list,\n",
    "    ##  new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "    ##  viz2d_x, viz2d_y)\n",
    "    return res_calc_optimal_grouping\n",
    "\n",
    "def gen_optimal_grouping_from_csv_file_with_bc(input_filepath= \"./members.csv\", input_index_col = 0, output_filepath = \"./grouping.csv\",\n",
    "                           N_size = None,\n",
    "                           standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 2.0, \n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## input_filepath = \"./members.csv\" ## File path of the input file, in csv format.\n",
    "    ## input_index_col = 0 ## Column number with column name or column number in the csv file\n",
    "    ## output_filepath = \"./grouping.csv\" ##  File path of the output file, in csv format.\n",
    "    ############################\n",
    "    ## Loading data: loading csv files\n",
    "    df = pd.read_csv(filepath_or_buffer=input_filepath, index_col=input_index_col)\n",
    "    output_data = copy.deepcopy(df)\n",
    "    data_size = len(df)\n",
    "    ############################\n",
    "    ## Dummy variable processing: dummy variable for columns where dtype is object\n",
    "    df = pd.get_dummies(df, drop_first=True, dtype=\"float\") # float64, uint8, bool\n",
    "    ############################\n",
    "    ##  Handling missing values: interpolate by median\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    ############################\n",
    "    ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray_org = np.array(df.values)\n",
    "    data_points_nparray = copy.deepcopy(data_points_nparray_org) ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray = data_points_nparray.astype(float)\n",
    "    ###########################################\n",
    "    ## Data Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    ###########################################\n",
    "    ## Division and Search\n",
    "    (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "     opt_adjusted_cost_value,\n",
    "     opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "     opt_mean_cost_value, opt_deviation_cost_value,\n",
    "     iteration_number_list, elapsed_time_list,\n",
    "     new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "     viz2d_x, viz2d_y\n",
    "    ) = gen_optimal_grouping_with_bc(data_points_nparray, N_size, standardization,\n",
    "                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_indexes_list, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            sub_show_info, sub_drawing_graphs,\n",
    "                            info_func, info_args,\n",
    "                            tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                            viz2d_x, viz2d_y)\n",
    "    ###########################################\n",
    "    ## Output grouping results to csv file\n",
    "    group_labels_list = np.zeros(data_size)\n",
    "    group = 0\n",
    "    for members_list in opt_grouping_indexes_list:\n",
    "        for member in members_list:\n",
    "            group_labels_list[member] = int(group)\n",
    "        group = group + 1\n",
    "    output_data.insert(loc=0, column=\"Group\", value=group_labels_list.astype(int), allow_duplicates=True)\n",
    "    if (viz2d_x is not None) and (viz2d_y is not None):\n",
    "        output_data.insert(loc=1, column=\"viz2d_x\", value=viz2d_x.astype(float), allow_duplicates=True)\n",
    "        output_data.insert(loc=2, column=\"viz2d_y\", value=viz2d_y.astype(float), allow_duplicates=True)\n",
    "    output_data.to_csv(output_filepath)\n",
    "    ###########################################\n",
    "    ## Return\n",
    "    return (opt_grouping_indexes_list,\n",
    "            opt_intergroup_P_tensor,\n",
    "            opt_adjusted_cost_value,\n",
    "            opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "            opt_mean_cost_value, opt_deviation_cost_value,\n",
    "            iteration_number_list, elapsed_time_list,\n",
    "            new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "            output_data, viz2d_x, viz2d_y\n",
    "    )\n",
    "\n",
    "## Functions for calculating optrimal grouping with minimum spanning tree (MST)\n",
    "def calc_distance_matrix(data_points: List[np.ndarray], order: float) -> np.ndarray:\n",
    "    n = len(data_points)\n",
    "    p = len(data_points[0]) ## Assuming all points have the same dimensionality\n",
    "    ## Initialize an empty distance matrix\n",
    "    distance_matrix = np.zeros((n, n))\n",
    "    ## Calculate pairwise distances\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            distance = np.linalg.norm(np.array(data_points[i]) - np.array(data_points[j]), ord = order)\n",
    "            distance_matrix[i, j] = distance\n",
    "            distance_matrix[j, i] = distance\n",
    "    return distance_matrix\n",
    "\n",
    "def calc_minimum_spanning_tree(distance_matrix: np.ndarray) -> Tuple[np.ndarray, float]:\n",
    "    n = distance_matrix.shape[0]\n",
    "    visited = [False] * n\n",
    "    adjacency_matrix = np.zeros((n, n))\n",
    "    total_weight = 0.0\n",
    "    ## Start with the first node\n",
    "    visited[0] = True\n",
    "    for _ in range(n - 1):\n",
    "        min_edge_weight = float('inf')\n",
    "        u, v = -1, -1\n",
    "        ## Find the minimum weight edge connecting visited and unvisited nodes\n",
    "        for i in range(n):\n",
    "            if visited[i]:\n",
    "                for j in range(n):\n",
    "                    if not visited[j] and distance_matrix[i, j] < min_edge_weight:\n",
    "                        min_edge_weight = distance_matrix[i, j]\n",
    "                        u, v = i, j\n",
    "        ## Add the edge to the MST\n",
    "        adjacency_matrix[u, v] = 1\n",
    "        adjacency_matrix[v, u] = 1\n",
    "        total_weight += min_edge_weight\n",
    "        visited[v] = True\n",
    "    return adjacency_matrix, total_weight\n",
    "\n",
    "def calc_distance_matrix_and_minimum_spanning_tree(data_points: List[np.ndarray], order: float) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    distance_matrix = calc_distance_matrix(data_points, order)\n",
    "    (adjacency_matrix, total_weight) = calc_minimum_spanning_tree(distance_matrix)\n",
    "    return (distance_matrix, adjacency_matrix, total_weight)\n",
    "\n",
    "def calc_intergroup_cost_tensor_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "                                N_size, N_rank, N_accum, N_size_prod, order = 1.0,\n",
    "                                numerical_precision = 2e-8):\n",
    "    cost_tensor = np.zeros(N_size_prod)\n",
    "    for m_index in np.ndindex(N_size):\n",
    "        temp_data_points_nparray = []\n",
    "        temp_cost_value = 0\n",
    "        for group in range(N_rank):\n",
    "            temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][m_index[group]]])\n",
    "        ## Cost: MST\n",
    "        (distance_nparray, adjacency_nparray,\n",
    "         total_weight) = calc_distance_matrix_and_minimum_spanning_tree(\n",
    "             temp_data_points_nparray, order)\n",
    "        temp_cost_value = total_weight\n",
    "        temp_index = get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)\n",
    "        cost_tensor[temp_index] = temp_cost_value\n",
    "    normalized_cost_tensor = copy.deepcopy(cost_tensor)\n",
    "    max_cost_value = max(cost_tensor)\n",
    "    if max_cost_value > numerical_precision:\n",
    "        normalized_cost_tensor = normalized_cost_tensor/max_cost_value\n",
    "    return (cost_tensor, normalized_cost_tensor)\n",
    "\n",
    "def calc_intergroup_cost_value_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                               N_size, N_rank, N_accum, N_size_prod, order = 1.0,\n",
    "                               numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200):\n",
    "    (intergroup_cost_tensor, normalized_intergroup_cost_tensor) = calc_intergroup_cost_tensor_with_mst(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod, order,\n",
    "        numerical_precision)\n",
    "    (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "     intergroup_u_vec_list, intergroup_f_vec_list) = calc_multi_ot(\n",
    "        marginal_mass_vectors, intergroup_cost_tensor, normalized_intergroup_cost_tensor, N_size, N_rank, N_accum, N_size_prod,\n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "    return (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "            intergroup_u_vec_list, intergroup_f_vec_list, intergroup_cost_tensor)\n",
    "\n",
    "def calc_intragroup_cost_list_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                                      N_size, N_rank, N_accum, N_size_prod, order = 1.0):\n",
    "    distance_nparray_list = []\n",
    "    adjacency_nparray_list = []\n",
    "    cost_list = []\n",
    "    for group, size in enumerate(N_size):\n",
    "        temp_data_points_nparray = []\n",
    "        for element in range(size):\n",
    "            temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][element]])\n",
    "        ## Cost : MST\n",
    "        (distance_nparray, adjacency_nparray,\n",
    "         total_weight) = calc_distance_matrix_and_minimum_spanning_tree(\n",
    "            temp_data_points_nparray, order)\n",
    "        distance_nparray_list.append(distance_nparray)\n",
    "        adjacency_nparray_list.append(adjacency_nparray)\n",
    "        cost_list.append(total_weight)\n",
    "    return (distance_nparray_list, adjacency_nparray_list, cost_list)\n",
    "\n",
    "def calc_intragroup_cost_value_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                               N_size, N_rank, N_accum, N_size_prod, order = 1.0):\n",
    "    intragroup_cost_value = 0\n",
    "    (intragroup_distance_nparray_list, intragroup_adjacency_nparray_list,\n",
    "     intragroup_cost_list) = calc_intragroup_cost_list_with_mst(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod, order)\n",
    "    intragroup_cost_value = sum(intragroup_cost_list)/N_rank\n",
    "    return (intragroup_distance_nparray_list, intragroup_adjacency_nparray_list,\n",
    "            intragroup_cost_list, intragroup_cost_value)\n",
    "\n",
    "def calc_mean_cost_value_with_mst(grouping_indexes_list, data_points_nparray,\n",
    "                            N_size, N_rank, N_accum, N_size_prod, order = 1.0):\n",
    "    barycenter_nparray_list = []\n",
    "    for group, size in enumerate(N_size):\n",
    "        temp_data_points_nparray = []\n",
    "        for element in range(size):\n",
    "            temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][element]])\n",
    "        temp_barycenter_nparray = np.mean(temp_data_points_nparray, axis=0)\n",
    "        barycenter_nparray_list.append(temp_barycenter_nparray)\n",
    "    barycenter_nparray_list = np.array(barycenter_nparray_list)\n",
    "    ## Cost: MST\n",
    "    (distance_nparray, adjacency_nparray,\n",
    "        mean_cost_value) = calc_distance_matrix_and_minimum_spanning_tree(\n",
    "            barycenter_nparray_list, order)\n",
    "    mean_cost_value = mean_cost_value/N_rank\n",
    "    return (barycenter_nparray_list, mean_cost_value)\n",
    "\n",
    "def calc_deviation_cost_value_with_mst(intragroup_distance_nparray_list):\n",
    "    return (max(intragroup_distance_nparray_list) - min(intragroup_distance_nparray_list))\n",
    "\n",
    "def calc_aggregate_statistical_cost_list_with_mst(grouping_indexes_list, data_points_nparray,\n",
    "                                                  intragroup_distance_nparray_list, intragroup_adjacency_nparray_list, intragroup_cost_list,\n",
    "                                                  N_size, N_rank, N_accum, N_size_prod, order = 1.0):\n",
    "    (barycenter_nparray_list, mean_cost_value) = calc_mean_cost_value_with_mst(grouping_indexes_list, data_points_nparray,\n",
    "                                                                               N_size, N_rank, N_accum, N_size_prod, order)\n",
    "    deviation_cost_value = calc_deviation_cost_value_with_mst(intragroup_cost_list)\n",
    "    return (mean_cost_value, deviation_cost_value)\n",
    "\n",
    "def calc_adjusted_cost_value_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                             N_size, N_rank, N_accum, N_size_prod, \n",
    "                             mean_penalty_weight = 0.1, deviation_penalty_weight=0.8, order = 1.0,\n",
    "                             numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200):\n",
    "    ## intergroup_cost_value\n",
    "    (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "    intergroup_u_vec_list, intergroup_f_vec_list,\n",
    "    intergroup_cost_tensor) = calc_intergroup_cost_value_with_mst(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "        N_size, N_rank, N_accum, N_size_prod, order,\n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "        )\n",
    "    ## intragroup_cost_value\n",
    "    (intragroup_distance_nparray_list, intragroup_adjacency_nparray_list,\n",
    "            intragroup_cost_list, intragroup_cost_value) = calc_intragroup_cost_value_with_mst(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "        N_size, N_rank, N_accum, N_size_prod\n",
    "        )\n",
    "    ## aggregate_statistical_cost_value\n",
    "    (mean_cost_value, deviation_cost_value) = calc_aggregate_statistical_cost_list_with_mst(grouping_indexes_list, data_points_nparray,\n",
    "                                                                                            intragroup_distance_nparray_list, intragroup_adjacency_nparray_list, intragroup_cost_list, \n",
    "                                                                                            N_size, N_rank, N_accum, N_size_prod, order = 1.0)\n",
    "    ## adjusted_cost_value = (intergroup_cost_value + mean_cost_value + deviation_cost_value) / (intragroup_cost_value)\n",
    "    adjusted_cost_value = 0\n",
    "    if abs(intragroup_cost_value) < numerical_precision:\n",
    "        adjusted_cost_value = np.inf\n",
    "    else:\n",
    "        adjusted_cost_value = (intergroup_cost_value + mean_penalty_weight*mean_cost_value + deviation_penalty_weight*deviation_cost_value)/(intragroup_cost_value)\n",
    "    ## return\n",
    "    return (adjusted_cost_value, mean_cost_value, deviation_cost_value,\n",
    "            intragroup_cost_value, intragroup_distance_nparray_list, intragroup_adjacency_nparray_list, intragroup_cost_list,\n",
    "            intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "            intergroup_u_vec_list, intergroup_f_vec_list, intergroup_cost_tensor)\n",
    "\n",
    "def calc_optimal_grouping_with_mst(data_points_nparray, N_size,\n",
    "                           N_rank = None, N_accum = None, N_size_prod = None,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.8, order = 1.0,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 10, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           show_info = False, drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## N_rank, N_accum, N_size_prod, marginal_mass_vectors\n",
    "    if (N_rank is None) or (N_accum is None) or (N_size_prod is None):\n",
    "        (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    marginal_mass_vectors = calc_marginal_mass_vectors(N_rank, N_size)\n",
    "    ## Initial value settings\n",
    "    if init_grouping_indexes_list is None:\n",
    "        init_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "    ## Calculation of optimal transportation costs under initial conditions\n",
    "    (init_adjusted_cost_value, init_mean_cost_value, init_deviation_cost_value,\n",
    "    init_intragroup_cost_value, init_intragroup_distance_nparray_list, init_intragroup_adjacency_nparray_list, init_intragroup_cost_list,\n",
    "    init_intergroup_cost_value, init_intergroup_P_tensor, init_intergroup_weighted_cost_tensor,\n",
    "    init_intergroup_u_vec_list, init_intergroup_f_vec_list,\n",
    "    init_intergroup_cost_tensor) = calc_adjusted_cost_value_with_mst(init_grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                             N_size, N_rank, N_accum, N_size_prod, \n",
    "                             mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                             numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "    ## Preparation for recording\n",
    "    iteration_number_list = [0]\n",
    "    elapsed_time_list = [0]\n",
    "    new_adjusted_cost_trends_list = [init_adjusted_cost_value]\n",
    "    opt_adjusted_cost_trends_list = [init_adjusted_cost_value]\n",
    "    start_time = time.time()\n",
    "    ## info\n",
    "    if show_info:\n",
    "        info_func(info_args, \"---------- init\")\n",
    "        info_func(info_args, \"init_grouping_indexes_list: \" + str(init_grouping_indexes_list))\n",
    "        info_func(info_args, \"init_adjusted_cost_value: \" + str(init_adjusted_cost_value))\n",
    "        info_func(info_args, \"  (init_intergroup_cost_value, init_intragroup_cost_value: \" + str(init_intergroup_cost_value) + \", \" + str(init_intragroup_cost_value) + \")\")\n",
    "        info_func(info_args, \"  (mean_penalty_weight*init_mean_cost_value, deviation_penalty_weight*init_deviation_cost_value : \" \n",
    "              + str(mean_penalty_weight*init_mean_cost_value) + \", \" + str(deviation_penalty_weight*init_deviation_cost_value) + \")\")\n",
    "    if drawing_graphs:\n",
    "        (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "                                                                init_grouping_indexes_list, data_points_nparray, \n",
    "                                                                N_size, N_rank, N_accum, N_size_prod,\n",
    "                                                                viz2d_x, viz2d_y, init_intergroup_P_tensor)\n",
    "        # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, init_grouping_indexes_list, data_points_nparray,\n",
    "        #                             viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Initial Value\")\n",
    "        show_P_tensor(init_intergroup_P_tensor, N_size, N_rank, N_accum, f_size=(4,3), f_title=\"Initial Value\")\n",
    "    ## opt\n",
    "    opt_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "    opt_adjusted_cost_value = init_adjusted_cost_value\n",
    "    opt_mean_cost_value = init_mean_cost_value\n",
    "    opt_deviation_cost_value = init_deviation_cost_value\n",
    "    opt_intragroup_cost_value = init_intragroup_cost_value\n",
    "    opt_intergroup_cost_value = init_intergroup_cost_value\n",
    "    opt_intergroup_P_tensor = copy.deepcopy(init_intergroup_P_tensor)\n",
    "    ## new\n",
    "    new_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "    new_adjusted_cost_value = init_adjusted_cost_value\n",
    "    new_mean_cost_value = init_mean_cost_value\n",
    "    new_deviation_cost_value = init_deviation_cost_value\n",
    "    new_intragroup_cost_value = init_intragroup_cost_value\n",
    "    new_intergroup_cost_value = init_intergroup_cost_value\n",
    "    new_intergroup_P_tensor = copy.deepcopy(init_intergroup_P_tensor)\n",
    "    new_intergroup_weighted_cost_tensor = copy.deepcopy(init_intergroup_weighted_cost_tensor)\n",
    "    new_intergroup_cost_tensor = copy.deepcopy(init_intergroup_cost_tensor)\n",
    "    ## Search for optimal value\n",
    "    new_grouping_flag = True\n",
    "    search_stopping_rule_counter = 0\n",
    "    for loop in range(global_loop_max):\n",
    "        if show_info:\n",
    "            info_func(info_args, \"---------- loop: \" + str(loop+1))\n",
    "        search_stopping_rule_counter = search_stopping_rule_counter + 1\n",
    "        if search_method==\"rand\": ## search_method==\"rand\"\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=True) ## True: Random grouping, False: Grouping in order\n",
    "        else: ## search_method==\"ex\" or search_method==\"hybrid\"\n",
    "            if (search_stopping_rule_counter >= search_stopping_rule_rep):\n",
    "                opt_adjusted_cost_diff_list = opt_adjusted_cost_trends_list[(len(opt_adjusted_cost_trends_list)-search_stopping_rule_rep):]\n",
    "                old_adjusted_cost_value = opt_adjusted_cost_diff_list[0]\n",
    "                opt_adjusted_cost_diff_list = abs(np.array(opt_adjusted_cost_diff_list) - old_adjusted_cost_value)\n",
    "                opt_adjusted_cost_diff_list = opt_adjusted_cost_diff_list/(abs(old_adjusted_cost_value)+numerical_precision)\n",
    "                opt_adjusted_cost_diff_max = max(opt_adjusted_cost_diff_list)\n",
    "                if opt_adjusted_cost_diff_max <= search_stopping_rule_err:\n",
    "                    if search_method==\"hybrid\": ## search_method==\"hybrid\"\n",
    "                        search_stopping_rule_counter = 0\n",
    "                        new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=True) ## True: Random grouping, False: Grouping in order\n",
    "                        if show_info:\n",
    "                            info_func(info_args, \"Grouping has been shuffled.\")\n",
    "                    else: ## search_method==\"ex\"\n",
    "                        if show_info:\n",
    "                            info_func(info_args, \"The stopping criterion determined that convergence to the optimum value was achieved.\")\n",
    "                        break\n",
    "            ## Local grouping: Select two clusters and perform an exchange between the two clusters\n",
    "            probability_tensor = copy.deepcopy(new_intergroup_weighted_cost_tensor)\n",
    "            cluster_1_value = (random.choices(probability_tensor, k=1, weights=probability_tensor))[0]\n",
    "            cluster_1_flattened_index_list = get_tensor_flattened_index_list_from_value(probability_tensor, cluster_1_value, tensor_tolerance)\n",
    "            cluster_1_flattened_index = random.choice(cluster_1_flattened_index_list)\n",
    "            cluster_1_multi_index = get_tensor_multi_index_from_flattened_index(cluster_1_flattened_index, N_rank, N_accum)\n",
    "            probability_tensor[cluster_1_flattened_index] = 0\n",
    "            cluster_2_value = (random.choices(probability_tensor, k=1, weights=probability_tensor))[0]\n",
    "            cluster_2_flattened_index_list = get_tensor_flattened_index_list_from_value(probability_tensor, cluster_2_value, tensor_tolerance)\n",
    "            cluster_2_flattened_index = random.choice(cluster_2_flattened_index_list)\n",
    "            cluster_2_multi_index = get_tensor_multi_index_from_flattened_index(cluster_2_flattened_index, N_rank, N_accum)\n",
    "            ## Preparation for local grouping\n",
    "            local_N_size = []\n",
    "            local_data_indexes = []\n",
    "            opt_local_grouping_indexes_list = []\n",
    "            ## local_N_size, local_data_indexes, opt_local_grouping_indexes_list, local_N_rank, local_N_accum, local_N_size_prod, local_marginal_mass_vectors\n",
    "            for local_group in range(N_rank):\n",
    "                if cluster_1_multi_index[local_group] == cluster_2_multi_index[local_group]:\n",
    "                    local_N_size.append(1)\n",
    "                    temp_index = new_grouping_indexes_list[local_group][cluster_1_multi_index[local_group]]\n",
    "                    local_data_indexes.append(temp_index)\n",
    "                    opt_local_grouping_indexes_list.append([temp_index])\n",
    "                else:\n",
    "                    local_N_size.append(2)\n",
    "                    temp_index_1 = new_grouping_indexes_list[local_group][cluster_1_multi_index[local_group]]\n",
    "                    temp_index_2 = new_grouping_indexes_list[local_group][cluster_2_multi_index[local_group]]\n",
    "                    local_data_indexes.append(temp_index_1)\n",
    "                    local_data_indexes.append(temp_index_2)\n",
    "                    opt_local_grouping_indexes_list.append([temp_index_1, temp_index_2])\n",
    "            local_N_size = tuple(local_N_size)\n",
    "            (local_N_rank, local_N_accum, local_N_size_prod) = get_N(local_N_size)\n",
    "            local_marginal_mass_vectors = calc_marginal_mass_vectors(local_N_rank, local_N_size)\n",
    "            ## Calculation of current local optimal transportation costs\n",
    "            (opt_local_adjusted_cost_value, opt_local_mean_cost_value, opt_local_deviation_cost_value,\n",
    "            opt_local_intragroup_cost_value, opt_local_intragroup_distance_nparray_list, opt_local_intragroup_adjacency_nparray_list, opt_local_intragroup_cost_list,\n",
    "            opt_local_intergroup_cost_value, opt_local_intergroup_P_tensor, opt_local_intergroup_weighted_cost_tensor,\n",
    "            opt_local_intergroup_u_vec_list, opt_local_intergroup_f_vec_list,\n",
    "            opt_local_intergroup_cost_tensor) = calc_adjusted_cost_value_with_mst(opt_local_grouping_indexes_list, data_points_nparray,\n",
    "                                                                                  local_marginal_mass_vectors,\n",
    "                                                                                  local_N_size, local_N_rank, local_N_accum, local_N_size_prod,\n",
    "                                                                                  mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                                                                                  numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "            old_local_adjusted_cost_value = opt_local_adjusted_cost_value\n",
    "            ## Enumeration of grouping patterns\n",
    "            ## (If N_rank is 2 or 3, all enumeration is used, and more than that, random selection is used.)\n",
    "            local_grouping_indexes_list_combinations = []\n",
    "            if local_N_rank == 2: ## It might be a good idea to have all the patterns ready in advance. (2^2-1=3)\n",
    "                numbers_list = list(range(sum(local_N_size)))\n",
    "                for sub_numbers_list_1 in itertools.combinations(numbers_list, local_N_size[0]):\n",
    "                    sub_numbers_list_2 = tuple(np.delete(numbers_list, sub_numbers_list_1, 0))\n",
    "                    temp_local_grouping_indexes_list = list((np.array(local_data_indexes))[list(sub_numbers_list_1+sub_numbers_list_2)])\n",
    "                    temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                    if temp_local_grouping_indexes_list != opt_local_grouping_indexes_list:\n",
    "                        local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            elif local_N_rank == 3: ## It might be a good idea to have all the patterns ready in advance. (2^3-1=7)\n",
    "                numbers_list = list(range(sum(local_N_size)))\n",
    "                for sub_numbers_list_1 in itertools.combinations(numbers_list, local_N_size[0]):\n",
    "                    temp_numbers_list = np.delete(numbers_list, sub_numbers_list_1, 0)\n",
    "                    for sub_numbers_list_2 in itertools.combinations(temp_numbers_list, local_N_size[1]):      \n",
    "                        sub_numbers_list_3 = tuple(np.delete(numbers_list, sub_numbers_list_1+sub_numbers_list_2, 0))\n",
    "                        temp_local_grouping_indexes_list = list((np.array(local_data_indexes))[list(sub_numbers_list_1+sub_numbers_list_2+sub_numbers_list_3)])\n",
    "                        temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                        if temp_local_grouping_indexes_list!= opt_local_grouping_indexes_list:\n",
    "                                local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            else:\n",
    "                for i in range(local_loop_max):\n",
    "                    temp_local_grouping_indexes_list = random.sample(local_data_indexes, len(local_data_indexes))\n",
    "                    temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                    if (temp_local_grouping_indexes_list!= opt_local_grouping_indexes_list) and (temp_local_grouping_indexes_list not in local_grouping_indexes_list_combinations):\n",
    "                                local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            ## Calculate the cost of local optimal transportation for each pattern of local grouping\n",
    "            opt_local_adjusted_cost_value = float('inf')\n",
    "            opt_local_grouping_indexes_list_list = []\n",
    "            for new_local_grouping_indexes_list in local_grouping_indexes_list_combinations:\n",
    "                (new_local_adjusted_cost_value, new_local_mean_cost_value, new_local_deviation_cost_value,\n",
    "                new_local_intragroup_cost_value, new_local_intragroup_distance_nparray_list, new_local_intragroup_adjacency_nparray_list, new_local_intragroup_cost_list,\n",
    "                new_local_intergroup_cost_value, new_local_intergroup_P_tensor, new_local_intergroup_weighted_cost_tenso,\n",
    "                new_local_intergroup_u_vec_list, new_local_intergroup_f_vec_list,\n",
    "                new_local_intergroup_cost_tensor) = calc_adjusted_cost_value_with_mst(new_local_grouping_indexes_list, data_points_nparray,\n",
    "                                                                                  local_marginal_mass_vectors,\n",
    "                                                                                  local_N_size, local_N_rank, local_N_accum, local_N_size_prod,\n",
    "                                                                                  mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                                                                                  numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "                if new_local_adjusted_cost_value < opt_local_adjusted_cost_value:\n",
    "                    opt_local_adjusted_cost_value = new_local_adjusted_cost_value\n",
    "                    opt_local_grouping_indexes_list_list = [new_local_grouping_indexes_list]\n",
    "                elif new_local_adjusted_cost_value == opt_local_adjusted_cost_value:\n",
    "                    opt_local_grouping_indexes_list_list.append(new_local_grouping_indexes_list)\n",
    "            opt_local_grouping_indexes_list = random.choice(opt_local_grouping_indexes_list_list)\n",
    "            random_number = random.random()\n",
    "            new_grouping_flag = (opt_local_adjusted_cost_value==0) or (random_number <= (old_local_adjusted_cost_value/opt_local_adjusted_cost_value))\n",
    "            if new_grouping_flag:\n",
    "                for group in range(local_N_rank):\n",
    "                    if local_N_size[group] == 1:\n",
    "                        new_grouping_indexes_list[group][cluster_1_multi_index[group]] = opt_local_grouping_indexes_list[group][0]\n",
    "                    else:\n",
    "                        new_grouping_indexes_list[group][cluster_1_multi_index[group]] = opt_local_grouping_indexes_list[group][0]\n",
    "                        new_grouping_indexes_list[group][cluster_2_multi_index[group]] = opt_local_grouping_indexes_list[group][1]\n",
    "        if new_grouping_flag:\n",
    "            ## Calculation of the cost of optimal transport\n",
    "            (new_adjusted_cost_value, new_mean_cost_value, new_deviation_cost_value,\n",
    "            new_intragroup_cost_value, new_intragroup_distance_nparray_list, new_intragroup_adjacency_nparray_list, new_intragroup_cost_list,\n",
    "            new_intergroup_cost_value, new_intergroup_P_tensor, \n",
    "            new_intergroup_weighted_cost_tensor, new_intergroup_u_vec_list, new_intergroup_f_vec_list, \n",
    "            new_intergroup_cost_tensor) = calc_adjusted_cost_value_with_mst(new_grouping_indexes_list, data_points_nparray,\n",
    "                                                                            marginal_mass_vectors,\n",
    "                                                                            N_size, N_rank, N_accum, N_size_prod,\n",
    "                                                                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                                                                            numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "        if show_info:\n",
    "            info_func(info_args, \"new_grouping_indexes_list: \" + str(new_grouping_indexes_list))\n",
    "            info_func(info_args, \"new_adjusted_cost_value: \" + str(new_adjusted_cost_value))\n",
    "        # if drawing_graphs:\n",
    "        #     (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "        #                                                 new_grouping_indexes_list, data_points_nparray, \n",
    "        #                                                 N_size, N_rank, N_accum, N_size_prod,\n",
    "        #                                                 viz2d_x, viz2d_y, new_intergroup_P_tensor)\n",
    "        #     # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "        #     #                             viz2d_x, viz2d_y, line_width = 1, f_size=(4,3,1), f_title=\"Mid-calculation\")\n",
    "        if new_adjusted_cost_value <= opt_adjusted_cost_value:\n",
    "            opt_grouping_indexes_list = copy.deepcopy(new_grouping_indexes_list)\n",
    "            opt_adjusted_cost_value = new_adjusted_cost_value\n",
    "            opt_mean_cost_value = new_mean_cost_value\n",
    "            opt_deviation_cost_value = new_deviation_cost_value\n",
    "            opt_intragroup_cost_value = new_intragroup_cost_value\n",
    "            opt_intergroup_cost_value = new_intergroup_cost_value\n",
    "            opt_intergroup_P_tensor = copy.deepcopy(new_intergroup_P_tensor)\n",
    "        ## Recording\n",
    "        iteration_number_list.append(loop+1)\n",
    "        elapsed_time = float(time.time() - start_time)\n",
    "        elapsed_time_list.append(elapsed_time)\n",
    "        new_adjusted_cost_trends_list.append(new_adjusted_cost_value)\n",
    "        opt_adjusted_cost_trends_list.append(opt_adjusted_cost_value)\n",
    "    ## info\n",
    "    if show_info:\n",
    "        info_func(info_args, \"---------- opt\")\n",
    "        info_func(info_args, \"opt_grouping_indexes_list: \" + str(init_grouping_indexes_list))\n",
    "        info_func(info_args, \"opt_adjusted_cost_value: \" + str(opt_adjusted_cost_value))\n",
    "        info_func(info_args, \"  (opt_intergroup_cost_value, opt_intragroup_cost_value: \" + str(opt_intergroup_cost_value) + \", \" + str(opt_intragroup_cost_value) + \")\")\n",
    "        info_func(info_args, \"  (mean_penalty_weight*opt_mean_cost_value, deviation_penalty_weight*opt_deviation_cost_value : \"\n",
    "              + str(mean_penalty_weight*opt_mean_cost_value) + \", \" + str(deviation_penalty_weight*opt_deviation_cost_value) + \")\")\n",
    "        ## Computation time\n",
    "        elapsed_hour = elapsed_time // 3600\n",
    "        elapsed_minute = (elapsed_time % 3600) // 60\n",
    "        elapsed_second = (elapsed_time % 3600 % 60)\n",
    "        info_func(info_args, \"computation time:\" + str(elapsed_hour).zfill(2) + \":\" + str(elapsed_minute).zfill(2) + \":\" + str(elapsed_second).zfill(2))\n",
    "    if drawing_graphs:\n",
    "        (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "                                            opt_grouping_indexes_list, data_points_nparray, \n",
    "                                            N_size, N_rank, N_accum, N_size_prod,\n",
    "                                            viz2d_x, viz2d_y, opt_intergroup_P_tensor)\n",
    "        # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, opt_grouping_indexes_list, data_points_nparray,\n",
    "        #                             viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "        show_P_tensor(opt_intergroup_P_tensor, N_size, N_rank, N_accum, f_size=(4,3), f_title=\"Optimal value\")\n",
    "     ## return\n",
    "    return (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "            opt_adjusted_cost_value,\n",
    "            opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "            opt_mean_cost_value, opt_deviation_cost_value,\n",
    "            iteration_number_list, elapsed_time_list,\n",
    "            new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "            viz2d_x, viz2d_y\n",
    "            )\n",
    "\n",
    "def gen_optimal_grouping_with_mst(data_points_nparray, N_size = None, standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 1.0,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## ## data_points_nparray: NumPy array consisting of data points\n",
    "    ## N_size: Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "    ## standardization = True ## Standardization\n",
    "    ## mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "    ## deviation_penalty_weight = 0.8 ## Weight of deviation_cost_value\n",
    "    ## order = 1.0 ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "    ## numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "    ## ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "    ## ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ## ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot\n",
    "    ## tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "    ## global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "    ## local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "    ## init_grouping_indexes_list = None ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## search_method = \"ex\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "    ## search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "    ## search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "    ## main_show_info = True ## Flag whether information is displayed or not\n",
    "    ## main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "    ## sub_show_info = False ## Flag whether information is displayed or not\n",
    "    ## sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "    ## info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "    ## info_args = None ## Arguments for info_func\n",
    "    ## tensor_size_max = 4000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "    ## group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "    ## loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "    ## viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## N_size\n",
    "    data_size = len(data_points_nparray)\n",
    "    if N_size is None:\n",
    "        info_func(info_args, \"Warning: N_size is None.\")\n",
    "        N_size = tuple(data_size)\n",
    "    if (type(N_size) == int):\n",
    "        if data_size > N_size:\n",
    "            (quotient, remainder) = divmod(data_size, N_size)\n",
    "            N_size = np.full(N_size, quotient)\n",
    "            for i in range(remainder):\n",
    "                N_size[i] = N_size[i] + 1\n",
    "            N_size = tuple(N_size)\n",
    "        else:\n",
    "            N_size = tuple(data_size)\n",
    "    elif (type(N_size) == tuple) or (type(N_size) == list):\n",
    "        N_size = tuple(N_size)\n",
    "        if data_size != sum(N_size):\n",
    "            info_func(info_args, \"Warning: The sum of N_size does not match sample size.\")\n",
    "            N_size = tuple(data_size)\n",
    "    else:\n",
    "        info_func(info_args, \"Warning: N_size must be of type integer or tuple.\")\n",
    "        N_size = tuple(data_size)\n",
    "    (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    res_calc_optimal_grouping = None\n",
    "    ## Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    ## Setting Parameters\n",
    "    if (N_size_prod > tensor_size_max) or (min(N_size) > group_size_max): ## If True, use \"approximate solution\".\n",
    "        ## Initial value settings\n",
    "        if init_grouping_indexes_list is None:\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "        else:\n",
    "            new_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "        if main_show_info:\n",
    "            info_func(info_args, \"---------- new_grouping_indexes_list (initial value): \" + str(new_grouping_indexes_list))\n",
    "        if main_drawing_graphs:\n",
    "            (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                        viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Initial value\")\n",
    "        for loop in range( loop_max_multiplier*N_rank ):\n",
    "            (group_1, group_2) = random.sample(list(range(N_rank)), 2)\n",
    "            sub_N_size = [N_size[group_1], N_size[group_2]]\n",
    "            group_1_sub_index = []\n",
    "            group_2_sub_index = []\n",
    "            if sub_N_size[0] > group_size_max:\n",
    "                group_1_sub_index = random.sample(list(range(sub_N_size[0])), group_size_max)\n",
    "                sub_N_size[0] = group_size_max\n",
    "            else:\n",
    "                group_1_sub_index = list(range(sub_N_size[0]))\n",
    "            if sub_N_size[1] > group_size_max:\n",
    "                group_2_sub_index = random.sample(list(range(sub_N_size[1])), group_size_max)\n",
    "                sub_N_size[1] = group_size_max\n",
    "            else:\n",
    "                group_2_sub_index = list(range(sub_N_size[1]))\n",
    "            sub_N_size = tuple(sub_N_size)\n",
    "            sub_data_index = list(np.array(new_grouping_indexes_list[group_1])[group_1_sub_index]) + list(np.array(new_grouping_indexes_list[group_2])[group_2_sub_index])\n",
    "            sub_data_points_nparray = data_points_nparray[sub_data_index]\n",
    "            (sub_N_rank, sub_N_accum, sub_N_size_prod) = get_N(sub_N_size)\n",
    "            res_calc_optimal_grouping = calc_optimal_grouping_with_mst(\n",
    "                sub_data_points_nparray, sub_N_size,\n",
    "                sub_N_rank, sub_N_accum, sub_N_size_prod,\n",
    "                mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                numerical_precision,\n",
    "                ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                None, True, ## init_grouping_indexes_list, init_grouping_rand,\n",
    "                search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                sub_show_info, sub_drawing_graphs,\n",
    "                info_func,\n",
    "                info_args,\n",
    "                viz2d_x, viz2d_y)\n",
    "            sub_opt_grouping_indexes_list = res_calc_optimal_grouping[0]\n",
    "            group_1_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[0]])\n",
    "            group_2_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[1]])\n",
    "            for i, index in enumerate(group_1_sub_index):\n",
    "                new_grouping_indexes_list[group_1][index] = group_1_sub_grouping_indexes_list[i]\n",
    "            for i, index in enumerate(group_2_sub_index):\n",
    "                new_grouping_indexes_list[group_2][index] = group_2_sub_grouping_indexes_list[i]\n",
    "            if main_show_info:\n",
    "                info_func(info_args, \"---------- loop (partial optimization): \" + str(loop+1))\n",
    "                info_func(info_args, \"---------- new_grouping_indexes_list (partial optimization): \" + str(new_grouping_indexes_list))\n",
    "            if (main_drawing_graphs) and (loop == (2*N_rank-1)):\n",
    "                (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                            viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "        res_calc_optimal_grouping = (new_grouping_indexes_list, \n",
    "                                     None, # opt_intergroup_P_tensor,\n",
    "                                     None, # opt_adjusted_cost_value,\n",
    "                                     None, # opt_intergroup_cost_value,\n",
    "                                     None, # opt_intragroup_cost_value,\n",
    "                                     None, # opt_mean_cost_value,\n",
    "                                     None, # opt_deviation_cost_value,\n",
    "                                     None, # iteration_number_list,\n",
    "                                     None, # elapsed_time_list,\n",
    "                                     None, # new_adjusted_cost_trends_list,\n",
    "                                     None, # opt_adjusted_cost_trends_list,\n",
    "                                     viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_mst(data_points_nparray, N_size,\n",
    "                            N_rank, N_accum, N_size_prod,\n",
    "                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_indexes_list, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            info_func,\n",
    "                            info_args,\n",
    "                            viz2d_x, viz2d_y)\n",
    "    ## res_calc_optimal_grouping:\n",
    "    ## (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "    ##  opt_adjusted_cost_value,\n",
    "    ##  opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "    ##  opt_mean_cost_value, opt_deviation_cost_value,\n",
    "    ##  iteration_number_list, elapsed_time_list,\n",
    "    ##  new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "    ##  viz2d_x, viz2d_y)\n",
    "    return res_calc_optimal_grouping\n",
    "\n",
    "def gen_optimal_grouping_from_csv_file_with_mst(input_filepath= \"./members.csv\", input_index_col = 0, output_filepath = \"./grouping.csv\",\n",
    "                           N_size = None,\n",
    "                           standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 1.0,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## input_filepath = \"./members.csv\" ## File path of the input file, in csv format.\n",
    "    ## input_index_col = 0 ## Column number with column name or column number in the csv file\n",
    "    ## output_filepath = \"./grouping.csv\" ##  File path of the output file, in csv format.\n",
    "    ############################\n",
    "    ## Loading data: loading csv files\n",
    "    df = pd.read_csv(filepath_or_buffer=input_filepath, index_col=input_index_col)\n",
    "    output_data = copy.deepcopy(df)\n",
    "    data_size = len(df)\n",
    "    ############################\n",
    "    ## Dummy variable processing: dummy variable for columns where dtype is object\n",
    "    df = pd.get_dummies(df, drop_first=True, dtype=\"float\") # float64, uint8, bool\n",
    "    ############################\n",
    "    ##  Handling missing values: interpolate by median\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    ############################\n",
    "    ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray_org = np.array(df.values)\n",
    "    data_points_nparray = copy.deepcopy(data_points_nparray_org) ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray = data_points_nparray.astype(float)\n",
    "    ###########################################\n",
    "    ## Data Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    ###########################################\n",
    "    ## Division and Search\n",
    "    (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "     opt_adjusted_cost_value,\n",
    "     opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "     opt_mean_cost_value, opt_deviation_cost_value,\n",
    "     iteration_number_list, elapsed_time_list,\n",
    "     new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "     viz2d_x, viz2d_y\n",
    "    ) = gen_optimal_grouping_with_mst(data_points_nparray, N_size, standardization,\n",
    "                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_indexes_list, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            sub_show_info, sub_drawing_graphs,\n",
    "                            info_func, info_args,\n",
    "                            tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                            viz2d_x, viz2d_y)\n",
    "    ###########################################\n",
    "    ## Output grouping results to csv file\n",
    "    group_labels_list = np.zeros(data_size)\n",
    "    group = 0\n",
    "    for members_list in opt_grouping_indexes_list:\n",
    "        for member in members_list:\n",
    "            group_labels_list[member] = int(group)\n",
    "        group = group + 1\n",
    "    output_data.insert(loc=0, column=\"Group\", value=group_labels_list.astype(int), allow_duplicates=True)\n",
    "    if (viz2d_x is not None) and (viz2d_y is not None):\n",
    "        output_data.insert(loc=1, column=\"viz2d_x\", value=viz2d_x.astype(float), allow_duplicates=True)\n",
    "        output_data.insert(loc=2, column=\"viz2d_y\", value=viz2d_y.astype(float), allow_duplicates=True)\n",
    "    output_data.to_csv(output_filepath)\n",
    "    ###########################################\n",
    "    ## Return\n",
    "    return (opt_grouping_indexes_list,\n",
    "            opt_intergroup_P_tensor,\n",
    "            opt_adjusted_cost_value,\n",
    "            opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "            opt_mean_cost_value, opt_deviation_cost_value,\n",
    "            iteration_number_list, elapsed_time_list,\n",
    "            new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "            output_data, viz2d_x, viz2d_y\n",
    "    )\n",
    "\n",
    "## Functions for calculating optrimal grouping\n",
    "def calc_optimal_grouping(data_points_nparray, N_size,\n",
    "                           N_rank = None, N_accum = None, N_size_prod = None,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.8,\n",
    "                           cost_type = \"mst\", order = None,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 10, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           show_info = False, drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    res_calc_optimal_grouping = None\n",
    "    if (cost_type == \"mst\"):\n",
    "        if(order == None):\n",
    "            order = 1.0\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_mst(data_points_nparray, N_size,\n",
    "                           N_rank, N_accum, N_size_prod,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           show_info, drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    elif(cost_type == \"bc\"):\n",
    "        if(order == None):\n",
    "            order = 2.0\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_bc(data_points_nparray, N_size,\n",
    "                           N_rank, N_accum, N_size_prod,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           show_info, drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        cost_type = \"mst\"\n",
    "        order = 1.0\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_mst(data_points_nparray, N_size,\n",
    "                           N_rank, N_accum, N_size_prod,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           show_info, drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    return res_calc_optimal_grouping\n",
    "\n",
    "def gen_optimal_grouping(data_points_nparray, N_size = None, standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1,\n",
    "                           cost_type = \"mst\", order = None,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## ## data_points_nparray: NumPy array consisting of data points\n",
    "    ## N_size: Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "    ## standardization = True ## Standardization\n",
    "    ## mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "    ## deviation_penalty_weight = 0.8 ## Weight of deviation_cost_value\n",
    "    ## cost_type = \"mst\" ## \"mst\": minimum spanning tree, \"bc\": barycenter\n",
    "    ## order = None ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "    ## numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "    ## ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "    ## ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ## ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot\n",
    "    ## tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "    ## global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "    ## local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "    ## init_grouping_indexes_list = None ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## search_method = \"ex\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "    ## search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "    ## search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "    ## main_show_info = True ## Flag whether information is displayed or not\n",
    "    ## main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "    ## sub_show_info = False ## Flag whether information is displayed or not\n",
    "    ## sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "    ## info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "    ## info_args = None ## Arguments for info_func\n",
    "    ## tensor_size_max = 4000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "    ## group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "    ## loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "    ## viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## N_size\n",
    "    res_gen_optimal_grouping = None\n",
    "    if (cost_type == \"mst\"):\n",
    "        if(order == None):\n",
    "            order = 1.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_with_mst(data_points_nparray, N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    elif(cost_type == \"bc\"):\n",
    "        if(order == None):\n",
    "            order = 2.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_with_bc(data_points_nparray, N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        cost_type = \"mst\"\n",
    "        order = 1.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_with_mst(data_points_nparray, N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    return res_gen_optimal_grouping\n",
    "\n",
    "def gen_optimal_grouping_from_csv_file(input_filepath= \"./members.csv\", input_index_col = 0, output_filepath = \"./grouping.csv\",\n",
    "                           N_size = None,\n",
    "                           standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1,\n",
    "                           cost_type = \"mst\", order = None,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## input_filepath = \"./members.csv\" ## File path of the input file, in csv format.\n",
    "    ## input_index_col = 0 ## Column number with column name or column number in the csv file\n",
    "    ## output_filepath = \"./grouping.csv\" ##  File path of the output file, in csv format.\n",
    "    res_gen_optimal_grouping = None\n",
    "    if (cost_type == \"mst\"):\n",
    "        if(order == None):\n",
    "            order = 1.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_from_csv_file_with_mst(input_filepath, input_index_col, output_filepath,\n",
    "                           N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    elif(cost_type == \"bc\"):\n",
    "        if(order == None):\n",
    "            order = 2.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_from_csv_file_with_bc(input_filepath, input_index_col, output_filepath,\n",
    "                           N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        cost_type = \"mst\"\n",
    "        order = 1.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_from_csv_file_with_mst(input_filepath, input_index_col, output_filepath,\n",
    "                           N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    return res_gen_optimal_grouping\n",
    "\n",
    "## Functions for displaying information and drawing graphs\n",
    "\n",
    "def cprint(txt, color=\"BRIGHT_CYAN\", end=\"\\n\"):\n",
    "    if os.name == 'nt':\n",
    "        COLORS = {\n",
    "        \"BLACK\": \"\\033[30m\",\n",
    "        \"RED\": \"\\033[31m\",\n",
    "        \"GREEN\": \"\\033[32m\",\n",
    "        \"YELLOW\": \"\\033[33m\",\n",
    "        \"BLUE\": \"\\033[34m\",\n",
    "        \"MAGENTA\": \"\\033[35m\",\n",
    "        \"CYAN\": \"\\033[36m\",\n",
    "        \"WHITE\": \"\\033[37m\",\n",
    "        \"DEFAULT_COLOR\": \"\\033[39m\",\n",
    "        \"GRAY\": \"\\033[90m\",\n",
    "        \"BRIGHT_RED\": \"\\033[91m\",\n",
    "        \"BRIGHT_GREEN\": \"\\033[92m\",\n",
    "        \"BRIGHT_YELLOW\": \"\\033[93m\",\n",
    "        \"BRIGHT_BLUE\": \"\\033[94m\",\n",
    "        \"BRIGHT_MAGENTA\": \"\\033[95m\",\n",
    "        \"BRIGHT_CYAN\": \"\\033[96m\",\n",
    "        \"BRIGHT_WHITE\": \"\\033[97m\",\n",
    "        }\n",
    "        END = \"\\033[0m\"\n",
    "        print(COLORS[color] + txt + END, end=end)\n",
    "    else:\n",
    "        print(txt)\n",
    "\n",
    "def get_rank_vec(v):\n",
    "    n = len(v)\n",
    "    rank = [0]*n\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if v[i]>v[j]:\n",
    "                rank[j] = rank[j] + 1\n",
    "            else:\n",
    "                rank[i] = rank[i] + 1\n",
    "    return rank\n",
    "\n",
    "def get_points_list_in_non_intersecting_order(x, y):\n",
    "    n = len(x)\n",
    "    qcos_vec = [0]*n\n",
    "    reference_index = y.index(min(y))\n",
    "    qcos_vec[reference_index] = 2\n",
    "    indices_rem = (list(range(n)))\n",
    "    indices_rem.pop(reference_index)\n",
    "    range_x = max(x)-min(x)\n",
    "    for i in indices_rem:\n",
    "        dx = (x[i]-x[reference_index])\n",
    "        dy = (y[i]-y[reference_index])\n",
    "        dr = math.sqrt(dx*dx + dy*dy)\n",
    "        if dr == 0:\n",
    "            qcos_vec[i] = 2\n",
    "        elif dx == dr:\n",
    "            qcos_vec[i] = 2 - dx/range_x\n",
    "        elif dx == -dr:\n",
    "            qcos_vec[i] = -2 - dx/range_x\n",
    "        else:\n",
    "            qcos_vec[i] = dx/dr\n",
    "    rank_cos = get_rank_vec(qcos_vec)\n",
    "    points = [[]]*n\n",
    "    for i in range(n):\n",
    "        points[rank_cos[i]] = [x[i], y[i]]\n",
    "    return points\n",
    "\n",
    "def show_P_tensor(P_tensor, N_size, N_rank, N_accum, f_size=(6,4), numerical_precision=1e-8, f_title=\"\"):\n",
    "    ## Draw the graph of the tensor of the solution of the grouping\n",
    "    ## The horizontal axis is the groups (1～N_rank) and the vertical axis is the number of elements belonging to each group (N_size).\n",
    "    ## A single line corresponds to one element of the tensor. The higher the value, the thicker the line.\n",
    "    ## ------------------------------\n",
    "    ## Visualization of P_tensor\n",
    "    x = list(range(N_rank))\n",
    "    x = [element+1 for element in x]\n",
    "    fig = plt.figure(figsize = (f_size[0], f_size[1]), facecolor=\"mistyrose\")\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(f_title)\n",
    "    ax.set_xlim((0, N_rank+1))\n",
    "    ax.set_ylim((0, max(N_size)+1))\n",
    "    P_max = max(P_tensor)\n",
    "    for m_index in np.ndindex(tuple(N_size)):\n",
    "        temp_y = list(m_index)\n",
    "        temp_y = [element+1 for element in temp_y]\n",
    "        temp_P_ratio = P_tensor[get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)] / (P_max + numerical_precision)\n",
    "        lwd = 10*math.sqrt(temp_P_ratio) # 10 * math.log( math.exp(1) - 1 + temp_P_ratio　)\n",
    "        ax.plot(x, temp_y, linewidth=lwd, alpha=0.5)\n",
    "\n",
    "def gen_2d_data(is_umap_loaded, data_points_nparray):\n",
    "    if len(data_points_nparray[0,:]) > 2:\n",
    "        if is_umap_loaded:\n",
    "            ## Umap\n",
    "            print(\"Umapping...\", flush=\"True\")\n",
    "            mapper = umap.UMAP(random_state=0)\n",
    "            embedding = mapper.fit_transform(data_points_nparray)\n",
    "            return (embedding[:,0], embedding[:,1])\n",
    "        else:\n",
    "            print(\"For two-dimensional visualization, use only the first and second variables.\")\n",
    "            return (data_points_nparray[:,0], data_points_nparray[:,1])\n",
    "    elif len(data_points_nparray[0,:]) == 2:\n",
    "        return (data_points_nparray[:,0], data_points_nparray[:,1])\n",
    "    elif len(data_points_nparray[0,:]) == 1:\n",
    "        return (data_points_nparray[:,0], np.zeros(len(data_points_nparray[:,0])))\n",
    "    else:\n",
    "        return ([0], [0])\n",
    "\n",
    "def show_2d_data(is_umap_loaded, grouping_indexes_list, data_points_nparray,\n",
    "                 viz2d_x = None, viz2d_y = None, line_width = 1, f_size=(8,6,4), f_title=\"\"):\n",
    "    ## Visualization of two-dimensional data\n",
    "    ## Each group is arranged in order of starting point (tau) to ending point (nu).\n",
    "    len_data_points_nparray = len(data_points_nparray)\n",
    "    if len_data_points_nparray > 20:\n",
    "        line_width = 0\n",
    "    if grouping_indexes_list is None:\n",
    "        grouping_indexes_list = [list(range(len_data_points_nparray))]\n",
    "    if (viz2d_x is None) or (viz2d_y is None):\n",
    "        viz2d_x, viz2d_y = gen_2d_data(is_umap_loaded, data_points_nparray)\n",
    "    x_min = min(viz2d_x)\n",
    "    x_max = max(viz2d_x)\n",
    "    x_range = x_max - x_min\n",
    "    y_min = 0\n",
    "    y_max = 0\n",
    "    y_range = 0\n",
    "    if len(data_points_nparray[0,:]) > 1:\n",
    "        viz2d_y = viz2d_y\n",
    "        y_min = min(viz2d_y)\n",
    "        y_max = max(viz2d_y)\n",
    "        y_range = y_max - y_min\n",
    "    figsize_x = f_size[0]\n",
    "    figsize_y = f_size[1]\n",
    "    if max(x_range, y_range) <= 0:\n",
    "        figsize_x = f_size[0]\n",
    "        figsize_y = f_size[1]\n",
    "    elif x_range > y_range:\n",
    "        figsize_x = f_size[0]\n",
    "        figsize_y = max(f_size[2] ,min(f_size[1], f_size[1]*(y_range/x_range)))\n",
    "    else:\n",
    "        figsize_y = f_size[1]\n",
    "        figsize_x = max(f_size[2] ,min(f_size[1], f_size[1]*(x_range/y_range)))\n",
    "    fig = plt.figure(figsize = (figsize_x, figsize_y), facecolor=\"mistyrose\")\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim((x_min-2, x_max+2))\n",
    "    ax.set_ylim((y_min-2, y_max+2))\n",
    "    colors = cm.tab10 # cm.tab20\n",
    "    len_colors = 10\n",
    "    markers = [\"o\", \"^\", \"s\", \"p\", \"D\", \"H\", \"*\", \"v\", \"<\", \">\",  \n",
    "                \"+\", \"x\", \".\", \",\", \"d\", \"h\", \"1\", \"2\", \"3\", \"4\", \"8\", \"|\", \"_\"]\n",
    "    for group, index_list in enumerate(grouping_indexes_list):\n",
    "        if len(index_list)>0:\n",
    "            x = []\n",
    "            y = []\n",
    "            x_start = [] # Starting point: tau\n",
    "            y_start = [] # Starting point: tau\n",
    "            x_end = [] # Ending point: nu\n",
    "            y_end = [] # Ending point: nu\n",
    "            p_color = colors(int(group)%len_colors)\n",
    "            p_marker = markers[int(group)%len(markers)]\n",
    "            for j, element in enumerate(index_list):\n",
    "                x.append(viz2d_x[element])\n",
    "                y.append(viz2d_y[element])\n",
    "                if j==0:\n",
    "                    x_start = [viz2d_x[element]]\n",
    "                    y_start = [viz2d_y[element]]\n",
    "                elif j==(len(index_list)-1):\n",
    "                    x_end = [viz2d_x[element]]\n",
    "                    y_end = [viz2d_y[element]]\n",
    "            ax.plot(x, y, alpha=0.5, color=p_color, marker=p_marker, markersize=12, linewidth=line_width)\n",
    "            ax.set_title(f_title)\n",
    "            if line_width > 0:\n",
    "                ## Starting point: tau\n",
    "                ax.plot(x_start, y_start, alpha=0.5, marker=\"$\\\\tau$\", markersize=6, color=\"black\")\n",
    "                ## Ending point: nu\n",
    "                ax.plot(x_end, y_end, alpha=0.5, marker=\"$\\\\nu$\", markersize=6, color=\"black\")\n",
    "    return (fig, ax, viz2d_x, viz2d_y)\n",
    "\n",
    "def show_2d_data_with_patches(is_umap_loaded, grouping_indexes_list, data_points_nparray, \n",
    "                              N_size, N_rank, N_accum, N_size_prod,\n",
    "                              viz2d_x = None, viz2d_y = None, patch_weight = None, line_width = 1, f_size=(8,6,4), f_title=\"\"):\n",
    "    (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, grouping_indexes_list, data_points_nparray,\n",
    "                                               viz2d_x, viz2d_y,\n",
    "                                               line_width = 1, f_size=(8,6,4), f_title=\"\")\n",
    "    if patch_weight is not None:\n",
    "        patch_weight_max = max(patch_weight)\n",
    "        if patch_weight_max > 0:\n",
    "            if (N_rank is None) or (N_accum is None) or (N_size_prod is None):\n",
    "                (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "            for m_index in np.ndindex(N_size):\n",
    "                w = get_tensor_value_from_multi_index(patch_weight, m_index, N_rank, N_accum)\n",
    "                alp = w / patch_weight_max\n",
    "                alp = 0.5 * alp / N_rank\n",
    "                if alp > 0.001:\n",
    "                    x_vec = []\n",
    "                    y_vec = []\n",
    "                    for group in range(N_rank):\n",
    "                        index_value = grouping_indexes_list[group][m_index[group]]\n",
    "                        x_vec.append(viz2d_x[index_value])\n",
    "                        y_vec.append(viz2d_y[index_value])\n",
    "                    if N_rank > 2:\n",
    "                        points = get_points_list_in_non_intersecting_order(x_vec, y_vec)\n",
    "                        patch = patches.Polygon(xy=points, closed=True, alpha=alp, color='black')\n",
    "                        ax.add_patch(patch)\n",
    "                    elif N_rank == 2:\n",
    "                        ax.plot(x_vec, y_vec, alpha=alp, color='black',\n",
    "                                marker=None, linestyle='solid', linewidth=2)\n",
    "    return (fig, ax, viz2d_x, viz2d_y)\n",
    "\n",
    "def get_argmax_list(target_tensor, fixed_group_list, fixed_element_list, \n",
    "                    N_size, N_rank, N_accum):\n",
    "    N_size_partially_fixed = copy.deepcopy(N_size)\n",
    "    N_size_partially_fixed = list(N_size_partially_fixed)\n",
    "    if (len(fixed_group_list)!=0) and (len(fixed_group_list)==len(fixed_element_list)):\n",
    "        for group in fixed_group_list:\n",
    "            N_size_partially_fixed[group] = 1\n",
    "    N_size_partially_fixed = tuple(N_size_partially_fixed)\n",
    "    temp_max = 0\n",
    "    argmax_list = []\n",
    "    for m_index in np.ndindex(N_size_partially_fixed):\n",
    "        m_index_list = list(m_index)\n",
    "        if (len(fixed_group_list)!=0) and (len(fixed_group_list)==len(fixed_element_list)):\n",
    "            for element, group in enumerate(fixed_group_list):\n",
    "                m_index_list[group] = fixed_element_list[element]\n",
    "        temp_value = target_tensor[get_tensor_flattened_index_from_multi_index(m_index_list, N_rank, N_accum)]\n",
    "        if temp_value == temp_max:\n",
    "            argmax_list.append(m_index_list)\n",
    "        elif temp_value > temp_max:\n",
    "            temp_max = temp_value\n",
    "            argmax_list = [m_index_list]\n",
    "    return argmax_list\n",
    "\n",
    "def get_marginal_value(target_tensor, fixed_group_list, fixed_element_list, \n",
    "                       N_size, N_rank, N_accum):\n",
    "    N_size_partially_fixed = copy.deepcopy(N_size)\n",
    "    N_size_partially_fixed = list(N_size_partially_fixed)\n",
    "    if (len(fixed_group_list)!=0) and (len(fixed_group_list)==len(fixed_element_list)):\n",
    "        for group in fixed_group_list:\n",
    "            N_size_partially_fixed[group] = 1\n",
    "    N_size_partially_fixed = tuple(N_size_partially_fixed)\n",
    "    marginal_value = 0\n",
    "    for m_index in np.ndindex(N_size_partially_fixed):\n",
    "        m_index_list = list(m_index)\n",
    "        if (len(fixed_group_list)!=0) and (len(fixed_group_list)==len(fixed_element_list)):\n",
    "            for element, group in enumerate(fixed_group_list):\n",
    "                m_index_list[group] = fixed_element_list[element]\n",
    "        temp_value = target_tensor[get_tensor_flattened_index_from_multi_index(m_index_list, N_rank, N_accum)]\n",
    "        marginal_value = marginal_value + temp_value\n",
    "    return marginal_value\n",
    "\n",
    "############################################################\n",
    "#### GUI with Flet ####\n",
    "\n",
    "class FletParameters:\n",
    "    input_filepath = \"./input.csv\"\n",
    "    input_filename = \"input.csv\"\n",
    "    input_filedirectory = \"./\"\n",
    "    input_index_col = None\n",
    "    df_org = None\n",
    "    df_cleaned = None\n",
    "    fig = None\n",
    "    ax = None\n",
    "    output_filename = \"output.csv\"\n",
    "    output_data = None\n",
    "    group_labels_list = None\n",
    "    opt_grouping_indexes_list = None\n",
    "    opt_intergroup_P_tensor = None\n",
    "    N_size = None ## Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "    N_rank = None\n",
    "    N_accum = None\n",
    "    N_size_prod = None\n",
    "    standardization = False ## Standardization\n",
    "    mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "    deviation_penalty_weight = 0.1 ## Weight of deviation_cost_value\n",
    "    cost_type = \"mst\" ## \"mst\": minimum spanning tree, \"bc\": barycenter\n",
    "    order = None ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "    numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "    ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "    ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot\n",
    "    tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "    global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "    local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "    init_grouping_indexes_list = None ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    search_method = \"ex\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "    search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "    search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "    main_show_info = True ## Flag whether information is displayed or not\n",
    "    main_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "    sub_show_info = False ## Flag whether information is displayed or not\n",
    "    sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "    info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "    info_args = None ## Arguments for info_func\n",
    "    tensor_size_max = 4000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "    group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "    loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "    viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "\n",
    "def load_csv(input_filepath, input_index_col, standardization=False):\n",
    "    ## Loading data: loading csv file\n",
    "    df_cleaned = pd.read_csv(filepath_or_buffer=input_filepath, index_col=input_index_col)\n",
    "    df_org = copy.deepcopy(df_cleaned)\n",
    "    ## Dummy variable processing: dummy variable for columns where dtype is object\n",
    "    df_cleaned = pd.get_dummies(df_cleaned, drop_first=True, dtype=\"float\") # float64, uint8, bool\n",
    "    ##  Handling missing values: interpolate by median\n",
    "    for col in df_cleaned.columns:\n",
    "        df_cleaned[col] = df_cleaned[col].fillna(df_cleaned[col].median())\n",
    "    ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray_org = np.array(df_cleaned.values)\n",
    "    data_points_nparray = copy.deepcopy(data_points_nparray_org) ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray = data_points_nparray.astype(float)\n",
    "    ## Data Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    ## 2d\n",
    "    viz2d_x, viz2d_y = gen_2d_data(is_umap_loaded, data_points_nparray)\n",
    "    ## return\n",
    "    return (df_org, df_cleaned, viz2d_x, viz2d_y)\n",
    "    \n",
    "def gen_grouping_in_flet(df, N_size = None,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1,\n",
    "                           cost_type = \"mst\", order = 1.0,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = False,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    data_points_nparray = np.array(df.values)\n",
    "    if search_method == \"ex\":\n",
    "        info_func(info_args, \"Search for optimal values using the exchange algorithm.\") \n",
    "    elif search_method == \"hybrid\":\n",
    "        info_func(info_args, \"Search for optimal values using the hybrid algorithm.\")\n",
    "    else:\n",
    "        info_func(info_args, \"Search for optimal values at random.\")\n",
    "    ## N_size\n",
    "    data_size = len(data_points_nparray)\n",
    "    if N_size is None:\n",
    "        info_func(info_args, \"Warning: N_size is None.\")\n",
    "        N_size = tuple(data_size)\n",
    "    if (type(N_size) == int):\n",
    "        if data_size > N_size:\n",
    "            (quotient, remainder) = divmod(data_size, N_size)\n",
    "            N_size = np.full(N_size, quotient)\n",
    "            for i in range(remainder):\n",
    "                N_size[i] = N_size[i] + 1\n",
    "            N_size = tuple(N_size)\n",
    "        else:\n",
    "            N_size = tuple(data_size)\n",
    "    elif (type(N_size) == tuple) or (type(N_size) == list):\n",
    "        N_size = tuple(N_size)\n",
    "        if data_size != sum(N_size):\n",
    "            info_func(info_args, \"Warning: The sum of N_size does not match sample size.\")\n",
    "            N_size = tuple(data_size)\n",
    "    else:\n",
    "        info_func(info_args, \"Warning: N_size must be of type integer or tuple.\")\n",
    "        N_size = tuple(data_size)\n",
    "    (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    ## Setting Parameters\n",
    "    res_calc_optimal_grouping = None\n",
    "    if (N_size_prod > tensor_size_max) or (min(N_size) > group_size_max): ## If True, use \"approximate solution\".\n",
    "        ## Initial value settings\n",
    "        if init_grouping_indexes_list is None:\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "        else:\n",
    "            new_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "        if main_show_info:\n",
    "            info_func(info_args, \"---------- new_grouping_indexes_list (initial value): \" + str(new_grouping_indexes_list))\n",
    "        if main_drawing_graphs:\n",
    "            (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                        viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Initial value\")\n",
    "        for loop in range( loop_max_multiplier*N_rank ):\n",
    "            (group_1, group_2) = random.sample(list(range(N_rank)), 2)\n",
    "            sub_N_size = [N_size[group_1], N_size[group_2]]\n",
    "            group_1_sub_index = []\n",
    "            group_2_sub_index = []\n",
    "            if sub_N_size[0] > group_size_max:\n",
    "                group_1_sub_index = random.sample(list(range(sub_N_size[0])), group_size_max)\n",
    "                sub_N_size[0] = group_size_max\n",
    "            else:\n",
    "                group_1_sub_index = list(range(sub_N_size[0]))\n",
    "            if sub_N_size[1] > group_size_max:\n",
    "                group_2_sub_index = random.sample(list(range(sub_N_size[1])), group_size_max)\n",
    "                sub_N_size[1] = group_size_max\n",
    "            else:\n",
    "                group_2_sub_index = list(range(sub_N_size[1]))\n",
    "            sub_N_size = tuple(sub_N_size)\n",
    "            sub_data_index = list(np.array(new_grouping_indexes_list[group_1])[group_1_sub_index]) + list(np.array(new_grouping_indexes_list[group_2])[group_2_sub_index])\n",
    "            sub_data_points_nparray = data_points_nparray[sub_data_index]\n",
    "            (sub_N_rank, sub_N_accum, sub_N_size_prod) = get_N(sub_N_size)\n",
    "            res_calc_optimal_grouping = calc_optimal_grouping(\n",
    "                sub_data_points_nparray, sub_N_size,\n",
    "                sub_N_rank, sub_N_accum, sub_N_size_prod,\n",
    "                mean_penalty_weight, deviation_penalty_weight,\n",
    "                cost_type, order,\n",
    "                numerical_precision,\n",
    "                ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                None, True, ## init_grouping_indexes_list, init_grouping_rand,\n",
    "                search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                sub_show_info, sub_drawing_graphs,\n",
    "                info_func, info_args,\n",
    "                viz2d_x, viz2d_y)\n",
    "            sub_opt_grouping_indexes_list = res_calc_optimal_grouping[0]\n",
    "            group_1_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[0]])\n",
    "            group_2_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[1]])\n",
    "            for i, index in enumerate(group_1_sub_index):\n",
    "                new_grouping_indexes_list[group_1][index] = group_1_sub_grouping_indexes_list[i]\n",
    "            for i, index in enumerate(group_2_sub_index):\n",
    "                new_grouping_indexes_list[group_2][index] = group_2_sub_grouping_indexes_list[i]\n",
    "            if main_show_info:\n",
    "                info_func(info_args, \"---------- loop (partial optimization): \" + str(loop+1))\n",
    "                info_func(info_args, \"---------- new_grouping_indexes_list (partial optimization): \" + str(new_grouping_indexes_list))\n",
    "            if (main_drawing_graphs) and (loop == (2*N_rank-1)):\n",
    "                (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                            viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "    else:\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping(data_points_nparray, N_size,\n",
    "                            N_rank, N_accum, N_size_prod,\n",
    "                            mean_penalty_weight, deviation_penalty_weight,\n",
    "                            cost_type, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_indexes_list, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            info_func, info_args,\n",
    "                            viz2d_x, viz2d_y)\n",
    "    ###########################################\n",
    "    opt_grouping_indexes_list = res_calc_optimal_grouping[0]\n",
    "    opt_intergroup_P_tensor = res_calc_optimal_grouping[1]\n",
    "    ## Output grouping results\n",
    "    output_data = copy.deepcopy(df)\n",
    "    group_labels_list = np.zeros(data_size)\n",
    "    group = 0\n",
    "    for members_list in opt_grouping_indexes_list:\n",
    "        for member in members_list:\n",
    "            group_labels_list[member] = int(group)\n",
    "        group = group + 1\n",
    "    output_data.insert(loc=0, column=\"Group\", value=group_labels_list.astype(int), allow_duplicates=True)\n",
    "    output_data.insert(loc=1, column=\"viz2d_x\", value=viz2d_x.astype(float), allow_duplicates=True)\n",
    "    output_data.insert(loc=2, column=\"viz2d_y\", value=viz2d_y.astype(float), allow_duplicates=True)\n",
    "    return (output_data, group_labels_list, opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "            N_size, N_rank, N_accum, N_size_prod)\n",
    "\n",
    "def draw_graph_in_flet(fig, ax, index_values, viz2d_x, viz2d_y,\n",
    "                        group_labels_list = None, \n",
    "                        grouping_indexes_list = None, patch_weight = None,\n",
    "                        N_size = None, N_rank = None, N_accum = None, N_size_prod = None):\n",
    "    ax.cla()\n",
    "    fig.set_facecolor(\"#C0C0C0\") ## silver=#C0C0C0, lightgray=#D3D3D3, whitesmoke=#F5F5F5, snow=#FFFAFA\n",
    "    ax.set_facecolor(\"#F5F5F5\") ## silver=#C0C0C0, lightgray=#D3D3D3, whitesmoke=#F5F5F5, snow=#FFFAFA\n",
    "    ax.set_xlabel(\"viz2d_x\")\n",
    "    ax.set_ylabel(\"viz2d_y\")\n",
    "    if group_labels_list is None:\n",
    "        ax.plot(viz2d_x, viz2d_y, alpha=0.5, marker=\"o\", markersize=10, linewidth=0)\n",
    "        for i, lab in enumerate(index_values): ## labels\n",
    "            ax.annotate(lab, (viz2d_x[i], viz2d_y[i]))  \n",
    "    else:\n",
    "        colors = cm.tab10 # cm.tab20\n",
    "        len_colors = 10\n",
    "        markers = [\"o\", \"^\", \"s\", \"p\", \"D\", \"H\", \"*\", \"v\", \"<\", \">\",  \n",
    "                    \"+\", \"x\", \".\", \",\", \"d\", \"h\", \"1\", \"2\", \"3\", \"4\", \"8\", \"|\", \"_\"]\n",
    "        for i, lab in enumerate(index_values):\n",
    "            p_color = colors(int(group_labels_list[i])%len_colors)\n",
    "            p_marker = markers[int(group_labels_list[i])%len(markers)]\n",
    "            ax.plot(viz2d_x[i], viz2d_y[i],\n",
    "                            color=p_color, marker=p_marker,\n",
    "                            alpha=0.5, markersize=10, linewidth=0)\n",
    "            ax.annotate(lab, (viz2d_x[i], viz2d_y[i]))\n",
    "        if patch_weight is not None:\n",
    "            patch_weight_max = max(patch_weight)\n",
    "            if (N_rank is None) or (N_accum is None) or (N_size_prod is None):\n",
    "                (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "            for m_index in np.ndindex(N_size):\n",
    "                w = get_tensor_value_from_multi_index(patch_weight, m_index, N_rank, N_accum)\n",
    "                alp = w / patch_weight_max\n",
    "                alp = 0.5 * alp / N_rank\n",
    "                if alp > 0.001:\n",
    "                    x_vec = []\n",
    "                    y_vec = []\n",
    "                    for group in range(N_rank):\n",
    "                        index_value = grouping_indexes_list[group][m_index[group]]\n",
    "                        x_vec.append(viz2d_x[index_value])\n",
    "                        y_vec.append(viz2d_y[index_value])\n",
    "                    if N_rank > 2:\n",
    "                        points = get_points_list_in_non_intersecting_order(x_vec, y_vec)\n",
    "                        patch = patches.Polygon(xy=points, closed=True, alpha=alp, color='black')\n",
    "                        ax.add_patch(patch)\n",
    "                    elif N_rank == 2:\n",
    "                        ax.plot(x_vec, y_vec, alpha=alp, color='black',\n",
    "                                marker=None, linestyle='solid', linewidth=2)\n",
    "\n",
    "def main(page: ft.Page):\n",
    "    ## Functions\n",
    "    def minus_click(e):\n",
    "        number_of_divisions.value = str(int(number_of_divisions.value) - 1) if int(number_of_divisions.value) > 1 else \"1\"\n",
    "        number_of_divisions.update()\n",
    "        output_filename_text.value = \"\"\n",
    "        output_filename_text.update()\n",
    "        FletParameters.N_size = int(number_of_divisions.value)\n",
    "    \n",
    "    def plus_click(e):\n",
    "        number_of_divisions.value = str(int(number_of_divisions.value) + 1) if int(number_of_divisions.value) > 0 else \"1\"\n",
    "        number_of_divisions.update() \n",
    "        output_filename_text.value = \"\"\n",
    "        output_filename_text.update()\n",
    "        FletParameters.N_size = int(number_of_divisions.value)\n",
    "    \n",
    "    def speed_slider_changed(e):\n",
    "        FletParameters.ot_speed = float(speed_slider.value)\n",
    "    \n",
    "    def m_weight_slider_changed(e):\n",
    "        FletParameters.mean_penalty_weight = float(m_weight_slider.value)\n",
    "    \n",
    "    def d_weight_slider_changed(e):\n",
    "        FletParameters.deviation_penalty_weight = float(d_weight_slider.value)\n",
    "    \n",
    "    def method_dropdown_changed(e): ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "        if method_dropdown.value == \"Heuristics\":\n",
    "            FletParameters.search_method = \"ex\"\n",
    "        elif method_dropdown.value == \"Hybrid\":\n",
    "            FletParameters.search_method = \"hybrid\"\n",
    "        else:\n",
    "            FletParameters.search_method = \"rand\"     \n",
    "\n",
    "    def pick_files_result(e: ft.FilePickerResultEvent):\n",
    "        selected_files.value = (\n",
    "            \", \".join(map(lambda f: f.name, e.files)) if e.files else \"Cancelled!\"\n",
    "        )\n",
    "        selected_files.update()\n",
    "        FletParameters.input_filepath = e.files[0].path\n",
    "        FletParameters.input_filename = e.files[0].name\n",
    "        FletParameters.input_filedirectory = FletParameters.input_filename.removesuffix(FletParameters.input_filename)\n",
    "        FletParameters.input_index_col = 0\n",
    "        pick_files_button.disabled = True\n",
    "        pick_files_button.update()\n",
    "        start_button.disabled = True\n",
    "        start_button.update()\n",
    "        progress_bar.value = None\n",
    "        progress_bar.update()\n",
    "        grouping_text.value = \"\"\n",
    "        grouping_text.update()\n",
    "        output_filename_text.value = \"\"\n",
    "        output_filename_text.update()\n",
    "        (FletParameters.df_org, FletParameters.df_cleaned, \n",
    "         FletParameters.viz2d_x, FletParameters.viz2d_y) = load_csv(\n",
    "             FletParameters.input_filepath, FletParameters.input_index_col, FletParameters.standardization)\n",
    "        pick_files_button.disabled = False\n",
    "        pick_files_button.update()\n",
    "        start_button.disabled = False\n",
    "        start_button.update()\n",
    "        progress_bar.value = 100\n",
    "        progress_bar.update()\n",
    "        data_textfield.value = str(FletParameters.df_org)\n",
    "        data_textfield.update()\n",
    "        draw_graph_in_flet(FletParameters.fig, FletParameters.ax, \n",
    "                          FletParameters.df_org.index.values, \n",
    "                          FletParameters.viz2d_x, FletParameters.viz2d_y)\n",
    "        data_chart.update() \n",
    "        start_button.disabled = False\n",
    "        start_button.update()\n",
    "        progress_bar.value = 0\n",
    "        progress_bar.update()\n",
    "        FletParameters.info_history = \"\"\n",
    "        info_textfield.value = FletParameters.info_history\n",
    "        info_textfield.update()\n",
    "    \n",
    "    def start_grouping(e):\n",
    "        pick_files_button.disabled = True\n",
    "        pick_files_button.update()\n",
    "        start_button.disabled = True\n",
    "        start_button.update()\n",
    "        progress_bar.value = None\n",
    "        progress_bar.update()\n",
    "        grouping_text.value = \"\"\n",
    "        grouping_text.update()\n",
    "        output_filename_text.value = \"\"\n",
    "        output_filename_text.update()\n",
    "        FletParameters.info_history = \"\"\n",
    "        info_textfield.value = \"\"\n",
    "        info_textfield.update()\n",
    "        (FletParameters.output_data, FletParameters.group_labels_list,\n",
    "         FletParameters.opt_grouping_indexes_list, FletParameters.opt_intergroup_P_tensor,\n",
    "         FletParameters.N_size, FletParameters.N_rank,\n",
    "         FletParameters.N_accum, FletParameters.N_size_prod) = gen_grouping_in_flet(\n",
    "            FletParameters.df_cleaned, FletParameters.N_size,\n",
    "            FletParameters.mean_penalty_weight, FletParameters.deviation_penalty_weight,\n",
    "            FletParameters.cost_type, FletParameters.order,\n",
    "            FletParameters.numerical_precision,\n",
    "            FletParameters.ot_speed, FletParameters.ot_stopping_rule, FletParameters.ot_loop_max,\n",
    "            FletParameters.tensor_tolerance, FletParameters.global_loop_max, FletParameters.local_loop_max,\n",
    "            FletParameters.init_grouping_indexes_list, FletParameters.init_grouping_rand,\n",
    "            FletParameters.search_method, FletParameters.search_stopping_rule_err, FletParameters.search_stopping_rule_rep,\n",
    "            FletParameters.main_show_info, FletParameters.main_drawing_graphs,\n",
    "            FletParameters.sub_show_info, FletParameters.sub_drawing_graphs,\n",
    "            FletParameters.info_func,\n",
    "            None, ## info_args # [FletParameters.info_address, FletParameters.info_history],\n",
    "            FletParameters.tensor_size_max, FletParameters.group_size_max, FletParameters.loop_max_multiplier,\n",
    "            FletParameters.viz2d_x, FletParameters.viz2d_y)\n",
    "        pick_files_button.disabled = False\n",
    "        pick_files_button.update()\n",
    "        start_button.disabled = False\n",
    "        start_button.update()\n",
    "        progress_bar.value = 100\n",
    "        progress_bar.update()\n",
    "        group_index_text = (str(FletParameters.group_labels_list.astype(int)))\n",
    "        if len(group_index_text) > 32:\n",
    "            group_index_text = group_index_text[:32] + \" ...\"\n",
    "        grouping_text.value = \"Group index: \" + group_index_text\n",
    "        grouping_text.update()\n",
    "        draw_graph_in_flet(FletParameters.fig, FletParameters.ax,\n",
    "                          FletParameters.df_org.index.values,\n",
    "                          FletParameters.viz2d_x, FletParameters.viz2d_y,\n",
    "                          FletParameters.group_labels_list,\n",
    "                          FletParameters.opt_grouping_indexes_list,\n",
    "                          FletParameters.opt_intergroup_P_tensor,\n",
    "                          FletParameters.N_size, FletParameters.N_rank,\n",
    "                          FletParameters.N_accum, FletParameters.N_size_prod)\n",
    "        data_chart.update()\n",
    "        if save_output_checkbox.value:\n",
    "            FletParameters.output_filename = \"output.\" + (datetime.datetime.now()).strftime('%Y%m%d%H%M%S') + \".csv\"\n",
    "            output_filepath =  FletParameters.input_filedirectory + FletParameters.output_filename\n",
    "            FletParameters.output_data.to_csv(output_filepath)\n",
    "            output_filename_text.value = \" >> Saved as \\\"\" + FletParameters.output_filename + \"\\\"\"\n",
    "            output_filename_text.update()\n",
    "        # page.update()\n",
    "\n",
    "    ## Variables\n",
    "    df_init = pd.DataFrame(\n",
    "    (np.array([1,1, 1,2, 1,3, 1,4,  2,1, 2,2, 2,3, 2,4,  3,1, 3,2, 3,3, 3,4,])).reshape(12, 2),\n",
    "        index=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\"],\n",
    "        columns=[\"x\", \"y\"])\n",
    "    FletParameters.df_org = copy.deepcopy(df_init)\n",
    "    FletParameters.df_cleaned = copy.deepcopy(df_init)\n",
    "    viz2d_x_init, viz2d_y_init = gen_2d_data(is_umap_loaded, np.array(df_init.values))\n",
    "    FletParameters.viz2d_x = copy.deepcopy(viz2d_x_init)\n",
    "    FletParameters.viz2d_y = copy.deepcopy(viz2d_y_init)\n",
    "    fig = plt.figure(figsize=(7,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    FletParameters.fig = fig\n",
    "    FletParameters.ax = ax\n",
    "    draw_graph_in_flet(FletParameters.fig, FletParameters.ax, \n",
    "                    FletParameters.df_org.index.values, \n",
    "                    FletParameters.viz2d_x, FletParameters.viz2d_y)\n",
    "\n",
    "    ## Controllers\n",
    "    number_of_divisions = ft.TextField(\n",
    "        value=\"2\",\n",
    "        label=\"Number of divisions\",\n",
    "        text_align=ft.TextAlign.RIGHT,\n",
    "        read_only=True,\n",
    "        width=140,\n",
    "        text_size=24\n",
    "        )\n",
    "    FletParameters.N_size = int(number_of_divisions.value)\n",
    "    # number_of_divisions.text_style = \n",
    "    minus_divisions = ft.IconButton(\n",
    "        icon=ft.icons.REMOVE,\n",
    "        on_click=minus_click\n",
    "        )\n",
    "    plus_divisions = ft.IconButton(\n",
    "        icon=ft.icons.ADD,\n",
    "        on_click=plus_click\n",
    "        )\n",
    "    speed_slider = ft.Slider(\n",
    "        value=0.02, min=0.01, max=0.1, divisions=9, round=2,\n",
    "        label=\"Speed:{value}\",\n",
    "        on_change=speed_slider_changed,\n",
    "        width=int(page.window_width/10),\n",
    "    )\n",
    "    m_weight_slider = ft.Slider(\n",
    "        value=0.1, min=0, max=1, divisions=10, round=1,\n",
    "        label=\"M:{value}\",\n",
    "        on_change=m_weight_slider_changed,\n",
    "        width=int(page.window_width/10),\n",
    "    )\n",
    "    d_weight_slider = ft.Slider(\n",
    "        value=0.1, min=0, max=1, divisions=10, round=1,\n",
    "        label=\"V:{value}\",\n",
    "        on_change=d_weight_slider_changed,\n",
    "        width=int(page.window_width/10),\n",
    "    )\n",
    "    method_dropdown = ft.Dropdown(\n",
    "        label=\"Search method\",\n",
    "        options=[\n",
    "            ft.dropdown.Option(\"Heuristics\"),\n",
    "            ft.dropdown.Option(\"Hybrid\"),\n",
    "            ft.dropdown.Option(\"Random search\"),\n",
    "        ],\n",
    "        value=\"Heuristics\",\n",
    "        on_change=method_dropdown_changed,\n",
    "        width=int(page.window_width/6),\n",
    "    )\n",
    "    pick_files_button = ft.ElevatedButton(\n",
    "                                \"CSV file\",\n",
    "                                icon=ft.icons.UPLOAD_FILE,\n",
    "                                on_click=lambda _: pick_files_dialog.pick_files(\n",
    "                                    allow_multiple=False\n",
    "                                ),\n",
    "                            )\n",
    "    pick_files_dialog = ft.FilePicker(on_result=pick_files_result)\n",
    "    selected_files = ft.Text()\n",
    "    save_output_checkbox = ft.Checkbox(label=\"Save output\", value=True)\n",
    "    start_button = ft.ElevatedButton(\n",
    "        icon=ft.icons.PLAY_ARROW,\n",
    "        text=\"Start\",\n",
    "        on_click=start_grouping,\n",
    "        bgcolor=ft.colors.BLUE_GREY_800,\n",
    "        )\n",
    "    grouping_text = ft.Text(value=\"\")\n",
    "    output_filename_text = ft.Text(value=\"\")\n",
    "    data_textfield = ft.TextField(\n",
    "        # disabled=True,\n",
    "        label=\"Members data\",\n",
    "        value=str(df_init),\n",
    "        read_only=True,\n",
    "        multiline=True,\n",
    "        max_lines = 16,\n",
    "        expand=1\n",
    "        )\n",
    "    data_chart = MatplotlibChart( # ft.matplotlib_chart.MatplotlibChart(\n",
    "        fig,\n",
    "        isolated=True,\n",
    "        expand=2\n",
    "        )\n",
    "    progress_bar = ft.ProgressBar(value=0, width=int(page.window_width/10))\n",
    "    info_textfield = ft.TextField(\n",
    "        # disabled=True,\n",
    "        label=\"Progress log\",\n",
    "        value=\" \",\n",
    "        read_only=True,\n",
    "        multiline=True,\n",
    "        max_lines = 16,\n",
    "        expand=1,\n",
    "        )\n",
    "    FletParameters.info_history = \"\"\n",
    "    FletParameters.info_address = info_textfield\n",
    "    def info_func(info_args, txt):\n",
    "        if (FletParameters.info_history == \"\") or (FletParameters.info_history is None):\n",
    "            FletParameters.info_history = str(txt)\n",
    "        else:\n",
    "            FletParameters.info_history = FletParameters.info_history + \"\\n\" + str(txt)\n",
    "        FletParameters.info_history = FletParameters.info_history\n",
    "        FletParameters.info_address.value = str(FletParameters.info_history)\n",
    "        FletParameters.info_address.update()\n",
    "    FletParameters.info_func = info_func\n",
    "    \n",
    "    ## Style\n",
    "    page.scroll = \"always\"\n",
    "    page.title = \"Optimal Transport Grouping\"\n",
    "    page.vertical_alignment = ft.MainAxisAlignment.START\n",
    "    page.overlay.append(pick_files_dialog)\n",
    "    page.add(\n",
    "        ft.Column([\n",
    "            ft.Container(\n",
    "                ft.Row(\n",
    "                    [\n",
    "                        minus_divisions,\n",
    "                        number_of_divisions,\n",
    "                        plus_divisions,\n",
    "                        ft.Container(\n",
    "                            ft.Row([\n",
    "                                ft.Text(value=\"Speed\", text_align=\"RIGHT\"),\n",
    "                                speed_slider,\n",
    "                            ]),\n",
    "                            bgcolor=ft.colors.BLUE_GREY_800,\n",
    "                            alignment=ft.alignment.center,\n",
    "                            margin=8,\n",
    "                            padding=8,\n",
    "                            border_radius=8,\n",
    "                        ),\n",
    "                        ft.Container(\n",
    "                            ft.Row([\n",
    "                                ft.Text(value=\"M-weight\", text_align=\"RIGHT\"),\n",
    "                                m_weight_slider,\n",
    "                            ]),\n",
    "                            bgcolor=ft.colors.BLUE_GREY_800,\n",
    "                            alignment=ft.alignment.center,\n",
    "                            margin=8,\n",
    "                            padding=8,\n",
    "                            border_radius=8,\n",
    "                        ),\n",
    "                        ft.Container(\n",
    "                            ft.Row([\n",
    "                                ft.Text(value=\"D-weight\", text_align=\"RIGHT\"),\n",
    "                                d_weight_slider,\n",
    "                            ]),\n",
    "                            bgcolor=ft.colors.BLUE_GREY_800,\n",
    "                            alignment=ft.alignment.center,\n",
    "                            margin=8,\n",
    "                            padding=8,\n",
    "                            border_radius=8,\n",
    "                        ),\n",
    "                        method_dropdown,\n",
    "                    ],\n",
    "                    alignment=ft.MainAxisAlignment.START,\n",
    "                    # spacing=10,\n",
    "                ),\n",
    "                width=page.window_width - 20,\n",
    "                height= max(2*int(page.window_height/10)-20,90),\n",
    "                bgcolor=ft.colors.BLUE_GREY_600,\n",
    "                alignment=ft.alignment.center,\n",
    "                margin=10,\n",
    "                padding=10,\n",
    "                border_radius=10,\n",
    "            ),\n",
    "            ft.Container(\n",
    "                ft.Column([\n",
    "                    ft.Row(\n",
    "                        [\n",
    "                            ft.Container(\n",
    "                                ft.Row([\n",
    "                                    ft.Text(value=\" Members data\", text_align=\"RIGHT\"),\n",
    "                                    pick_files_button,\n",
    "                                    selected_files,\n",
    "                                ]),\n",
    "                                bgcolor=ft.colors.BLUE_GREY_800,\n",
    "                                alignment=ft.alignment.center,\n",
    "                                margin=8,\n",
    "                                padding=8,\n",
    "                                border_radius=8,\n",
    "                            ),\n",
    "                            ft.Container(\n",
    "                                ft.Row([\n",
    "                                    save_output_checkbox,\n",
    "                                    start_button,\n",
    "                                    progress_bar,\n",
    "                                    grouping_text,\n",
    "                                    output_filename_text,\n",
    "                                ]),\n",
    "                                bgcolor=ft.colors.BLUE_GREY_800,\n",
    "                                alignment=ft.alignment.center,\n",
    "                                margin=8,\n",
    "                                padding=8,\n",
    "                                border_radius=8,\n",
    "                            ),\n",
    "                        ],\n",
    "                        alignment=ft.MainAxisAlignment.START,\n",
    "                        spacing=10,\n",
    "                    ),\n",
    "                    ft.Row(\n",
    "                        [\n",
    "                            ft.Container(\n",
    "                                content=data_textfield,\n",
    "                                margin=10,\n",
    "                                padding=10,\n",
    "                                alignment=ft.alignment.center,\n",
    "                                bgcolor=ft.colors.BLUE_GREY_500,\n",
    "                                expand=3,\n",
    "                                border_radius=10,\n",
    "                            ),\n",
    "                            ft.Container(\n",
    "                                content=data_chart,\n",
    "                                margin=10,\n",
    "                                padding=10,\n",
    "                                alignment=ft.alignment.center,\n",
    "                                bgcolor=ft.colors.with_opacity(1.0, \"#C0C0C0\"),\n",
    "                                expand=5,\n",
    "                                border_radius=10,\n",
    "                            ), \n",
    "                        ],\n",
    "                        alignment=ft.MainAxisAlignment.START,\n",
    "                    ),\n",
    "                ]),\n",
    "                width=page.window_width - 20,\n",
    "                height= max(int(8*page.window_height/10)-20, 480),\n",
    "                bgcolor=ft.colors.BLUE_GREY_900,\n",
    "                alignment=ft.alignment.center,\n",
    "                margin=10,\n",
    "                padding=10,\n",
    "                border_radius=10,\n",
    "            ),\n",
    "            ft.Container(\n",
    "                ft.Row([\n",
    "                    info_textfield,\n",
    "                ],\n",
    "                    alignment=ft.MainAxisAlignment.START,\n",
    "                    # spacing=10,\n",
    "                ),\n",
    "                width=page.window_width - 20,\n",
    "                height= max(5*int(page.window_height/10)-20,180),\n",
    "                bgcolor=ft.colors.BLUE_GREY_700,\n",
    "                alignment=ft.alignment.center,\n",
    "                margin=10,\n",
    "                padding=10,\n",
    "                border_radius=10,\n",
    "            )\n",
    "        ]),\n",
    "    )\n",
    "\n",
    "ft.app(target=main)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. WebUI with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### OTG (Optimal Transport Grouping)\n",
    "## tanaken ( Kentaro TANAKA, 2024.2- )\n",
    "\n",
    "############################################################\n",
    "#### Required libraries ####\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install umap-learn\n",
    "# !pip install gradio\n",
    "\n",
    "############################################################\n",
    "#### Import ####\n",
    "#### Import ####\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "from matplotlib import cm as cm\n",
    "is_umap_loaded = True\n",
    "try:\n",
    "    import umap\n",
    "    # from numba import jit\n",
    "except ImportError as e:\n",
    "    is_umap_loaded = False\n",
    "    print(f\"{e} is not installed.\")\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "if os.name == 'nt':\n",
    "    import ctypes\n",
    "    ENABLE_PROCESSED_OUTPUT = 0x0001\n",
    "    ENABLE_WRAP_AT_EOL_OUTPUT = 0x0002\n",
    "    ENABLE_VIRTUAL_TERMINAL_PROCESSING = 0x0004\n",
    "    MODE = ENABLE_PROCESSED_OUTPUT + ENABLE_WRAP_AT_EOL_OUTPUT + ENABLE_VIRTUAL_TERMINAL_PROCESSING\n",
    "    kernel32 = ctypes.windll.kernel32\n",
    "    handle = kernel32.GetStdHandle(-11)\n",
    "    kernel32.SetConsoleMode(handle, MODE)\n",
    "import gradio as gr\n",
    "\n",
    "############################################################\n",
    "#### Functions ####\n",
    "\n",
    "## Functions for manipulating tensors\n",
    "def get_N(N_size):\n",
    "    if len(N_size) < 1:\n",
    "        raise ValueError(\"Error: N_size is invalid.\")\n",
    "    N_rank = len(N_size)\n",
    "    N_accum = np.ones(N_rank, dtype=int) # n2*n3*...*nN, n3*n4*...*nN, ... , nN, 1\n",
    "    for i in range(N_rank):\n",
    "        if i==0:\n",
    "            N_accum[N_rank-i-1] = 1\n",
    "        else:\n",
    "            N_accum[N_rank-i-1] = N_accum[N_rank-i]*N_size[N_rank-i]\n",
    "    N_size_prod = N_size[0]*N_accum[0]\n",
    "    return (N_rank, N_accum, N_size_prod)\n",
    "\n",
    "def get_tensor_flattened_index_from_multi_index(multi_index, N_rank, N_accum):\n",
    "    flattened_index = 0\n",
    "    for i in range(N_rank):\n",
    "            flattened_index = flattened_index + N_accum[i]*multi_index[i]\n",
    "    flattened_index = int(flattened_index)\n",
    "    return flattened_index\n",
    "\n",
    "def get_tensor_multi_index_from_flattened_index(flattened_index, N_rank, N_accum):\n",
    "    multi_index = []\n",
    "    remainder = flattened_index\n",
    "    for i in range(N_rank):\n",
    "        quotient, remainder = divmod(remainder, N_accum[i])\n",
    "        multi_index.append(quotient)\n",
    "    multi_index = tuple(multi_index)\n",
    "    return multi_index\n",
    "\n",
    "def get_tensor_value_from_multi_index(target_tensor, multi_index, N_rank, N_accum):\n",
    "    flattened_index = get_tensor_flattened_index_from_multi_index(multi_index, N_rank, N_accum)\n",
    "    return target_tensor[flattened_index]\n",
    "\n",
    "def get_tensor_flattened_index_list_from_value(target_tensor, value, tensor_tolerance=None):\n",
    "    if (tensor_tolerance is None) or (tensor_tolerance==0):\n",
    "        return [i for i, element in enumerate(target_tensor) if element==value]\n",
    "    else:\n",
    "        return [i for i, element in enumerate(target_tensor) if abs(element-value)<=tensor_tolerance]\n",
    "\n",
    "def get_tensor_multi_index_list_from_value(target_tensor, value, N_rank, N_accum, tensor_tolerance=None):\n",
    "    multi_index_list = []\n",
    "    flattened_index_list = get_tensor_flattened_index_list_from_value(target_tensor, value, tensor_tolerance)\n",
    "    for flattened_index in flattened_index_list:\n",
    "        multi_index_list.append(get_tensor_multi_index_from_flattened_index(flattened_index, N_rank, N_accum))\n",
    "    return multi_index_list\n",
    "\n",
    "## Function to generate marginal mass vectors\n",
    "def calc_marginal_mass_vectors(N_rank, N_size):\n",
    "    marginal_mass_vectors = []\n",
    "    for i in range(N_rank):\n",
    "        marginal_mass_vectors.append(np.ones(N_size[i])/N_size[i])\n",
    "    return marginal_mass_vectors\n",
    "\n",
    "## Function to generate grouping randomly (rand=True) or in the same order as the data_order_list (rand=False)\n",
    "def gen_grouping_indexes_list(N_size, rand=True, data_order_list=None):\n",
    "    if data_order_list is None:\n",
    "        data_order_list = list(range(sum(N_size)))\n",
    "    if rand:\n",
    "        data_order_list = random.sample(data_order_list, len(data_order_list))\n",
    "    grouping_indexes_list = [] # Double listing for grouping\n",
    "    range_from = 0\n",
    "    range_to = 0\n",
    "    for size in N_size:\n",
    "        range_to = range_from + size\n",
    "        grouping_indexes_list.append(data_order_list[range_from:range_to])\n",
    "        range_from = range_to\n",
    "    return grouping_indexes_list\n",
    "\n",
    "## Functions for the calculation of optimal transport\n",
    "# @jit\n",
    "def calc_multi_ot(marginal_mass_vectors, cost_tensor, normalized_cost_tensor,\n",
    "                  N_size, N_rank, N_accum, N_size_prod,\n",
    "                  numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200): ## ot_stopping_rule: Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ## Optrimal transport\n",
    "    K_tensor = np.exp(- normalized_cost_tensor / ot_speed) # Gibbs kernel\n",
    "    u_vec_list = []\n",
    "    for i in range(N_rank):\n",
    "        u_vec_list.append(np.ones(N_size[i]))\n",
    "    for loop in range(ot_loop_max):\n",
    "        u_diff = 0 # Variable to measure whether to exit the loop\n",
    "        for i in range(N_rank):\n",
    "            for j in range(N_size[i]):\n",
    "                temp_u_value = 0\n",
    "                temp_K_value = 1\n",
    "                temp_u_prod_value = 1\n",
    "                N_sizeub_s = list(copy.copy(N_size))\n",
    "                N_sizeub_s.pop(i)\n",
    "                for m_sub_index in np.ndindex(tuple(N_sizeub_s)):\n",
    "                    temp_m_index = list(copy.copy(m_sub_index))\n",
    "                    temp_m_index.insert(i, j)\n",
    "                    temp_K_value = get_tensor_value_from_multi_index(K_tensor, temp_m_index, N_rank, N_accum)\n",
    "                    temp_u_prod_value = 1\n",
    "                    for k in range(N_rank):\n",
    "                        if k != i:\n",
    "                            temp_u_prod_value = temp_u_prod_value * u_vec_list[k][temp_m_index[k]]\n",
    "                    temp_u_value = temp_u_value + temp_K_value * temp_u_prod_value\n",
    "                temp_u_value = (marginal_mass_vectors[i][j]) / (temp_u_value)\n",
    "                u_diff = max(u_diff, abs((u_vec_list[i][j]-temp_u_value)/(temp_u_value+numerical_precision))) \n",
    "                u_vec_list[i][j] = temp_u_value\n",
    "        if abs(u_diff) < ot_stopping_rule:\n",
    "            break\n",
    "    f_vec_list = []\n",
    "    for i in range(N_rank):\n",
    "        temp_f_vec = ot_speed * np.log(u_vec_list[i] + numerical_precision)\n",
    "        f_vec_list.append(temp_f_vec)\n",
    "    P_tensor = np.zeros(N_size_prod)\n",
    "    weighted_cost_tensor = np.zeros(N_size_prod)\n",
    "    objective_function_value = 0\n",
    "    for m_index in np.ndindex(tuple(N_size)):\n",
    "        temp_cost_value = get_tensor_value_from_multi_index(cost_tensor, m_index, N_rank, N_accum)\n",
    "        temp_P_value = get_tensor_value_from_multi_index(K_tensor, m_index, N_rank, N_accum)\n",
    "        for k in range(N_rank):\n",
    "            temp_P_value = temp_P_value * u_vec_list[k][m_index[k]]\n",
    "        P_tensor[get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)] = temp_P_value\n",
    "        weighted_cost_tensor[get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)] = temp_P_value*temp_cost_value\n",
    "        objective_function_value = objective_function_value + weighted_cost_tensor[get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)]\n",
    "    return (objective_function_value, P_tensor, weighted_cost_tensor, u_vec_list, f_vec_list)\n",
    "\n",
    "## Functions for calculating optrimal grouping with barycenter (BC)\n",
    "def calc_intergroup_cost_tensor_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "                                N_size, N_rank, N_accum, N_size_prod, order = 2.0,\n",
    "                                numerical_precision = 2e-8):\n",
    "    cost_tensor = np.zeros(N_size_prod)\n",
    "    for m_index in np.ndindex(N_size):\n",
    "        temp_data_points_nparray = []\n",
    "        temp_cost_value = 0\n",
    "        ## Cost : Sum of distances (not squared) between each point and the barycenter\n",
    "        for group in range(N_rank):\n",
    "            temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][m_index[group]]])\n",
    "        temp_barycenter = np.mean(temp_data_points_nparray, axis=0)\n",
    "        for group in range(N_rank):\n",
    "            temp_cost_value_bt2 = np.linalg.norm(temp_data_points_nparray[group] - temp_barycenter) ## Cost between two points\n",
    "            temp_cost_value = temp_cost_value + temp_cost_value_bt2\n",
    "        temp_index = get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)\n",
    "        cost_tensor[temp_index] = temp_cost_value\n",
    "    normalized_cost_tensor = copy.deepcopy(cost_tensor)\n",
    "    max_cost_value = max(cost_tensor)\n",
    "    if max_cost_value > numerical_precision:\n",
    "        normalized_cost_tensor = normalized_cost_tensor/max_cost_value\n",
    "    return (cost_tensor, normalized_cost_tensor)\n",
    "\n",
    "def calc_intergroup_cost_value_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                               N_size, N_rank, N_accum, N_size_prod, order = 2.0,\n",
    "                               numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200):\n",
    "    (intergroup_cost_tensor, normalized_intergroup_cost_tensor) = calc_intergroup_cost_tensor_with_bc(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod,\n",
    "        numerical_precision)\n",
    "    (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "     intergroup_u_vec_list, intergroup_f_vec_list) = calc_multi_ot(\n",
    "        marginal_mass_vectors, intergroup_cost_tensor, normalized_intergroup_cost_tensor, N_size, N_rank, N_accum, N_size_prod,\n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "    return (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "            intergroup_u_vec_list, intergroup_f_vec_list, intergroup_cost_tensor)\n",
    "\n",
    "def calc_intragroup_cost_nparray_list_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                                      N_size, N_rank, N_accum, N_size_prod, order = 2.0):\n",
    "    cost_nparray_list = []\n",
    "    barycenter_nparray_list = []\n",
    "    for group, size in enumerate(N_size):\n",
    "        temp_cost_nparray = np.zeros(size)\n",
    "        for element in range(size):\n",
    "            temp_data_points_nparray = []\n",
    "            ## Cost : Sum of distances (not squared) between each point and the barycenter\n",
    "            for element in range(N_size[group]): ## barycenter\n",
    "                temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][element]])\n",
    "            temp_barycenter_nparray = np.mean(temp_data_points_nparray, axis=0)\n",
    "            for element in range(N_size[group]): ## Cost between one mass point and barycenter\n",
    "                temp_cost_value_bt2 = np.linalg.norm(temp_data_points_nparray[element] - temp_barycenter_nparray, ord=order) ## Cost between two points\n",
    "                temp_cost_nparray[element] = temp_cost_value_bt2\n",
    "        cost_nparray_list.append(temp_cost_nparray)\n",
    "        barycenter_nparray_list.append(temp_barycenter_nparray)\n",
    "    return (cost_nparray_list, barycenter_nparray_list)\n",
    "\n",
    "def calc_intragroup_cost_value_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                               N_size, N_rank, N_accum, N_size_prod, order = 2.0):\n",
    "    intragroup_cost_value = 0\n",
    "    intragroup_average_cost_list = []\n",
    "    (intragroup_cost_nparray_list, intragroup_barycenter_nparray_list) = calc_intragroup_cost_nparray_list_with_bc(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod, order\n",
    "        )\n",
    "    for group in range(N_rank):\n",
    "        intragroup_average_cost = np.mean(intragroup_cost_nparray_list[group])\n",
    "        intragroup_average_cost_list.append(intragroup_average_cost)\n",
    "        intragroup_cost_value = intragroup_cost_value + intragroup_average_cost\n",
    "    intragroup_cost_value = intragroup_cost_value/N_rank\n",
    "    return (intragroup_cost_value, intragroup_cost_nparray_list, intragroup_average_cost_list, intragroup_barycenter_nparray_list)\n",
    "\n",
    "def calc_aggregate_statistical_cost_list_with_bc(intragroup_barycenter_nparray_list, intragroup_average_cost_list,\n",
    "                                         N_size, N_rank, N_accum, N_size_prod, order = 2.0):\n",
    "    center_of_intragroup_barycenter_nparray_list =  np.mean(intragroup_barycenter_nparray_list, axis=0)\n",
    "    center_of_intragroup_average_cost = np.mean(intragroup_average_cost_list, axis=0)\n",
    "    mean_cost_value = 0\n",
    "    deviation_cost_value = 0\n",
    "    for group in range(N_rank):\n",
    "        mean_cost_value = mean_cost_value + np.linalg.norm(intragroup_barycenter_nparray_list[group] - center_of_intragroup_barycenter_nparray_list, ord = order)\n",
    "        deviation_cost_value = deviation_cost_value + abs(intragroup_average_cost_list[group] - center_of_intragroup_average_cost)\n",
    "    mean_cost_value = mean_cost_value/N_rank\n",
    "    deviation_cost_value = deviation_cost_value/N_rank   \n",
    "    return (mean_cost_value, deviation_cost_value)\n",
    "\n",
    "def calc_adjusted_cost_value_with_bc(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                             N_size, N_rank, N_accum, N_size_prod, \n",
    "                             mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 2.0, \n",
    "                             numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200):\n",
    "    ## intergroup_cost_value\n",
    "    (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "    intergroup_u_vec_list, intergroup_f_vec_list,\n",
    "    intergroup_cost_tensor) = calc_intergroup_cost_value_with_bc(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "        N_size, N_rank, N_accum, N_size_prod, order,\n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "        )\n",
    "    ## intragroup_cost_value\n",
    "    (intragroup_cost_value, intragroup_cost_nparray_list, intragroup_average_cost_list,\n",
    "     intragroup_barycenter_nparray_list) = calc_intragroup_cost_value_with_bc(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "        N_size, N_rank, N_accum, N_size_prod, order\n",
    "        )\n",
    "    ## aggregate_statistical_cost_value\n",
    "    (mean_cost_value, deviation_cost_value) = calc_aggregate_statistical_cost_list_with_bc(\n",
    "        intragroup_barycenter_nparray_list, intragroup_average_cost_list,\n",
    "        N_size, N_rank, N_accum, N_size_prod, order\n",
    "        )\n",
    "    ## adjusted_cost_value = (intergroup_cost_value + mean_cost_value + deviation_cost_value) / (intragroup_cost_value)\n",
    "    adjusted_cost_value = 0\n",
    "    if abs(intragroup_cost_value) < numerical_precision:\n",
    "        adjusted_cost_value = np.inf\n",
    "    else:\n",
    "        adjusted_cost_value = (intergroup_cost_value + mean_penalty_weight*mean_cost_value + deviation_penalty_weight*deviation_cost_value)/(intragroup_cost_value)\n",
    "    ## return\n",
    "    return (adjusted_cost_value, mean_cost_value, deviation_cost_value,\n",
    "            intragroup_cost_value, intragroup_cost_nparray_list, intragroup_barycenter_nparray_list, \n",
    "            intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "            intergroup_u_vec_list, intergroup_f_vec_list, intergroup_cost_tensor)\n",
    "\n",
    "def calc_optimal_grouping_with_bc(data_points_nparray, N_size,\n",
    "                           N_rank = None, N_accum = None, N_size_prod = None,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 2.0,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 10, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           show_info = False, drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## N_rank, N_accum, N_size_prod, marginal_mass_vectors\n",
    "    if (N_rank is None) or (N_accum is None) or (N_size_prod is None):\n",
    "        (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    marginal_mass_vectors = calc_marginal_mass_vectors(N_rank, N_size)\n",
    "    ## Initial value settings\n",
    "    if init_grouping_indexes_list is None:\n",
    "        init_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "    ## Calculation of optimal transportation costs under initial conditions\n",
    "    (init_adjusted_cost_value, init_mean_cost_value, init_deviation_cost_value,\n",
    "    init_intragroup_cost_value, init_intragroup_cost_nparray_list, init_intragroup_barycenter_nparray_list,\n",
    "    init_intergroup_cost_value, init_intergroup_P_tensor, init_intergroup_weighted_cost_tensor,\n",
    "    init_intergroup_u_vec_list, init_intergroup_f_vec_list,\n",
    "    init_intergroup_cost_tensor) = calc_adjusted_cost_value_with_bc(\n",
    "        init_grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod, order,\n",
    "        mean_penalty_weight, deviation_penalty_weight, \n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "    )\n",
    "    ## Preparation for recording\n",
    "    iteration_number_list = [0]\n",
    "    elapsed_time_list = [0]\n",
    "    new_adjusted_cost_trends_list = [init_adjusted_cost_value]\n",
    "    opt_adjusted_cost_trends_list = [init_adjusted_cost_value]\n",
    "    start_time = time.time()\n",
    "    ## info\n",
    "    if show_info:\n",
    "        info_func(info_args, \"---------- init\")\n",
    "        info_func(info_args, \"init_grouping_indexes_list: \" + str(init_grouping_indexes_list))\n",
    "        info_func(info_args, \"init_adjusted_cost_value: \" + str(init_adjusted_cost_value))\n",
    "        info_func(info_args, \"  (init_intergroup_cost_value, init_intragroup_cost_value: \" + str(init_intergroup_cost_value) + \", \" + str(init_intragroup_cost_value) + \")\")\n",
    "        info_func(info_args, \"  (mean_penalty_weight*init_mean_cost_value, deviation_penalty_weight*init_deviation_cost_value : \" \n",
    "              + str(mean_penalty_weight*init_mean_cost_value) + \", \" + str(deviation_penalty_weight*init_deviation_cost_value) + \")\")\n",
    "    if drawing_graphs:\n",
    "        (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "                                                                init_grouping_indexes_list, data_points_nparray, \n",
    "                                                                N_size, N_rank, N_accum, N_size_prod,\n",
    "                                                                viz2d_x, viz2d_y, init_intergroup_P_tensor)\n",
    "        # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, init_grouping_indexes_list, data_points_nparray,\n",
    "        #                             viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Initial Value\")\n",
    "        show_P_tensor(init_intergroup_P_tensor, N_size, N_rank, N_accum, f_size=(4,3), f_title=\"Initial Value\")\n",
    "    ## opt\n",
    "    opt_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "    opt_adjusted_cost_value = init_adjusted_cost_value\n",
    "    opt_mean_cost_value = init_mean_cost_value\n",
    "    opt_deviation_cost_value = init_deviation_cost_value\n",
    "    opt_intragroup_cost_value = init_intragroup_cost_value\n",
    "    opt_intergroup_cost_value = init_intergroup_cost_value\n",
    "    opt_intergroup_P_tensor = copy.deepcopy(init_intergroup_P_tensor)\n",
    "    ## new\n",
    "    new_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "    new_adjusted_cost_value = init_adjusted_cost_value\n",
    "    new_mean_cost_value = init_mean_cost_value\n",
    "    new_deviation_cost_value = init_deviation_cost_value\n",
    "    new_intragroup_cost_value = init_intragroup_cost_value\n",
    "    new_intragroup_cost_nparray_list = copy.deepcopy(init_intragroup_cost_nparray_list)\n",
    "    new_intragroup_barycenter_nparray_list = copy.deepcopy(init_intragroup_barycenter_nparray_list)\n",
    "    new_intergroup_cost_value = init_intergroup_cost_value\n",
    "    new_intergroup_P_tensor = copy.deepcopy(init_intergroup_P_tensor)\n",
    "    new_intergroup_weighted_cost_tensor = copy.deepcopy(init_intergroup_weighted_cost_tensor)\n",
    "    new_intergroup_cost_tensor = copy.deepcopy(init_intergroup_cost_tensor)\n",
    "    ## Search for optimal value\n",
    "    new_grouping_flag = True\n",
    "    search_stopping_rule_counter = 0\n",
    "    for loop in range(global_loop_max):\n",
    "        if show_info:\n",
    "            info_func(info_args, \"---------- loop: \" + str(loop+1))\n",
    "        search_stopping_rule_counter = search_stopping_rule_counter + 1\n",
    "        if search_method==\"rand\": ## search_method==\"rand\"\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=True) ## True: Random grouping, False: Grouping in order\n",
    "        else: ## search_method==\"ex\" or search_method==\"hybrid\"\n",
    "            if (search_stopping_rule_counter >= search_stopping_rule_rep):\n",
    "                opt_adjusted_cost_diff_list = opt_adjusted_cost_trends_list[(len(opt_adjusted_cost_trends_list)-search_stopping_rule_rep):]\n",
    "                old_adjusted_cost_value = opt_adjusted_cost_diff_list[0]\n",
    "                opt_adjusted_cost_diff_list = abs(np.array(opt_adjusted_cost_diff_list) - old_adjusted_cost_value)\n",
    "                opt_adjusted_cost_diff_list = opt_adjusted_cost_diff_list/(abs(old_adjusted_cost_value)+numerical_precision)\n",
    "                opt_adjusted_cost_diff_max = max(opt_adjusted_cost_diff_list)\n",
    "                if opt_adjusted_cost_diff_max <= search_stopping_rule_err:\n",
    "                    if search_method==\"hybrid\": ## search_method==\"hybrid\"\n",
    "                        search_stopping_rule_counter = 0\n",
    "                        new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=True) ## True: Random grouping, False: Grouping in order\n",
    "                        if show_info:\n",
    "                            info_func(info_args, \"Grouping has been shuffled.\")\n",
    "                    else: ## search_method==\"ex\"\n",
    "                        if show_info:\n",
    "                            info_func(info_args, \"The stopping criterion determined that convergence to the optimum value was achieved.\")\n",
    "                        break\n",
    "            ## Local grouping: Select two clusters and perform an exchange between the two clusters\n",
    "            probability_tensor = copy.deepcopy(new_intergroup_weighted_cost_tensor)\n",
    "            cluster_1_value = (random.choices(probability_tensor, k=1, weights=probability_tensor))[0]\n",
    "            cluster_1_flattened_index_list = get_tensor_flattened_index_list_from_value(probability_tensor, cluster_1_value, tensor_tolerance)\n",
    "            cluster_1_flattened_index = random.choice(cluster_1_flattened_index_list)\n",
    "            cluster_1_multi_index = get_tensor_multi_index_from_flattened_index(cluster_1_flattened_index, N_rank, N_accum)\n",
    "            probability_tensor[cluster_1_flattened_index] = 0\n",
    "            cluster_2_value = (random.choices(probability_tensor, k=1, weights=probability_tensor))[0]\n",
    "            cluster_2_flattened_index_list = get_tensor_flattened_index_list_from_value(probability_tensor, cluster_2_value, tensor_tolerance)\n",
    "            cluster_2_flattened_index = random.choice(cluster_2_flattened_index_list)\n",
    "            cluster_2_multi_index = get_tensor_multi_index_from_flattened_index(cluster_2_flattened_index, N_rank, N_accum)\n",
    "            ## Preparation for local grouping\n",
    "            local_N_size = []\n",
    "            local_data_indexes = []\n",
    "            opt_local_grouping_indexes_list = []\n",
    "            ## local_N_size, local_data_indexes, opt_local_grouping_indexes_list, local_N_rank, local_N_accum, local_N_size_prod, local_marginal_mass_vectors\n",
    "            for local_group in range(N_rank):\n",
    "                if cluster_1_multi_index[local_group] == cluster_2_multi_index[local_group]:\n",
    "                    local_N_size.append(1)\n",
    "                    temp_index = new_grouping_indexes_list[local_group][cluster_1_multi_index[local_group]]\n",
    "                    local_data_indexes.append(temp_index)\n",
    "                    opt_local_grouping_indexes_list.append([temp_index])\n",
    "                else:\n",
    "                    local_N_size.append(2)\n",
    "                    temp_index_1 = new_grouping_indexes_list[local_group][cluster_1_multi_index[local_group]]\n",
    "                    temp_index_2 = new_grouping_indexes_list[local_group][cluster_2_multi_index[local_group]]\n",
    "                    local_data_indexes.append(temp_index_1)\n",
    "                    local_data_indexes.append(temp_index_2)\n",
    "                    opt_local_grouping_indexes_list.append([temp_index_1, temp_index_2])\n",
    "            local_N_size = tuple(local_N_size)\n",
    "            (local_N_rank, local_N_accum, local_N_size_prod) = get_N(local_N_size)\n",
    "            local_marginal_mass_vectors = calc_marginal_mass_vectors(local_N_rank, local_N_size)\n",
    "            ## Calculation of current local optimal transportation costs\n",
    "            (opt_local_adjusted_cost_value, opt_local_mean_cost_value, opt_local_deviation_cost_value,\n",
    "            opt_local_intragroup_cost_value, opt_local_intragroup_cost_nparray_list, opt_local_intragroup_barycenter_nparray_list,\n",
    "            opt_local_intergroup_cost_value, opt_local_intergroup_P_tensor, opt_local_intergroup_weighted_cost_tensor,\n",
    "            opt_local_intergroup_u_vec_list, opt_local_intergroup_f_vec_list,\n",
    "            opt_local_intergroup_cost_tensor) = calc_adjusted_cost_value_with_bc(\n",
    "                opt_local_grouping_indexes_list, data_points_nparray, local_marginal_mass_vectors,\n",
    "                local_N_size, local_N_rank, local_N_accum, local_N_size_prod,\n",
    "                mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "            )\n",
    "            old_local_adjusted_cost_value = opt_local_adjusted_cost_value\n",
    "            ## Enumeration of grouping patterns\n",
    "            ## (If N_rank is 2 or 3, all enumeration is used, and more than that, random selection is used.)\n",
    "            local_grouping_indexes_list_combinations = []\n",
    "            if local_N_rank == 2: ## It might be a good idea to have all the patterns ready in advance. (2^2-1=3)\n",
    "                numbers_list = list(range(sum(local_N_size)))\n",
    "                for sub_numbers_list_1 in itertools.combinations(numbers_list, local_N_size[0]):\n",
    "                    sub_numbers_list_2 = tuple(np.delete(numbers_list, sub_numbers_list_1, 0))\n",
    "                    temp_local_grouping_indexes_list = list((np.array(local_data_indexes))[list(sub_numbers_list_1+sub_numbers_list_2)])\n",
    "                    temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                    if temp_local_grouping_indexes_list != opt_local_grouping_indexes_list:\n",
    "                        local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            elif local_N_rank == 3: ## It might be a good idea to have all the patterns ready in advance. (2^3-1=7)\n",
    "                numbers_list = list(range(sum(local_N_size)))\n",
    "                for sub_numbers_list_1 in itertools.combinations(numbers_list, local_N_size[0]):\n",
    "                    temp_numbers_list = np.delete(numbers_list, sub_numbers_list_1, 0)\n",
    "                    for sub_numbers_list_2 in itertools.combinations(temp_numbers_list, local_N_size[1]):      \n",
    "                        sub_numbers_list_3 = tuple(np.delete(numbers_list, sub_numbers_list_1+sub_numbers_list_2, 0))\n",
    "                        temp_local_grouping_indexes_list = list((np.array(local_data_indexes))[list(sub_numbers_list_1+sub_numbers_list_2+sub_numbers_list_3)])\n",
    "                        temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                        if temp_local_grouping_indexes_list!= opt_local_grouping_indexes_list:\n",
    "                                local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            else:\n",
    "                for i in range(local_loop_max):\n",
    "                    temp_local_grouping_indexes_list = random.sample(local_data_indexes, len(local_data_indexes))\n",
    "                    temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                    if (temp_local_grouping_indexes_list!= opt_local_grouping_indexes_list) and (temp_local_grouping_indexes_list not in local_grouping_indexes_list_combinations):\n",
    "                                local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            ## Calculate the cost of local optimal transportation for each pattern of local grouping\n",
    "            opt_local_adjusted_cost_value = float('inf')\n",
    "            opt_local_grouping_indexes_list_list = []\n",
    "            for new_local_grouping_indexes_list in local_grouping_indexes_list_combinations:\n",
    "                (new_local_adjusted_cost_value, new_local_mean_cost_value, new_local_deviation_cost_value,\n",
    "                new_local_intragroup_cost_value, new_local_intragroup_cost_nparray_list, new_local_intragroup_barycenter_nparray_list,\n",
    "                new_local_intergroup_cost_value, new_local_intergroup_P_tensor, new_local_intergroup_weighted_cost_tenso,\n",
    "                new_local_intergroup_u_vec_list, new_local_intergroup_f_vec_list,\n",
    "                new_local_intergroup_cost_tensor) = calc_adjusted_cost_value_with_bc(\n",
    "                        new_local_grouping_indexes_list, data_points_nparray, local_marginal_mass_vectors,\n",
    "                        local_N_size, local_N_rank, local_N_accum, local_N_size_prod,\n",
    "                        mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "                )\n",
    "                if new_local_adjusted_cost_value < opt_local_adjusted_cost_value:\n",
    "                    opt_local_adjusted_cost_value = new_local_adjusted_cost_value\n",
    "                    opt_local_grouping_indexes_list_list = [new_local_grouping_indexes_list]\n",
    "                elif new_local_adjusted_cost_value == opt_local_adjusted_cost_value:\n",
    "                    opt_local_grouping_indexes_list_list.append(new_local_grouping_indexes_list)\n",
    "            opt_local_grouping_indexes_list = random.choice(opt_local_grouping_indexes_list_list)\n",
    "            random_number = random.random()\n",
    "            new_grouping_flag = (opt_local_adjusted_cost_value==0) or (random_number <= (old_local_adjusted_cost_value/opt_local_adjusted_cost_value))\n",
    "            if new_grouping_flag:\n",
    "                for group in range(local_N_rank):\n",
    "                    if local_N_size[group] == 1:\n",
    "                        new_grouping_indexes_list[group][cluster_1_multi_index[group]] = opt_local_grouping_indexes_list[group][0]\n",
    "                    else:\n",
    "                        new_grouping_indexes_list[group][cluster_1_multi_index[group]] = opt_local_grouping_indexes_list[group][0]\n",
    "                        new_grouping_indexes_list[group][cluster_2_multi_index[group]] = opt_local_grouping_indexes_list[group][1]\n",
    "        if new_grouping_flag:\n",
    "            ## Calculation of the cost of optimal transport\n",
    "            (new_adjusted_cost_value, new_mean_cost_value, new_deviation_cost_value,\n",
    "            new_intragroup_cost_value, new_intragroup_cost_nparray_list, new_intragroup_barycenter_nparray_list, \n",
    "            new_intergroup_cost_value, new_intergroup_P_tensor, \n",
    "            new_intergroup_weighted_cost_tensor, new_intergroup_u_vec_list, new_intergroup_f_vec_list, \n",
    "            new_intergroup_cost_tensor) = calc_adjusted_cost_value_with_bc(\n",
    "                    new_grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                    N_size, N_rank, N_accum, N_size_prod,\n",
    "                    mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                    numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "            )\n",
    "        if show_info:\n",
    "            info_func(info_args, \"new_grouping_indexes_list: \" + str(new_grouping_indexes_list))\n",
    "            info_func(info_args, \"new_adjusted_cost_value: \" + str(new_adjusted_cost_value))\n",
    "        # if drawing_graphs:\n",
    "        #     (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "        #                                                 new_grouping_indexes_list, data_points_nparray, \n",
    "        #                                                 N_size, N_rank, N_accum, N_size_prod,\n",
    "        #                                                 viz2d_x, viz2d_y, new_intergroup_P_tensor)\n",
    "        #     # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "        #     #                             viz2d_x, viz2d_y, line_width = 1, f_size=(4,3,1), f_title=\"Mid-calculation\")\n",
    "        if new_adjusted_cost_value <= opt_adjusted_cost_value:\n",
    "            opt_grouping_indexes_list = copy.deepcopy(new_grouping_indexes_list)\n",
    "            opt_adjusted_cost_value = new_adjusted_cost_value\n",
    "            opt_mean_cost_value = new_mean_cost_value\n",
    "            opt_deviation_cost_value = new_deviation_cost_value\n",
    "            opt_intragroup_cost_value = new_intragroup_cost_value\n",
    "            opt_intragroup_cost_nparray_list = copy.deepcopy(new_intragroup_cost_nparray_list)\n",
    "            opt_intragroup_barycenter_nparray_list = copy.deepcopy(new_intragroup_barycenter_nparray_list)\n",
    "            opt_intergroup_cost_value = new_intergroup_cost_value\n",
    "            opt_intergroup_P_tensor = copy.deepcopy(new_intergroup_P_tensor)\n",
    "            opt_intergroup_weighted_cost_tensor = copy.deepcopy(new_intergroup_weighted_cost_tensor)\n",
    "            opt_intergroup_cost_tensor = copy.deepcopy(new_intergroup_cost_tensor)\n",
    "        ## Recording\n",
    "        iteration_number_list.append(loop+1)\n",
    "        elapsed_time = float(time.time() - start_time)\n",
    "        elapsed_time_list.append(elapsed_time)\n",
    "        new_adjusted_cost_trends_list.append(new_adjusted_cost_value)\n",
    "        opt_adjusted_cost_trends_list.append(opt_adjusted_cost_value)\n",
    "    ## info\n",
    "    if show_info:\n",
    "        info_func(info_args, \"---------- opt\")\n",
    "        info_func(info_args, \"opt_grouping_indexes_list: \" + str(init_grouping_indexes_list))\n",
    "        info_func(info_args, \"opt_adjusted_cost_value: \" + str(opt_adjusted_cost_value))\n",
    "        info_func(info_args, \"  (opt_intergroup_cost_value, opt_intragroup_cost_value: \" + str(opt_intergroup_cost_value) + \", \" + str(opt_intragroup_cost_value) + \")\")\n",
    "        info_func(info_args, \"  (mean_penalty_weight*opt_mean_cost_value, deviation_penalty_weight*opt_deviation_cost_value : \"\n",
    "              + str(mean_penalty_weight*opt_mean_cost_value) + \", \" + str(deviation_penalty_weight*opt_deviation_cost_value) + \")\")\n",
    "        ## Computation time\n",
    "        elapsed_hour = elapsed_time // 3600\n",
    "        elapsed_minute = (elapsed_time % 3600) // 60\n",
    "        elapsed_second = (elapsed_time % 3600 % 60)\n",
    "        info_func(info_args, \"computation time:\" + str(elapsed_hour).zfill(2) + \":\" + str(elapsed_minute).zfill(2) + \":\" + str(elapsed_second).zfill(2))\n",
    "    if drawing_graphs:\n",
    "        (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "                                            opt_grouping_indexes_list, data_points_nparray, \n",
    "                                            N_size, N_rank, N_accum, N_size_prod,\n",
    "                                            viz2d_x, viz2d_y, opt_intergroup_P_tensor)\n",
    "        # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, opt_grouping_indexes_list, data_points_nparray,\n",
    "        #                             viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "        show_P_tensor(opt_intergroup_P_tensor, N_size, N_rank, N_accum, f_size=(4,3), f_title=\"Optimal value\")\n",
    "     ## return\n",
    "    return (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "            opt_adjusted_cost_value,\n",
    "            opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "            opt_mean_cost_value, opt_deviation_cost_value,\n",
    "            iteration_number_list, elapsed_time_list,\n",
    "            new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "            viz2d_x, viz2d_y\n",
    "            )\n",
    "\n",
    "def gen_optimal_grouping_with_bc(data_points_nparray, N_size = None, standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 2.0, \n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## ## data_points_nparray: NumPy array consisting of data points\n",
    "    ## N_size: Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "    ## standardization = True ## Standardization\n",
    "    ## mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "    ## deviation_penalty_weight = 0.1 ## Weight of deviation_cost_value\n",
    "    ## order = 2.0 ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "    ## numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "    ## ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "    ## ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ## ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot_with_bc\n",
    "    ## tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "    ## global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "    ## local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "    ## init_grouping_indexes_list = None ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## search_method = \"ex\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "    ## search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "    ## search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "    ## main_show_info = True ## Flag whether information is displayed or not\n",
    "    ## main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "    ## sub_show_info = False ## Flag whether information is displayed or not\n",
    "    ## sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "    ## info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "    ## info_args = None ## Arguments for info_func\n",
    "    ## tensor_size_max = 4000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "    ## group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "    ## loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "    ## viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## N_size\n",
    "    data_size = len(data_points_nparray)\n",
    "    if N_size is None:\n",
    "        info_func(info_args, \"Warning: N_size is None.\")\n",
    "        N_size = tuple(data_size)\n",
    "    if (type(N_size) == int):\n",
    "        if data_size > N_size:\n",
    "            (quotient, remainder) = divmod(data_size, N_size)\n",
    "            N_size = np.full(N_size, quotient)\n",
    "            for i in range(remainder):\n",
    "                N_size[i] = N_size[i] + 1\n",
    "            N_size = tuple(N_size)\n",
    "        else:\n",
    "            N_size = tuple(data_size)\n",
    "    elif (type(N_size) == tuple) or (type(N_size) == list):\n",
    "        N_size = tuple(N_size)\n",
    "        if data_size != sum(N_size):\n",
    "            info_func(info_args, \"Warning: The sum of N_size does not match sample size.\")\n",
    "            N_size = tuple(data_size)\n",
    "    else:\n",
    "        info_func(info_args, \"Warning: N_size must be of type integer or tuple.\")\n",
    "        N_size = tuple(data_size)\n",
    "    (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    res_calc_optimal_grouping = None\n",
    "    ## Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    ## Setting Parameters\n",
    "    if (N_size_prod > tensor_size_max) or (min(N_size) > group_size_max): ## If True, use \"approximate solution\".\n",
    "        ## Initial value settings\n",
    "        if init_grouping_indexes_list is None:\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "        else:\n",
    "            new_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "        if main_show_info:\n",
    "            info_func(info_args, \"---------- new_grouping_indexes_list (initial value): \" + str(new_grouping_indexes_list))\n",
    "        if main_drawing_graphs:\n",
    "            (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                        viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Initial value\")\n",
    "        for loop in range( loop_max_multiplier*N_rank ):\n",
    "            (group_1, group_2) = random.sample(list(range(N_rank)), 2)\n",
    "            sub_N_size = [N_size[group_1], N_size[group_2]]\n",
    "            group_1_sub_index = []\n",
    "            group_2_sub_index = []\n",
    "            if sub_N_size[0] > group_size_max:\n",
    "                group_1_sub_index = random.sample(list(range(sub_N_size[0])), group_size_max)\n",
    "                sub_N_size[0] = group_size_max\n",
    "            else:\n",
    "                group_1_sub_index = list(range(sub_N_size[0]))\n",
    "            if sub_N_size[1] > group_size_max:\n",
    "                group_2_sub_index = random.sample(list(range(sub_N_size[1])), group_size_max)\n",
    "                sub_N_size[1] = group_size_max\n",
    "            else:\n",
    "                group_2_sub_index = list(range(sub_N_size[1]))\n",
    "            sub_N_size = tuple(sub_N_size)\n",
    "            sub_data_index = list(np.array(new_grouping_indexes_list[group_1])[group_1_sub_index]) + list(np.array(new_grouping_indexes_list[group_2])[group_2_sub_index])\n",
    "            sub_data_points_nparray = data_points_nparray[sub_data_index]\n",
    "            (sub_N_rank, sub_N_accum, sub_N_size_prod) = get_N(sub_N_size)\n",
    "            res_calc_optimal_grouping = calc_optimal_grouping_with_bc(\n",
    "                sub_data_points_nparray, sub_N_size,\n",
    "                sub_N_rank, sub_N_accum, sub_N_size_prod,\n",
    "                mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                numerical_precision,\n",
    "                ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                None, True, ## init_grouping_indexes_list, init_grouping_rand,\n",
    "                search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                sub_show_info, sub_drawing_graphs,\n",
    "                info_func,\n",
    "                info_args,\n",
    "                viz2d_x, viz2d_y)\n",
    "            sub_opt_grouping_indexes_list = res_calc_optimal_grouping[0]\n",
    "            group_1_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[0]])\n",
    "            group_2_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[1]])\n",
    "            for i, index in enumerate(group_1_sub_index):\n",
    "                new_grouping_indexes_list[group_1][index] = group_1_sub_grouping_indexes_list[i]\n",
    "            for i, index in enumerate(group_2_sub_index):\n",
    "                new_grouping_indexes_list[group_2][index] = group_2_sub_grouping_indexes_list[i]\n",
    "            if main_show_info:\n",
    "                info_func(info_args, \"---------- loop (partial optimization): \" + str(loop+1))\n",
    "                info_func(info_args, \"---------- new_grouping_indexes_list (partial optimization): \" + str(new_grouping_indexes_list))\n",
    "            if (main_drawing_graphs) and (loop == (2*N_rank-1)):\n",
    "                (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                            viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "        res_calc_optimal_grouping = (new_grouping_indexes_list, \n",
    "                                     None, # opt_intergroup_P_tensor,\n",
    "                                     None, # opt_adjusted_cost_value,\n",
    "                                     None, # opt_intergroup_cost_value,\n",
    "                                     None, # opt_intragroup_cost_value,\n",
    "                                     None, # opt_mean_cost_value,\n",
    "                                     None, # opt_deviation_cost_value,\n",
    "                                     None, # iteration_number_list,\n",
    "                                     None, # elapsed_time_list,\n",
    "                                     None, # new_adjusted_cost_trends_list,\n",
    "                                     None, # opt_adjusted_cost_trends_list,\n",
    "                                     viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_bc(data_points_nparray, N_size,\n",
    "                            N_rank, N_accum, N_size_prod,\n",
    "                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_indexes_list, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            info_func,\n",
    "                            info_args,\n",
    "                            viz2d_x, viz2d_y)\n",
    "    ## res_calc_optimal_grouping:\n",
    "    ## (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "    ##  opt_adjusted_cost_value,\n",
    "    ##  opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "    ##  opt_mean_cost_value, opt_deviation_cost_value,\n",
    "    ##  iteration_number_list, elapsed_time_list,\n",
    "    ##  new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "    ##  viz2d_x, viz2d_y)\n",
    "    return res_calc_optimal_grouping\n",
    "\n",
    "def gen_optimal_grouping_from_csv_file_with_bc(input_filepath= \"./members.csv\", input_index_col = 0, output_filepath = \"./grouping.csv\",\n",
    "                           N_size = None,\n",
    "                           standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 2.0, \n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## input_filepath = \"./members.csv\" ## File path of the input file, in csv format.\n",
    "    ## input_index_col = 0 ## Column number with column name or column number in the csv file\n",
    "    ## output_filepath = \"./grouping.csv\" ##  File path of the output file, in csv format.\n",
    "    ############################\n",
    "    ## Loading data: loading csv files\n",
    "    df = pd.read_csv(filepath_or_buffer=input_filepath, index_col=input_index_col)\n",
    "    output_data = copy.deepcopy(df)\n",
    "    data_size = len(df)\n",
    "    ############################\n",
    "    ## Dummy variable processing: dummy variable for columns where dtype is object\n",
    "    df = pd.get_dummies(df, drop_first=True, dtype=\"float\") # float64, uint8, bool\n",
    "    ############################\n",
    "    ##  Handling missing values: interpolate by median\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    ############################\n",
    "    ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray_org = np.array(df.values)\n",
    "    data_points_nparray = copy.deepcopy(data_points_nparray_org) ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray = data_points_nparray.astype(float)\n",
    "    ###########################################\n",
    "    ## Data Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    ###########################################\n",
    "    ## Division and Search\n",
    "    (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "     opt_adjusted_cost_value,\n",
    "     opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "     opt_mean_cost_value, opt_deviation_cost_value,\n",
    "     iteration_number_list, elapsed_time_list,\n",
    "     new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "     viz2d_x, viz2d_y\n",
    "    ) = gen_optimal_grouping_with_bc(data_points_nparray, N_size, standardization,\n",
    "                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_indexes_list, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            sub_show_info, sub_drawing_graphs,\n",
    "                            info_func, info_args,\n",
    "                            tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                            viz2d_x, viz2d_y)\n",
    "    ###########################################\n",
    "    ## Output grouping results to csv file\n",
    "    group_labels_list = np.zeros(data_size)\n",
    "    group = 0\n",
    "    for members_list in opt_grouping_indexes_list:\n",
    "        for member in members_list:\n",
    "            group_labels_list[member] = int(group)\n",
    "        group = group + 1\n",
    "    output_data.insert(loc=0, column=\"Group\", value=group_labels_list.astype(int), allow_duplicates=True)\n",
    "    if (viz2d_x is not None) and (viz2d_y is not None):\n",
    "        output_data.insert(loc=1, column=\"viz2d_x\", value=viz2d_x.astype(float), allow_duplicates=True)\n",
    "        output_data.insert(loc=2, column=\"viz2d_y\", value=viz2d_y.astype(float), allow_duplicates=True)\n",
    "    output_data.to_csv(output_filepath)\n",
    "    ###########################################\n",
    "    ## Return\n",
    "    return (opt_grouping_indexes_list,\n",
    "            opt_intergroup_P_tensor,\n",
    "            opt_adjusted_cost_value,\n",
    "            opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "            opt_mean_cost_value, opt_deviation_cost_value,\n",
    "            iteration_number_list, elapsed_time_list,\n",
    "            new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "            output_data, viz2d_x, viz2d_y\n",
    "    )\n",
    "\n",
    "## Functions for calculating optrimal grouping with minimum spanning tree (MST)\n",
    "def calc_distance_matrix(data_points: List[np.ndarray], order: float) -> np.ndarray:\n",
    "    n = len(data_points)\n",
    "    p = len(data_points[0]) ## Assuming all points have the same dimensionality\n",
    "    ## Initialize an empty distance matrix\n",
    "    distance_matrix = np.zeros((n, n))\n",
    "    ## Calculate pairwise distances\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            distance = np.linalg.norm(np.array(data_points[i]) - np.array(data_points[j]), ord = order)\n",
    "            distance_matrix[i, j] = distance\n",
    "            distance_matrix[j, i] = distance\n",
    "    return distance_matrix\n",
    "\n",
    "def calc_minimum_spanning_tree(distance_matrix: np.ndarray) -> Tuple[np.ndarray, float]:\n",
    "    n = distance_matrix.shape[0]\n",
    "    visited = [False] * n\n",
    "    adjacency_matrix = np.zeros((n, n))\n",
    "    total_weight = 0.0\n",
    "    ## Start with the first node\n",
    "    visited[0] = True\n",
    "    for _ in range(n - 1):\n",
    "        min_edge_weight = float('inf')\n",
    "        u, v = -1, -1\n",
    "        ## Find the minimum weight edge connecting visited and unvisited nodes\n",
    "        for i in range(n):\n",
    "            if visited[i]:\n",
    "                for j in range(n):\n",
    "                    if not visited[j] and distance_matrix[i, j] < min_edge_weight:\n",
    "                        min_edge_weight = distance_matrix[i, j]\n",
    "                        u, v = i, j\n",
    "        ## Add the edge to the MST\n",
    "        adjacency_matrix[u, v] = 1\n",
    "        adjacency_matrix[v, u] = 1\n",
    "        total_weight += min_edge_weight\n",
    "        visited[v] = True\n",
    "    return adjacency_matrix, total_weight\n",
    "\n",
    "def calc_distance_matrix_and_minimum_spanning_tree(data_points: List[np.ndarray], order: float) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    distance_matrix = calc_distance_matrix(data_points, order)\n",
    "    (adjacency_matrix, total_weight) = calc_minimum_spanning_tree(distance_matrix)\n",
    "    return (distance_matrix, adjacency_matrix, total_weight)\n",
    "\n",
    "def calc_intergroup_cost_tensor_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "                                N_size, N_rank, N_accum, N_size_prod, order = 1.0,\n",
    "                                numerical_precision = 2e-8):\n",
    "    cost_tensor = np.zeros(N_size_prod)\n",
    "    for m_index in np.ndindex(N_size):\n",
    "        temp_data_points_nparray = []\n",
    "        temp_cost_value = 0\n",
    "        for group in range(N_rank):\n",
    "            temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][m_index[group]]])\n",
    "        ## Cost: MST\n",
    "        (distance_nparray, adjacency_nparray,\n",
    "         total_weight) = calc_distance_matrix_and_minimum_spanning_tree(\n",
    "             temp_data_points_nparray, order)\n",
    "        temp_cost_value = total_weight\n",
    "        temp_index = get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)\n",
    "        cost_tensor[temp_index] = temp_cost_value\n",
    "    normalized_cost_tensor = copy.deepcopy(cost_tensor)\n",
    "    max_cost_value = max(cost_tensor)\n",
    "    if max_cost_value > numerical_precision:\n",
    "        normalized_cost_tensor = normalized_cost_tensor/max_cost_value\n",
    "    return (cost_tensor, normalized_cost_tensor)\n",
    "\n",
    "def calc_intergroup_cost_value_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                               N_size, N_rank, N_accum, N_size_prod, order = 1.0,\n",
    "                               numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200):\n",
    "    (intergroup_cost_tensor, normalized_intergroup_cost_tensor) = calc_intergroup_cost_tensor_with_mst(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod, order,\n",
    "        numerical_precision)\n",
    "    (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "     intergroup_u_vec_list, intergroup_f_vec_list) = calc_multi_ot(\n",
    "        marginal_mass_vectors, intergroup_cost_tensor, normalized_intergroup_cost_tensor, N_size, N_rank, N_accum, N_size_prod,\n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "    return (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "            intergroup_u_vec_list, intergroup_f_vec_list, intergroup_cost_tensor)\n",
    "\n",
    "def calc_intragroup_cost_list_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                                      N_size, N_rank, N_accum, N_size_prod, order = 1.0):\n",
    "    distance_nparray_list = []\n",
    "    adjacency_nparray_list = []\n",
    "    cost_list = []\n",
    "    for group, size in enumerate(N_size):\n",
    "        temp_data_points_nparray = []\n",
    "        for element in range(size):\n",
    "            temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][element]])\n",
    "        ## Cost : MST\n",
    "        (distance_nparray, adjacency_nparray,\n",
    "         total_weight) = calc_distance_matrix_and_minimum_spanning_tree(\n",
    "            temp_data_points_nparray, order)\n",
    "        distance_nparray_list.append(distance_nparray)\n",
    "        adjacency_nparray_list.append(adjacency_nparray)\n",
    "        cost_list.append(total_weight)\n",
    "    return (distance_nparray_list, adjacency_nparray_list, cost_list)\n",
    "\n",
    "def calc_intragroup_cost_value_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                               N_size, N_rank, N_accum, N_size_prod, order = 1.0):\n",
    "    intragroup_cost_value = 0\n",
    "    (intragroup_distance_nparray_list, intragroup_adjacency_nparray_list,\n",
    "     intragroup_cost_list) = calc_intragroup_cost_list_with_mst(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "        N_size, N_rank, N_accum, N_size_prod, order)\n",
    "    intragroup_cost_value = sum(intragroup_cost_list)/N_rank\n",
    "    return (intragroup_distance_nparray_list, intragroup_adjacency_nparray_list,\n",
    "            intragroup_cost_list, intragroup_cost_value)\n",
    "\n",
    "def calc_mean_cost_value_with_mst(grouping_indexes_list, data_points_nparray,\n",
    "                            N_size, N_rank, N_accum, N_size_prod, order = 1.0):\n",
    "    barycenter_nparray_list = []\n",
    "    for group, size in enumerate(N_size):\n",
    "        temp_data_points_nparray = []\n",
    "        for element in range(size):\n",
    "            temp_data_points_nparray.append(data_points_nparray[grouping_indexes_list[group][element]])\n",
    "        temp_barycenter_nparray = np.mean(temp_data_points_nparray, axis=0)\n",
    "        barycenter_nparray_list.append(temp_barycenter_nparray)\n",
    "    barycenter_nparray_list = np.array(barycenter_nparray_list)\n",
    "    ## Cost: MST\n",
    "    (distance_nparray, adjacency_nparray,\n",
    "        mean_cost_value) = calc_distance_matrix_and_minimum_spanning_tree(\n",
    "            barycenter_nparray_list, order)\n",
    "    mean_cost_value = mean_cost_value/N_rank\n",
    "    return (barycenter_nparray_list, mean_cost_value)\n",
    "\n",
    "def calc_deviation_cost_value_with_mst(intragroup_distance_nparray_list):\n",
    "    return (max(intragroup_distance_nparray_list) - min(intragroup_distance_nparray_list))\n",
    "\n",
    "def calc_aggregate_statistical_cost_list_with_mst(grouping_indexes_list, data_points_nparray,\n",
    "                                                  intragroup_distance_nparray_list, intragroup_adjacency_nparray_list, intragroup_cost_list,\n",
    "                                                  N_size, N_rank, N_accum, N_size_prod, order = 1.0):\n",
    "    (barycenter_nparray_list, mean_cost_value) = calc_mean_cost_value_with_mst(grouping_indexes_list, data_points_nparray,\n",
    "                                                                               N_size, N_rank, N_accum, N_size_prod, order)\n",
    "    deviation_cost_value = calc_deviation_cost_value_with_mst(intragroup_cost_list)\n",
    "    return (mean_cost_value, deviation_cost_value)\n",
    "\n",
    "def calc_adjusted_cost_value_with_mst(grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                             N_size, N_rank, N_accum, N_size_prod, \n",
    "                             mean_penalty_weight = 0.1, deviation_penalty_weight=0.8, order = 1.0,\n",
    "                             numerical_precision = 2e-8, ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200):\n",
    "    ## intergroup_cost_value\n",
    "    (intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "    intergroup_u_vec_list, intergroup_f_vec_list,\n",
    "    intergroup_cost_tensor) = calc_intergroup_cost_value_with_mst(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "        N_size, N_rank, N_accum, N_size_prod, order,\n",
    "        numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max\n",
    "        )\n",
    "    ## intragroup_cost_value\n",
    "    (intragroup_distance_nparray_list, intragroup_adjacency_nparray_list,\n",
    "            intragroup_cost_list, intragroup_cost_value) = calc_intragroup_cost_value_with_mst(\n",
    "        grouping_indexes_list, data_points_nparray, marginal_mass_vectors,\n",
    "        N_size, N_rank, N_accum, N_size_prod\n",
    "        )\n",
    "    ## aggregate_statistical_cost_value\n",
    "    (mean_cost_value, deviation_cost_value) = calc_aggregate_statistical_cost_list_with_mst(grouping_indexes_list, data_points_nparray,\n",
    "                                                                                            intragroup_distance_nparray_list, intragroup_adjacency_nparray_list, intragroup_cost_list, \n",
    "                                                                                            N_size, N_rank, N_accum, N_size_prod, order = 1.0)\n",
    "    ## adjusted_cost_value = (intergroup_cost_value + mean_cost_value + deviation_cost_value) / (intragroup_cost_value)\n",
    "    adjusted_cost_value = 0\n",
    "    if abs(intragroup_cost_value) < numerical_precision:\n",
    "        adjusted_cost_value = np.inf\n",
    "    else:\n",
    "        adjusted_cost_value = (intergroup_cost_value + mean_penalty_weight*mean_cost_value + deviation_penalty_weight*deviation_cost_value)/(intragroup_cost_value)\n",
    "    ## return\n",
    "    return (adjusted_cost_value, mean_cost_value, deviation_cost_value,\n",
    "            intragroup_cost_value, intragroup_distance_nparray_list, intragroup_adjacency_nparray_list, intragroup_cost_list,\n",
    "            intergroup_cost_value, intergroup_P_tensor, intergroup_weighted_cost_tensor, \n",
    "            intergroup_u_vec_list, intergroup_f_vec_list, intergroup_cost_tensor)\n",
    "\n",
    "def calc_optimal_grouping_with_mst(data_points_nparray, N_size,\n",
    "                           N_rank = None, N_accum = None, N_size_prod = None,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.8, order = 1.0,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 10, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           show_info = False, drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## N_rank, N_accum, N_size_prod, marginal_mass_vectors\n",
    "    if (N_rank is None) or (N_accum is None) or (N_size_prod is None):\n",
    "        (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    marginal_mass_vectors = calc_marginal_mass_vectors(N_rank, N_size)\n",
    "    ## Initial value settings\n",
    "    if init_grouping_indexes_list is None:\n",
    "        init_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "    ## Calculation of optimal transportation costs under initial conditions\n",
    "    (init_adjusted_cost_value, init_mean_cost_value, init_deviation_cost_value,\n",
    "    init_intragroup_cost_value, init_intragroup_distance_nparray_list, init_intragroup_adjacency_nparray_list, init_intragroup_cost_list,\n",
    "    init_intergroup_cost_value, init_intergroup_P_tensor, init_intergroup_weighted_cost_tensor,\n",
    "    init_intergroup_u_vec_list, init_intergroup_f_vec_list,\n",
    "    init_intergroup_cost_tensor) = calc_adjusted_cost_value_with_mst(init_grouping_indexes_list, data_points_nparray, marginal_mass_vectors, \n",
    "                             N_size, N_rank, N_accum, N_size_prod, \n",
    "                             mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                             numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "    ## Preparation for recording\n",
    "    iteration_number_list = [0]\n",
    "    elapsed_time_list = [0]\n",
    "    new_adjusted_cost_trends_list = [init_adjusted_cost_value]\n",
    "    opt_adjusted_cost_trends_list = [init_adjusted_cost_value]\n",
    "    start_time = time.time()\n",
    "    ## info\n",
    "    if show_info:\n",
    "        info_func(info_args, \"---------- init\")\n",
    "        info_func(info_args, \"init_grouping_indexes_list: \" + str(init_grouping_indexes_list))\n",
    "        info_func(info_args, \"init_adjusted_cost_value: \" + str(init_adjusted_cost_value))\n",
    "        info_func(info_args, \"  (init_intergroup_cost_value, init_intragroup_cost_value: \" + str(init_intergroup_cost_value) + \", \" + str(init_intragroup_cost_value) + \")\")\n",
    "        info_func(info_args, \"  (mean_penalty_weight*init_mean_cost_value, deviation_penalty_weight*init_deviation_cost_value : \" \n",
    "              + str(mean_penalty_weight*init_mean_cost_value) + \", \" + str(deviation_penalty_weight*init_deviation_cost_value) + \")\")\n",
    "    if drawing_graphs:\n",
    "        (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "                                                                init_grouping_indexes_list, data_points_nparray, \n",
    "                                                                N_size, N_rank, N_accum, N_size_prod,\n",
    "                                                                viz2d_x, viz2d_y, init_intergroup_P_tensor)\n",
    "        # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, init_grouping_indexes_list, data_points_nparray,\n",
    "        #                             viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Initial Value\")\n",
    "        show_P_tensor(init_intergroup_P_tensor, N_size, N_rank, N_accum, f_size=(4,3), f_title=\"Initial Value\")\n",
    "    ## opt\n",
    "    opt_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "    opt_adjusted_cost_value = init_adjusted_cost_value\n",
    "    opt_mean_cost_value = init_mean_cost_value\n",
    "    opt_deviation_cost_value = init_deviation_cost_value\n",
    "    opt_intragroup_cost_value = init_intragroup_cost_value\n",
    "    opt_intergroup_cost_value = init_intergroup_cost_value\n",
    "    opt_intergroup_P_tensor = copy.deepcopy(init_intergroup_P_tensor)\n",
    "    ## new\n",
    "    new_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "    new_adjusted_cost_value = init_adjusted_cost_value\n",
    "    new_mean_cost_value = init_mean_cost_value\n",
    "    new_deviation_cost_value = init_deviation_cost_value\n",
    "    new_intragroup_cost_value = init_intragroup_cost_value\n",
    "    new_intergroup_cost_value = init_intergroup_cost_value\n",
    "    new_intergroup_P_tensor = copy.deepcopy(init_intergroup_P_tensor)\n",
    "    new_intergroup_weighted_cost_tensor = copy.deepcopy(init_intergroup_weighted_cost_tensor)\n",
    "    new_intergroup_cost_tensor = copy.deepcopy(init_intergroup_cost_tensor)\n",
    "    ## Search for optimal value\n",
    "    new_grouping_flag = True\n",
    "    search_stopping_rule_counter = 0\n",
    "    for loop in range(global_loop_max):\n",
    "        if show_info:\n",
    "            info_func(info_args, \"---------- loop: \" + str(loop+1))\n",
    "        search_stopping_rule_counter = search_stopping_rule_counter + 1\n",
    "        if search_method==\"rand\": ## search_method==\"rand\"\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=True) ## True: Random grouping, False: Grouping in order\n",
    "        else: ## search_method==\"ex\" or search_method==\"hybrid\"\n",
    "            if (search_stopping_rule_counter >= search_stopping_rule_rep):\n",
    "                opt_adjusted_cost_diff_list = opt_adjusted_cost_trends_list[(len(opt_adjusted_cost_trends_list)-search_stopping_rule_rep):]\n",
    "                old_adjusted_cost_value = opt_adjusted_cost_diff_list[0]\n",
    "                opt_adjusted_cost_diff_list = abs(np.array(opt_adjusted_cost_diff_list) - old_adjusted_cost_value)\n",
    "                opt_adjusted_cost_diff_list = opt_adjusted_cost_diff_list/(abs(old_adjusted_cost_value)+numerical_precision)\n",
    "                opt_adjusted_cost_diff_max = max(opt_adjusted_cost_diff_list)\n",
    "                if opt_adjusted_cost_diff_max <= search_stopping_rule_err:\n",
    "                    if search_method==\"hybrid\": ## search_method==\"hybrid\"\n",
    "                        search_stopping_rule_counter = 0\n",
    "                        new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=True) ## True: Random grouping, False: Grouping in order\n",
    "                        if show_info:\n",
    "                            info_func(info_args, \"Grouping has been shuffled.\")\n",
    "                    else: ## search_method==\"ex\"\n",
    "                        if show_info:\n",
    "                            info_func(info_args, \"The stopping criterion determined that convergence to the optimum value was achieved.\")\n",
    "                        break\n",
    "            ## Local grouping: Select two clusters and perform an exchange between the two clusters\n",
    "            probability_tensor = copy.deepcopy(new_intergroup_weighted_cost_tensor)\n",
    "            cluster_1_value = (random.choices(probability_tensor, k=1, weights=probability_tensor))[0]\n",
    "            cluster_1_flattened_index_list = get_tensor_flattened_index_list_from_value(probability_tensor, cluster_1_value, tensor_tolerance)\n",
    "            cluster_1_flattened_index = random.choice(cluster_1_flattened_index_list)\n",
    "            cluster_1_multi_index = get_tensor_multi_index_from_flattened_index(cluster_1_flattened_index, N_rank, N_accum)\n",
    "            probability_tensor[cluster_1_flattened_index] = 0\n",
    "            cluster_2_value = (random.choices(probability_tensor, k=1, weights=probability_tensor))[0]\n",
    "            cluster_2_flattened_index_list = get_tensor_flattened_index_list_from_value(probability_tensor, cluster_2_value, tensor_tolerance)\n",
    "            cluster_2_flattened_index = random.choice(cluster_2_flattened_index_list)\n",
    "            cluster_2_multi_index = get_tensor_multi_index_from_flattened_index(cluster_2_flattened_index, N_rank, N_accum)\n",
    "            ## Preparation for local grouping\n",
    "            local_N_size = []\n",
    "            local_data_indexes = []\n",
    "            opt_local_grouping_indexes_list = []\n",
    "            ## local_N_size, local_data_indexes, opt_local_grouping_indexes_list, local_N_rank, local_N_accum, local_N_size_prod, local_marginal_mass_vectors\n",
    "            for local_group in range(N_rank):\n",
    "                if cluster_1_multi_index[local_group] == cluster_2_multi_index[local_group]:\n",
    "                    local_N_size.append(1)\n",
    "                    temp_index = new_grouping_indexes_list[local_group][cluster_1_multi_index[local_group]]\n",
    "                    local_data_indexes.append(temp_index)\n",
    "                    opt_local_grouping_indexes_list.append([temp_index])\n",
    "                else:\n",
    "                    local_N_size.append(2)\n",
    "                    temp_index_1 = new_grouping_indexes_list[local_group][cluster_1_multi_index[local_group]]\n",
    "                    temp_index_2 = new_grouping_indexes_list[local_group][cluster_2_multi_index[local_group]]\n",
    "                    local_data_indexes.append(temp_index_1)\n",
    "                    local_data_indexes.append(temp_index_2)\n",
    "                    opt_local_grouping_indexes_list.append([temp_index_1, temp_index_2])\n",
    "            local_N_size = tuple(local_N_size)\n",
    "            (local_N_rank, local_N_accum, local_N_size_prod) = get_N(local_N_size)\n",
    "            local_marginal_mass_vectors = calc_marginal_mass_vectors(local_N_rank, local_N_size)\n",
    "            ## Calculation of current local optimal transportation costs\n",
    "            (opt_local_adjusted_cost_value, opt_local_mean_cost_value, opt_local_deviation_cost_value,\n",
    "            opt_local_intragroup_cost_value, opt_local_intragroup_distance_nparray_list, opt_local_intragroup_adjacency_nparray_list, opt_local_intragroup_cost_list,\n",
    "            opt_local_intergroup_cost_value, opt_local_intergroup_P_tensor, opt_local_intergroup_weighted_cost_tensor,\n",
    "            opt_local_intergroup_u_vec_list, opt_local_intergroup_f_vec_list,\n",
    "            opt_local_intergroup_cost_tensor) = calc_adjusted_cost_value_with_mst(opt_local_grouping_indexes_list, data_points_nparray,\n",
    "                                                                                  local_marginal_mass_vectors,\n",
    "                                                                                  local_N_size, local_N_rank, local_N_accum, local_N_size_prod,\n",
    "                                                                                  mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                                                                                  numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "            old_local_adjusted_cost_value = opt_local_adjusted_cost_value\n",
    "            ## Enumeration of grouping patterns\n",
    "            ## (If N_rank is 2 or 3, all enumeration is used, and more than that, random selection is used.)\n",
    "            local_grouping_indexes_list_combinations = []\n",
    "            if local_N_rank == 2: ## It might be a good idea to have all the patterns ready in advance. (2^2-1=3)\n",
    "                numbers_list = list(range(sum(local_N_size)))\n",
    "                for sub_numbers_list_1 in itertools.combinations(numbers_list, local_N_size[0]):\n",
    "                    sub_numbers_list_2 = tuple(np.delete(numbers_list, sub_numbers_list_1, 0))\n",
    "                    temp_local_grouping_indexes_list = list((np.array(local_data_indexes))[list(sub_numbers_list_1+sub_numbers_list_2)])\n",
    "                    temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                    if temp_local_grouping_indexes_list != opt_local_grouping_indexes_list:\n",
    "                        local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            elif local_N_rank == 3: ## It might be a good idea to have all the patterns ready in advance. (2^3-1=7)\n",
    "                numbers_list = list(range(sum(local_N_size)))\n",
    "                for sub_numbers_list_1 in itertools.combinations(numbers_list, local_N_size[0]):\n",
    "                    temp_numbers_list = np.delete(numbers_list, sub_numbers_list_1, 0)\n",
    "                    for sub_numbers_list_2 in itertools.combinations(temp_numbers_list, local_N_size[1]):      \n",
    "                        sub_numbers_list_3 = tuple(np.delete(numbers_list, sub_numbers_list_1+sub_numbers_list_2, 0))\n",
    "                        temp_local_grouping_indexes_list = list((np.array(local_data_indexes))[list(sub_numbers_list_1+sub_numbers_list_2+sub_numbers_list_3)])\n",
    "                        temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                        if temp_local_grouping_indexes_list!= opt_local_grouping_indexes_list:\n",
    "                                local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            else:\n",
    "                for i in range(local_loop_max):\n",
    "                    temp_local_grouping_indexes_list = random.sample(local_data_indexes, len(local_data_indexes))\n",
    "                    temp_local_grouping_indexes_list = gen_grouping_indexes_list(local_N_size, rand=False, data_order_list=temp_local_grouping_indexes_list)\n",
    "                    if (temp_local_grouping_indexes_list!= opt_local_grouping_indexes_list) and (temp_local_grouping_indexes_list not in local_grouping_indexes_list_combinations):\n",
    "                                local_grouping_indexes_list_combinations.append(temp_local_grouping_indexes_list)\n",
    "            ## Calculate the cost of local optimal transportation for each pattern of local grouping\n",
    "            opt_local_adjusted_cost_value = float('inf')\n",
    "            opt_local_grouping_indexes_list_list = []\n",
    "            for new_local_grouping_indexes_list in local_grouping_indexes_list_combinations:\n",
    "                (new_local_adjusted_cost_value, new_local_mean_cost_value, new_local_deviation_cost_value,\n",
    "                new_local_intragroup_cost_value, new_local_intragroup_distance_nparray_list, new_local_intragroup_adjacency_nparray_list, new_local_intragroup_cost_list,\n",
    "                new_local_intergroup_cost_value, new_local_intergroup_P_tensor, new_local_intergroup_weighted_cost_tenso,\n",
    "                new_local_intergroup_u_vec_list, new_local_intergroup_f_vec_list,\n",
    "                new_local_intergroup_cost_tensor) = calc_adjusted_cost_value_with_mst(new_local_grouping_indexes_list, data_points_nparray,\n",
    "                                                                                  local_marginal_mass_vectors,\n",
    "                                                                                  local_N_size, local_N_rank, local_N_accum, local_N_size_prod,\n",
    "                                                                                  mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                                                                                  numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "                if new_local_adjusted_cost_value < opt_local_adjusted_cost_value:\n",
    "                    opt_local_adjusted_cost_value = new_local_adjusted_cost_value\n",
    "                    opt_local_grouping_indexes_list_list = [new_local_grouping_indexes_list]\n",
    "                elif new_local_adjusted_cost_value == opt_local_adjusted_cost_value:\n",
    "                    opt_local_grouping_indexes_list_list.append(new_local_grouping_indexes_list)\n",
    "            opt_local_grouping_indexes_list = random.choice(opt_local_grouping_indexes_list_list)\n",
    "            random_number = random.random()\n",
    "            new_grouping_flag = (opt_local_adjusted_cost_value==0) or (random_number <= (old_local_adjusted_cost_value/opt_local_adjusted_cost_value))\n",
    "            if new_grouping_flag:\n",
    "                for group in range(local_N_rank):\n",
    "                    if local_N_size[group] == 1:\n",
    "                        new_grouping_indexes_list[group][cluster_1_multi_index[group]] = opt_local_grouping_indexes_list[group][0]\n",
    "                    else:\n",
    "                        new_grouping_indexes_list[group][cluster_1_multi_index[group]] = opt_local_grouping_indexes_list[group][0]\n",
    "                        new_grouping_indexes_list[group][cluster_2_multi_index[group]] = opt_local_grouping_indexes_list[group][1]\n",
    "        if new_grouping_flag:\n",
    "            ## Calculation of the cost of optimal transport\n",
    "            (new_adjusted_cost_value, new_mean_cost_value, new_deviation_cost_value,\n",
    "            new_intragroup_cost_value, new_intragroup_distance_nparray_list, new_intragroup_adjacency_nparray_list, new_intragroup_cost_list,\n",
    "            new_intergroup_cost_value, new_intergroup_P_tensor, \n",
    "            new_intergroup_weighted_cost_tensor, new_intergroup_u_vec_list, new_intergroup_f_vec_list, \n",
    "            new_intergroup_cost_tensor) = calc_adjusted_cost_value_with_mst(new_grouping_indexes_list, data_points_nparray,\n",
    "                                                                            marginal_mass_vectors,\n",
    "                                                                            N_size, N_rank, N_accum, N_size_prod,\n",
    "                                                                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                                                                            numerical_precision, ot_speed, ot_stopping_rule, ot_loop_max)\n",
    "        if show_info:\n",
    "            info_func(info_args, \"new_grouping_indexes_list: \" + str(new_grouping_indexes_list))\n",
    "            info_func(info_args, \"new_adjusted_cost_value: \" + str(new_adjusted_cost_value))\n",
    "        # if drawing_graphs:\n",
    "        #     (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "        #                                                 new_grouping_indexes_list, data_points_nparray, \n",
    "        #                                                 N_size, N_rank, N_accum, N_size_prod,\n",
    "        #                                                 viz2d_x, viz2d_y, new_intergroup_P_tensor)\n",
    "        #     # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "        #     #                             viz2d_x, viz2d_y, line_width = 1, f_size=(4,3,1), f_title=\"Mid-calculation\")\n",
    "        if new_adjusted_cost_value <= opt_adjusted_cost_value:\n",
    "            opt_grouping_indexes_list = copy.deepcopy(new_grouping_indexes_list)\n",
    "            opt_adjusted_cost_value = new_adjusted_cost_value\n",
    "            opt_mean_cost_value = new_mean_cost_value\n",
    "            opt_deviation_cost_value = new_deviation_cost_value\n",
    "            opt_intragroup_cost_value = new_intragroup_cost_value\n",
    "            opt_intergroup_cost_value = new_intergroup_cost_value\n",
    "            opt_intergroup_P_tensor = copy.deepcopy(new_intergroup_P_tensor)\n",
    "        ## Recording\n",
    "        iteration_number_list.append(loop+1)\n",
    "        elapsed_time = float(time.time() - start_time)\n",
    "        elapsed_time_list.append(elapsed_time)\n",
    "        new_adjusted_cost_trends_list.append(new_adjusted_cost_value)\n",
    "        opt_adjusted_cost_trends_list.append(opt_adjusted_cost_value)\n",
    "    ## info\n",
    "    if show_info:\n",
    "        info_func(info_args, \"---------- opt\")\n",
    "        info_func(info_args, \"opt_grouping_indexes_list: \" + str(init_grouping_indexes_list))\n",
    "        info_func(info_args, \"opt_adjusted_cost_value: \" + str(opt_adjusted_cost_value))\n",
    "        info_func(info_args, \"  (opt_intergroup_cost_value, opt_intragroup_cost_value: \" + str(opt_intergroup_cost_value) + \", \" + str(opt_intragroup_cost_value) + \")\")\n",
    "        info_func(info_args, \"  (mean_penalty_weight*opt_mean_cost_value, deviation_penalty_weight*opt_deviation_cost_value : \"\n",
    "              + str(mean_penalty_weight*opt_mean_cost_value) + \", \" + str(deviation_penalty_weight*opt_deviation_cost_value) + \")\")\n",
    "        ## Computation time\n",
    "        elapsed_hour = elapsed_time // 3600\n",
    "        elapsed_minute = (elapsed_time % 3600) // 60\n",
    "        elapsed_second = (elapsed_time % 3600 % 60)\n",
    "        info_func(info_args, \"computation time:\" + str(elapsed_hour).zfill(2) + \":\" + str(elapsed_minute).zfill(2) + \":\" + str(elapsed_second).zfill(2))\n",
    "    if drawing_graphs:\n",
    "        (fig, ax, viz2d_x, viz2d_y) = show_2d_data_with_patches(is_umap_loaded, \n",
    "                                            opt_grouping_indexes_list, data_points_nparray, \n",
    "                                            N_size, N_rank, N_accum, N_size_prod,\n",
    "                                            viz2d_x, viz2d_y, opt_intergroup_P_tensor)\n",
    "        # (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, opt_grouping_indexes_list, data_points_nparray,\n",
    "        #                             viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "        show_P_tensor(opt_intergroup_P_tensor, N_size, N_rank, N_accum, f_size=(4,3), f_title=\"Optimal value\")\n",
    "     ## return\n",
    "    return (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "            opt_adjusted_cost_value,\n",
    "            opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "            opt_mean_cost_value, opt_deviation_cost_value,\n",
    "            iteration_number_list, elapsed_time_list,\n",
    "            new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "            viz2d_x, viz2d_y\n",
    "            )\n",
    "\n",
    "def gen_optimal_grouping_with_mst(data_points_nparray, N_size = None, standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 1.0,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## ## data_points_nparray: NumPy array consisting of data points\n",
    "    ## N_size: Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "    ## standardization = True ## Standardization\n",
    "    ## mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "    ## deviation_penalty_weight = 0.8 ## Weight of deviation_cost_value\n",
    "    ## order = 1.0 ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "    ## numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "    ## ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "    ## ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ## ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot\n",
    "    ## tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "    ## global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "    ## local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "    ## init_grouping_indexes_list = None ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## search_method = \"ex\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "    ## search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "    ## search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "    ## main_show_info = True ## Flag whether information is displayed or not\n",
    "    ## main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "    ## sub_show_info = False ## Flag whether information is displayed or not\n",
    "    ## sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "    ## info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "    ## info_args = None ## Arguments for info_func\n",
    "    ## tensor_size_max = 4000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "    ## group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "    ## loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "    ## viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## N_size\n",
    "    data_size = len(data_points_nparray)\n",
    "    if N_size is None:\n",
    "        info_func(info_args, \"Warning: N_size is None.\")\n",
    "        N_size = tuple(data_size)\n",
    "    if (type(N_size) == int):\n",
    "        if data_size > N_size:\n",
    "            (quotient, remainder) = divmod(data_size, N_size)\n",
    "            N_size = np.full(N_size, quotient)\n",
    "            for i in range(remainder):\n",
    "                N_size[i] = N_size[i] + 1\n",
    "            N_size = tuple(N_size)\n",
    "        else:\n",
    "            N_size = tuple(data_size)\n",
    "    elif (type(N_size) == tuple) or (type(N_size) == list):\n",
    "        N_size = tuple(N_size)\n",
    "        if data_size != sum(N_size):\n",
    "            info_func(info_args, \"Warning: The sum of N_size does not match sample size.\")\n",
    "            N_size = tuple(data_size)\n",
    "    else:\n",
    "        info_func(info_args, \"Warning: N_size must be of type integer or tuple.\")\n",
    "        N_size = tuple(data_size)\n",
    "    (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    res_calc_optimal_grouping = None\n",
    "    ## Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    ## Setting Parameters\n",
    "    if (N_size_prod > tensor_size_max) or (min(N_size) > group_size_max): ## If True, use \"approximate solution\".\n",
    "        ## Initial value settings\n",
    "        if init_grouping_indexes_list is None:\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "        else:\n",
    "            new_grouping_indexes_list = copy.deepcopy(init_grouping_indexes_list)\n",
    "        if main_show_info:\n",
    "            info_func(info_args, \"---------- new_grouping_indexes_list (initial value): \" + str(new_grouping_indexes_list))\n",
    "        if main_drawing_graphs:\n",
    "            (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                        viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Initial value\")\n",
    "        for loop in range( loop_max_multiplier*N_rank ):\n",
    "            (group_1, group_2) = random.sample(list(range(N_rank)), 2)\n",
    "            sub_N_size = [N_size[group_1], N_size[group_2]]\n",
    "            group_1_sub_index = []\n",
    "            group_2_sub_index = []\n",
    "            if sub_N_size[0] > group_size_max:\n",
    "                group_1_sub_index = random.sample(list(range(sub_N_size[0])), group_size_max)\n",
    "                sub_N_size[0] = group_size_max\n",
    "            else:\n",
    "                group_1_sub_index = list(range(sub_N_size[0]))\n",
    "            if sub_N_size[1] > group_size_max:\n",
    "                group_2_sub_index = random.sample(list(range(sub_N_size[1])), group_size_max)\n",
    "                sub_N_size[1] = group_size_max\n",
    "            else:\n",
    "                group_2_sub_index = list(range(sub_N_size[1]))\n",
    "            sub_N_size = tuple(sub_N_size)\n",
    "            sub_data_index = list(np.array(new_grouping_indexes_list[group_1])[group_1_sub_index]) + list(np.array(new_grouping_indexes_list[group_2])[group_2_sub_index])\n",
    "            sub_data_points_nparray = data_points_nparray[sub_data_index]\n",
    "            (sub_N_rank, sub_N_accum, sub_N_size_prod) = get_N(sub_N_size)\n",
    "            res_calc_optimal_grouping = calc_optimal_grouping_with_mst(\n",
    "                sub_data_points_nparray, sub_N_size,\n",
    "                sub_N_rank, sub_N_accum, sub_N_size_prod,\n",
    "                mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                numerical_precision,\n",
    "                ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                None, True, ## init_grouping_indexes_list, init_grouping_rand,\n",
    "                search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                sub_show_info, sub_drawing_graphs,\n",
    "                info_func,\n",
    "                info_args,\n",
    "                viz2d_x, viz2d_y)\n",
    "            sub_opt_grouping_indexes_list = res_calc_optimal_grouping[0]\n",
    "            group_1_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[0]])\n",
    "            group_2_sub_grouping_indexes_list = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[1]])\n",
    "            for i, index in enumerate(group_1_sub_index):\n",
    "                new_grouping_indexes_list[group_1][index] = group_1_sub_grouping_indexes_list[i]\n",
    "            for i, index in enumerate(group_2_sub_index):\n",
    "                new_grouping_indexes_list[group_2][index] = group_2_sub_grouping_indexes_list[i]\n",
    "            if main_show_info:\n",
    "                info_func(info_args, \"---------- loop (partial optimization): \" + str(loop+1))\n",
    "                info_func(info_args, \"---------- new_grouping_indexes_list (partial optimization): \" + str(new_grouping_indexes_list))\n",
    "            if (main_drawing_graphs) and (loop == (2*N_rank-1)):\n",
    "                (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                            viz2d_x, viz2d_y, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "        res_calc_optimal_grouping = (new_grouping_indexes_list, \n",
    "                                     None, # opt_intergroup_P_tensor,\n",
    "                                     None, # opt_adjusted_cost_value,\n",
    "                                     None, # opt_intergroup_cost_value,\n",
    "                                     None, # opt_intragroup_cost_value,\n",
    "                                     None, # opt_mean_cost_value,\n",
    "                                     None, # opt_deviation_cost_value,\n",
    "                                     None, # iteration_number_list,\n",
    "                                     None, # elapsed_time_list,\n",
    "                                     None, # new_adjusted_cost_trends_list,\n",
    "                                     None, # opt_adjusted_cost_trends_list,\n",
    "                                     viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_mst(data_points_nparray, N_size,\n",
    "                            N_rank, N_accum, N_size_prod,\n",
    "                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_indexes_list, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            info_func,\n",
    "                            info_args,\n",
    "                            viz2d_x, viz2d_y)\n",
    "    ## res_calc_optimal_grouping:\n",
    "    ## (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "    ##  opt_adjusted_cost_value,\n",
    "    ##  opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "    ##  opt_mean_cost_value, opt_deviation_cost_value,\n",
    "    ##  iteration_number_list, elapsed_time_list,\n",
    "    ##  new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "    ##  viz2d_x, viz2d_y)\n",
    "    return res_calc_optimal_grouping\n",
    "\n",
    "def gen_optimal_grouping_from_csv_file_with_mst(input_filepath= \"./members.csv\", input_index_col = 0, output_filepath = \"./grouping.csv\",\n",
    "                           N_size = None,\n",
    "                           standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1, order = 1.0,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## input_filepath = \"./members.csv\" ## File path of the input file, in csv format.\n",
    "    ## input_index_col = 0 ## Column number with column name or column number in the csv file\n",
    "    ## output_filepath = \"./grouping.csv\" ##  File path of the output file, in csv format.\n",
    "    ############################\n",
    "    ## Loading data: loading csv files\n",
    "    df = pd.read_csv(filepath_or_buffer=input_filepath, index_col=input_index_col)\n",
    "    output_data = copy.deepcopy(df)\n",
    "    data_size = len(df)\n",
    "    ############################\n",
    "    ## Dummy variable processing: dummy variable for columns where dtype is object\n",
    "    df = pd.get_dummies(df, drop_first=True, dtype=\"float\") # float64, uint8, bool\n",
    "    ############################\n",
    "    ##  Handling missing values: interpolate by median\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    ############################\n",
    "    ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray_org = np.array(df.values)\n",
    "    data_points_nparray = copy.deepcopy(data_points_nparray_org) ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray = data_points_nparray.astype(float)\n",
    "    ###########################################\n",
    "    ## Data Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    ###########################################\n",
    "    ## Division and Search\n",
    "    (opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "     opt_adjusted_cost_value,\n",
    "     opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "     opt_mean_cost_value, opt_deviation_cost_value,\n",
    "     iteration_number_list, elapsed_time_list,\n",
    "     new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "     viz2d_x, viz2d_y\n",
    "    ) = gen_optimal_grouping_with_mst(data_points_nparray, N_size, standardization,\n",
    "                            mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_indexes_list, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            sub_show_info, sub_drawing_graphs,\n",
    "                            info_func, info_args,\n",
    "                            tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                            viz2d_x, viz2d_y)\n",
    "    ###########################################\n",
    "    ## Output grouping results to csv file\n",
    "    group_labels_list = np.zeros(data_size)\n",
    "    group = 0\n",
    "    for members_list in opt_grouping_indexes_list:\n",
    "        for member in members_list:\n",
    "            group_labels_list[member] = int(group)\n",
    "        group = group + 1\n",
    "    output_data.insert(loc=0, column=\"Group\", value=group_labels_list.astype(int), allow_duplicates=True)\n",
    "    if (viz2d_x is not None) and (viz2d_y is not None):\n",
    "        output_data.insert(loc=1, column=\"viz2d_x\", value=viz2d_x.astype(float), allow_duplicates=True)\n",
    "        output_data.insert(loc=2, column=\"viz2d_y\", value=viz2d_y.astype(float), allow_duplicates=True)\n",
    "    output_data.to_csv(output_filepath)\n",
    "    ###########################################\n",
    "    ## Return\n",
    "    return (opt_grouping_indexes_list,\n",
    "            opt_intergroup_P_tensor,\n",
    "            opt_adjusted_cost_value,\n",
    "            opt_intergroup_cost_value, opt_intragroup_cost_value,\n",
    "            opt_mean_cost_value, opt_deviation_cost_value,\n",
    "            iteration_number_list, elapsed_time_list,\n",
    "            new_adjusted_cost_trends_list, opt_adjusted_cost_trends_list,\n",
    "            output_data, viz2d_x, viz2d_y\n",
    "    )\n",
    "\n",
    "## Functions for calculating optrimal grouping\n",
    "\n",
    "def calc_optimal_grouping(data_points_nparray, N_size,\n",
    "                           N_rank = None, N_accum = None, N_size_prod = None,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.8,\n",
    "                           cost_type = \"mst\", order = None,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 10, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           show_info = False, drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    res_calc_optimal_grouping = None\n",
    "    if (cost_type == \"mst\"):\n",
    "        if(order == None):\n",
    "            order = 1.0\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_mst(data_points_nparray, N_size,\n",
    "                           N_rank, N_accum, N_size_prod,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           show_info, drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    elif(cost_type == \"bc\"):\n",
    "        if(order == None):\n",
    "            order = 2.0\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_bc(data_points_nparray, N_size,\n",
    "                           N_rank, N_accum, N_size_prod,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           show_info, drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        cost_type = \"mst\"\n",
    "        order = 1.0\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping_with_mst(data_points_nparray, N_size,\n",
    "                           N_rank, N_accum, N_size_prod,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           show_info, drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    return res_calc_optimal_grouping\n",
    "\n",
    "def gen_optimal_grouping(data_points_nparray, N_size = None, standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1,\n",
    "                           cost_type = \"mst\", order = None,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## ## data_points_nparray: NumPy array consisting of data points\n",
    "    ## N_size: Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "    ## standardization = True ## Standardization\n",
    "    ## mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "    ## deviation_penalty_weight = 0.8 ## Weight of deviation_cost_value\n",
    "    ## cost_type = \"mst\" ## \"mst\": minimum spanning tree, \"bc\": barycenter\n",
    "    ## order = None ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "    ## numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "    ## ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "    ## ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ## ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot\n",
    "    ## tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "    ## global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "    ## local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "    ## init_grouping_indexes_list = None ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    ## search_method = \"ex\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "    ## search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "    ## search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "    ## main_show_info = True ## Flag whether information is displayed or not\n",
    "    ## main_drawing_graphs = True ## Flag whether or not to draw graphs\n",
    "    ## sub_show_info = False ## Flag whether information is displayed or not\n",
    "    ## sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "    ## info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "    ## info_args = None ## Arguments for info_func\n",
    "    ## tensor_size_max = 4000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "    ## group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "    ## loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "    ## viz2d_x = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## viz2d_y = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    ## N_size\n",
    "    res_gen_optimal_grouping = None\n",
    "    if (cost_type == \"mst\"):\n",
    "        if(order == None):\n",
    "            order = 1.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_with_mst(data_points_nparray, N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    elif(cost_type == \"bc\"):\n",
    "        if(order == None):\n",
    "            order = 2.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_with_bc(data_points_nparray, N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        cost_type = \"mst\"\n",
    "        order = 1.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_with_mst(data_points_nparray, N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    return res_gen_optimal_grouping\n",
    "\n",
    "def gen_optimal_grouping_from_csv_file(input_filepath= \"./members.csv\", input_index_col = 0, output_filepath = \"./grouping.csv\",\n",
    "                           N_size = None,\n",
    "                           standardization = True,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1,\n",
    "                           cost_type = \"mst\", order = None,\n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_indexes_list = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = True,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x = None, viz2d_y = None):\n",
    "    ## input_filepath = \"./members.csv\" ## File path of the input file, in csv format.\n",
    "    ## input_index_col = 0 ## Column number with column name or column number in the csv file\n",
    "    ## output_filepath = \"./grouping.csv\" ##  File path of the output file, in csv format.\n",
    "    res_gen_optimal_grouping = None\n",
    "    if (cost_type == \"mst\"):\n",
    "        if(order == None):\n",
    "            order = 1.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_from_csv_file_with_mst(input_filepath, input_index_col, output_filepath,\n",
    "                           N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    elif(cost_type == \"bc\"):\n",
    "        if(order == None):\n",
    "            order = 2.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_from_csv_file_with_bc(input_filepath, input_index_col, output_filepath,\n",
    "                           N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    else:\n",
    "        cost_type = \"mst\"\n",
    "        order = 1.0\n",
    "        res_gen_optimal_grouping = gen_optimal_grouping_from_csv_file_with_mst(input_filepath, input_index_col, output_filepath,\n",
    "                           N_size, standardization,\n",
    "                           mean_penalty_weight, deviation_penalty_weight, order,\n",
    "                           numerical_precision,\n",
    "                           ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                           tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                           init_grouping_indexes_list, init_grouping_rand,\n",
    "                           search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                           main_show_info, main_drawing_graphs,\n",
    "                           sub_show_info, sub_drawing_graphs,\n",
    "                           info_func,\n",
    "                           info_args,\n",
    "                           tensor_size_max, group_size_max, loop_max_multiplier,\n",
    "                           viz2d_x, viz2d_y)\n",
    "    return res_gen_optimal_grouping\n",
    "\n",
    "## Functions for displaying information and drawing graphs\n",
    "\n",
    "def cprint(txt, color=\"BRIGHT_CYAN\", end=\"\\n\"):\n",
    "    if os.name == 'nt':\n",
    "        COLORS = {\n",
    "        \"BLACK\": \"\\033[30m\",\n",
    "        \"RED\": \"\\033[31m\",\n",
    "        \"GREEN\": \"\\033[32m\",\n",
    "        \"YELLOW\": \"\\033[33m\",\n",
    "        \"BLUE\": \"\\033[34m\",\n",
    "        \"MAGENTA\": \"\\033[35m\",\n",
    "        \"CYAN\": \"\\033[36m\",\n",
    "        \"WHITE\": \"\\033[37m\",\n",
    "        \"DEFAULT_COLOR\": \"\\033[39m\",\n",
    "        \"GRAY\": \"\\033[90m\",\n",
    "        \"BRIGHT_RED\": \"\\033[91m\",\n",
    "        \"BRIGHT_GREEN\": \"\\033[92m\",\n",
    "        \"BRIGHT_YELLOW\": \"\\033[93m\",\n",
    "        \"BRIGHT_BLUE\": \"\\033[94m\",\n",
    "        \"BRIGHT_MAGENTA\": \"\\033[95m\",\n",
    "        \"BRIGHT_CYAN\": \"\\033[96m\",\n",
    "        \"BRIGHT_WHITE\": \"\\033[97m\",\n",
    "        }\n",
    "        END = \"\\033[0m\"\n",
    "        print(COLORS[color] + txt + END, end=end)\n",
    "    else:\n",
    "        print(txt)\n",
    "\n",
    "def get_rank_vec(v):\n",
    "    n = len(v)\n",
    "    rank = [0]*n\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if v[i]>v[j]:\n",
    "                rank[j] = rank[j] + 1\n",
    "            else:\n",
    "                rank[i] = rank[i] + 1\n",
    "    return rank\n",
    "\n",
    "def get_points_list_in_non_intersecting_order(x, y):\n",
    "    n = len(x)\n",
    "    qcos_vec = [0]*n\n",
    "    reference_index = y.index(min(y))\n",
    "    qcos_vec[reference_index] = 2\n",
    "    indices_rem = (list(range(n)))\n",
    "    indices_rem.pop(reference_index)\n",
    "    range_x = max(x)-min(x)\n",
    "    for i in indices_rem:\n",
    "        dx = (x[i]-x[reference_index])\n",
    "        dy = (y[i]-y[reference_index])\n",
    "        dr = math.sqrt(dx*dx + dy*dy)\n",
    "        if dr == 0:\n",
    "            qcos_vec[i] = 2\n",
    "        elif dx == dr:\n",
    "            qcos_vec[i] = 2 - dx/range_x\n",
    "        elif dx == -dr:\n",
    "            qcos_vec[i] = -2 - dx/range_x\n",
    "        else:\n",
    "            qcos_vec[i] = dx/dr\n",
    "    rank_cos = get_rank_vec(qcos_vec)\n",
    "    points = [[]]*n\n",
    "    for i in range(n):\n",
    "        points[rank_cos[i]] = [x[i], y[i]]\n",
    "    return points\n",
    "\n",
    "def show_P_tensor(P_tensor, N_size, N_rank, N_accum, f_size=(6,4), numerical_precision=1e-8, f_title=\"\"):\n",
    "    ## Draw the graph of the tensor of the solution of the grouping\n",
    "    ## The horizontal axis is the groups (1～N_rank) and the vertical axis is the number of elements belonging to each group (N_size).\n",
    "    ## A single line corresponds to one element of the tensor. The higher the value, the thicker the line.\n",
    "    ## ------------------------------\n",
    "    ## Visualization of P_tensor\n",
    "    x = list(range(N_rank))\n",
    "    x = [element+1 for element in x]\n",
    "    fig = plt.figure(figsize = (f_size[0], f_size[1]), facecolor=\"mistyrose\")\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(f_title)\n",
    "    ax.set_xlim((0, N_rank+1))\n",
    "    ax.set_ylim((0, max(N_size)+1))\n",
    "    P_max = max(P_tensor)\n",
    "    for m_index in np.ndindex(tuple(N_size)):\n",
    "        temp_y = list(m_index)\n",
    "        temp_y = [element+1 for element in temp_y]\n",
    "        temp_P_ratio = P_tensor[get_tensor_flattened_index_from_multi_index(m_index, N_rank, N_accum)] / (P_max + numerical_precision)\n",
    "        lwd = 10*math.sqrt(temp_P_ratio) # 10 * math.log( math.exp(1) - 1 + temp_P_ratio　)\n",
    "        ax.plot(x, temp_y, linewidth=lwd, alpha=0.5)\n",
    "\n",
    "def gen_2d_data(is_umap_loaded, data_points_nparray):\n",
    "    if len(data_points_nparray[0,:]) > 2:\n",
    "        if is_umap_loaded:\n",
    "            ## Umap\n",
    "            print(\"Umapping...\", flush=\"True\")\n",
    "            mapper = umap.UMAP(random_state=0)\n",
    "            embedding = mapper.fit_transform(data_points_nparray)\n",
    "            return (embedding[:,0], embedding[:,1])\n",
    "        else:\n",
    "            print(\"For two-dimensional visualization, use only the first and second variables.\")\n",
    "            return (data_points_nparray[:,0], data_points_nparray[:,1])\n",
    "    elif len(data_points_nparray[0,:]) == 2:\n",
    "        return (data_points_nparray[:,0], data_points_nparray[:,1])\n",
    "    elif len(data_points_nparray[0,:]) == 1:\n",
    "        return (data_points_nparray[:,0], np.zeros(len(data_points_nparray[:,0])))\n",
    "    else:\n",
    "        return ([0], [0])\n",
    "\n",
    "def show_2d_data(is_umap_loaded, grouping_indexes_list, data_points_nparray,\n",
    "                 viz2d_x = None, viz2d_y = None, line_width = 1, f_size=(8,6,4), f_title=\"\"):\n",
    "    ## Visualization of two-dimensional data\n",
    "    ## Each group is arranged in order of starting point (tau) to ending point (nu).\n",
    "    len_data_points_nparray = len(data_points_nparray)\n",
    "    if len_data_points_nparray > 20:\n",
    "        line_width = 0\n",
    "    if grouping_indexes_list is None:\n",
    "        grouping_indexes_list = [list(range(len_data_points_nparray))]\n",
    "    if (viz2d_x is None) or (viz2d_y is None):\n",
    "        viz2d_x, viz2d_y = gen_2d_data(is_umap_loaded, data_points_nparray)\n",
    "    x_min = min(viz2d_x)\n",
    "    x_max = max(viz2d_x)\n",
    "    x_range = x_max - x_min\n",
    "    y_min = 0\n",
    "    y_max = 0\n",
    "    y_range = 0\n",
    "    if len(data_points_nparray[0,:]) > 1:\n",
    "        viz2d_y = viz2d_y\n",
    "        y_min = min(viz2d_y)\n",
    "        y_max = max(viz2d_y)\n",
    "        y_range = y_max - y_min\n",
    "    figsize_x = f_size[0]\n",
    "    figsize_y = f_size[1]\n",
    "    if max(x_range, y_range) <= 0:\n",
    "        figsize_x = f_size[0]\n",
    "        figsize_y = f_size[1]\n",
    "    elif x_range > y_range:\n",
    "        figsize_x = f_size[0]\n",
    "        figsize_y = max(f_size[2] ,min(f_size[1], f_size[1]*(y_range/x_range)))\n",
    "    else:\n",
    "        figsize_y = f_size[1]\n",
    "        figsize_x = max(f_size[2] ,min(f_size[1], f_size[1]*(x_range/y_range)))\n",
    "    fig = plt.figure(figsize = (figsize_x, figsize_y), facecolor=\"mistyrose\")\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim((x_min-2, x_max+2))\n",
    "    ax.set_ylim((y_min-2, y_max+2))\n",
    "    colors = cm.tab10 # cm.tab20\n",
    "    len_colors = 10\n",
    "    markers = [\"o\", \"^\", \"s\", \"p\", \"D\", \"H\", \"*\", \"v\", \"<\", \">\",  \n",
    "                \"+\", \"x\", \".\", \",\", \"d\", \"h\", \"1\", \"2\", \"3\", \"4\", \"8\", \"|\", \"_\"]\n",
    "    for group, index_list in enumerate(grouping_indexes_list):\n",
    "        if len(index_list)>0:\n",
    "            x = []\n",
    "            y = []\n",
    "            x_start = [] # Starting point: tau\n",
    "            y_start = [] # Starting point: tau\n",
    "            x_end = [] # Ending point: nu\n",
    "            y_end = [] # Ending point: nu\n",
    "            p_color = colors(int(group)%len_colors)\n",
    "            p_marker = markers[int(group)%len(markers)]\n",
    "            for j, element in enumerate(index_list):\n",
    "                x.append(viz2d_x[element])\n",
    "                y.append(viz2d_y[element])\n",
    "                if j==0:\n",
    "                    x_start = [viz2d_x[element]]\n",
    "                    y_start = [viz2d_y[element]]\n",
    "                elif j==(len(index_list)-1):\n",
    "                    x_end = [viz2d_x[element]]\n",
    "                    y_end = [viz2d_y[element]]\n",
    "            ax.plot(x, y, alpha=0.5, color=p_color, marker=p_marker, markersize=12, linewidth=line_width)\n",
    "            ax.set_title(f_title)\n",
    "            if line_width > 0:\n",
    "                ## Starting point: tau\n",
    "                ax.plot(x_start, y_start, alpha=0.5, marker=\"$\\\\tau$\", markersize=6, color=\"black\")\n",
    "                ## Ending point: nu\n",
    "                ax.plot(x_end, y_end, alpha=0.5, marker=\"$\\\\nu$\", markersize=6, color=\"black\")\n",
    "    return (fig, ax, viz2d_x, viz2d_y)\n",
    "\n",
    "def show_2d_data_with_patches(is_umap_loaded, grouping_indexes_list, data_points_nparray, \n",
    "                              N_size, N_rank, N_accum, N_size_prod,\n",
    "                              viz2d_x = None, viz2d_y = None, patch_weight = None, line_width = 1, f_size=(8,6,4), f_title=\"\"):\n",
    "    (fig, ax, viz2d_x, viz2d_y) = show_2d_data(is_umap_loaded, grouping_indexes_list, data_points_nparray,\n",
    "                                               viz2d_x, viz2d_y,\n",
    "                                               line_width = 1, f_size=(8,6,4), f_title=\"\")\n",
    "    if patch_weight is not None:\n",
    "        patch_weight_max = max(patch_weight)\n",
    "        if patch_weight_max > 0:\n",
    "            if (N_rank is None) or (N_accum is None) or (N_size_prod is None):\n",
    "                (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "            for m_index in np.ndindex(N_size):\n",
    "                w = get_tensor_value_from_multi_index(patch_weight, m_index, N_rank, N_accum)\n",
    "                alp = w / patch_weight_max\n",
    "                alp = 0.5 * alp / N_rank\n",
    "                if alp > 0.001:\n",
    "                    x_vec = []\n",
    "                    y_vec = []\n",
    "                    for group in range(N_rank):\n",
    "                        index_value = grouping_indexes_list[group][m_index[group]]\n",
    "                        x_vec.append(viz2d_x[index_value])\n",
    "                        y_vec.append(viz2d_y[index_value])\n",
    "                    if N_rank > 2:\n",
    "                        points = get_points_list_in_non_intersecting_order(x_vec, y_vec)\n",
    "                        patch = patches.Polygon(xy=points, closed=True, alpha=alp, color='black')\n",
    "                        ax.add_patch(patch)\n",
    "                    elif N_rank == 2:\n",
    "                        ax.plot(x_vec, y_vec, alpha=alp, color='black',\n",
    "                                marker=None, linestyle='solid', linewidth=2)\n",
    "    return (fig, ax, viz2d_x, viz2d_y)\n",
    "\n",
    "def get_argmax_list(target_tensor, fixed_group_list, fixed_element_list, \n",
    "                    N_size, N_rank, N_accum):\n",
    "    N_size_partially_fixed = copy.deepcopy(N_size)\n",
    "    N_size_partially_fixed = list(N_size_partially_fixed)\n",
    "    if (len(fixed_group_list)!=0) and (len(fixed_group_list)==len(fixed_element_list)):\n",
    "        for group in fixed_group_list:\n",
    "            N_size_partially_fixed[group] = 1\n",
    "    N_size_partially_fixed = tuple(N_size_partially_fixed)\n",
    "    temp_max = 0\n",
    "    argmax_list = []\n",
    "    for m_index in np.ndindex(N_size_partially_fixed):\n",
    "        m_index_list = list(m_index)\n",
    "        if (len(fixed_group_list)!=0) and (len(fixed_group_list)==len(fixed_element_list)):\n",
    "            for element, group in enumerate(fixed_group_list):\n",
    "                m_index_list[group] = fixed_element_list[element]\n",
    "        temp_value = target_tensor[get_tensor_flattened_index_from_multi_index(m_index_list, N_rank, N_accum)]\n",
    "        if temp_value == temp_max:\n",
    "            argmax_list.append(m_index_list)\n",
    "        elif temp_value > temp_max:\n",
    "            temp_max = temp_value\n",
    "            argmax_list = [m_index_list]\n",
    "    return argmax_list\n",
    "\n",
    "def get_marginal_value(target_tensor, fixed_group_list, fixed_element_list, \n",
    "                       N_size, N_rank, N_accum):\n",
    "    N_size_partially_fixed = copy.deepcopy(N_size)\n",
    "    N_size_partially_fixed = list(N_size_partially_fixed)\n",
    "    if (len(fixed_group_list)!=0) and (len(fixed_group_list)==len(fixed_element_list)):\n",
    "        for group in fixed_group_list:\n",
    "            N_size_partially_fixed[group] = 1\n",
    "    N_size_partially_fixed = tuple(N_size_partially_fixed)\n",
    "    marginal_value = 0\n",
    "    for m_index in np.ndindex(N_size_partially_fixed):\n",
    "        m_index_list = list(m_index)\n",
    "        if (len(fixed_group_list)!=0) and (len(fixed_group_list)==len(fixed_element_list)):\n",
    "            for element, group in enumerate(fixed_group_list):\n",
    "                m_index_list[group] = fixed_element_list[element]\n",
    "        temp_value = target_tensor[get_tensor_flattened_index_from_multi_index(m_index_list, N_rank, N_accum)]\n",
    "        marginal_value = marginal_value + temp_value\n",
    "    return marginal_value\n",
    "\n",
    "############################################################\n",
    "#### WebUI with Gradio ####\n",
    "\n",
    "def remove_unnecessary_characters(txt):\n",
    "    txt = txt.replace(\" \", \"\")\n",
    "    txt = txt.replace(\"\\n\", \"\")\n",
    "    txt = txt.replace(\"\\t\", \"\")\n",
    "    txt = txt.replace(\",,\", \",\")\n",
    "    txt = txt.replace(\"[[\", \"[\")\n",
    "    txt = txt.replace(\"]]\", \"]\")\n",
    "    txt = txt.replace(\"[,[\", \"[\")\n",
    "    txt = txt.replace(\"],]\", \"]\")\n",
    "    txt = txt.removeprefix(\",\")\n",
    "    txt = txt.removesuffix(\",\")\n",
    "    txt = txt.removeprefix(\"[\")\n",
    "    txt = txt.removesuffix(\"]\")\n",
    "    txt = txt.removeprefix(\",\")\n",
    "    txt = txt.removesuffix(\",\")\n",
    "    return txt\n",
    "\n",
    "def str_to_int_list(txt):\n",
    "    txt = remove_unnecessary_characters(txt)\n",
    "    txt = txt.split(\",\")\n",
    "    txt = [int(e) for e in txt]\n",
    "    return txt\n",
    "\n",
    "def is_float_str(txt):\n",
    "    try:\n",
    "        float(txt)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def get_cleaned_df_and_viz2d(df, standardization=True):\n",
    "    df = df.replace(\"\", np.nan).dropna(how='any')\n",
    "    ## Converts a string that can be converted to a number to a number\n",
    "    for colname, item in df.items():\n",
    "        df[colname] = pd.to_numeric(item, errors=\"ignore\")\n",
    "    df_cleaned = copy.deepcopy(df)\n",
    "    ## Dummy variable processing: dummy variable for columns where dtype is object\n",
    "    df_cleaned = pd.get_dummies(df_cleaned, drop_first=True, dtype=\"float\") # float64, uint8, bool\n",
    "    ##  Handling missing values: interpolate by median\n",
    "    for col in df_cleaned.columns:\n",
    "        df_cleaned[col] = df_cleaned[col].fillna(df_cleaned[col].median())\n",
    "    ## data_points_nparray: NumPy array consisting of data points\n",
    "    data_points_nparray = np.array(df_cleaned.values)\n",
    "    data_points_nparray = data_points_nparray.astype(float)\n",
    "    ## Data Standardization\n",
    "    if standardization:\n",
    "        for i in range((data_points_nparray.shape)[1]):\n",
    "            if np.var(data_points_nparray[:,i]) > 0:\n",
    "                data_points_nparray[:,i] = (data_points_nparray[:,i] - np.mean(data_points_nparray[:,i]))/np.std(data_points_nparray[:,i])\n",
    "            else:\n",
    "                data_points_nparray[:,i] = data_points_nparray[:,i] - np.mean(data_points_nparray[:,i])\n",
    "    df_cleaned = pd.DataFrame(data_points_nparray,\n",
    "                 index=df_cleaned.index.values,\n",
    "                 columns=df_cleaned.columns.values)\n",
    "    ## 2d\n",
    "    viz2d_x_value, viz2d_y_value = gen_2d_data(is_umap_loaded, data_points_nparray)\n",
    "    ## labels\n",
    "    viz2d_x_label = \"x_umapped\"\n",
    "    viz2d_y_label = \"y_umapped\"\n",
    "    if (not(is_umap_loaded)) or (df_cleaned.shape[1] == 2):\n",
    "        viz2d_x_label = df_cleaned.columns[0]\n",
    "        viz2d_y_label = df_cleaned.columns[1]\n",
    "    elif df_cleaned.shape[1] < 2:\n",
    "        viz2d_x_label = df_cleaned.columns[0]\n",
    "        viz2d_y_label = \"\"\n",
    "    return (df_cleaned, viz2d_x_value, viz2d_y_value, viz2d_x_label, viz2d_y_label)\n",
    "\n",
    "def load_csv(input_filepath, input_index_col, standardization=True):\n",
    "    ## Loading data: loading csv file\n",
    "    df_org = pd.read_csv(filepath_or_buffer=input_filepath, index_col=input_index_col)\n",
    "    (df_cleaned, viz2d_x_value, viz2d_y_value,\n",
    "     viz2d_x_label, viz2d_y_label) = get_cleaned_df_and_viz2d(df_org, standardization)\n",
    "    ## return\n",
    "    return (df_org, df_cleaned, viz2d_x_value, viz2d_y_value, viz2d_x_label, viz2d_y_label)\n",
    "\n",
    "def gen_grouping_in_gradio(df_org, df_cleaned, N_size = None,\n",
    "                           mean_penalty_weight = 0.1, deviation_penalty_weight = 0.1,\n",
    "                           cost_type = \"mst\", order = None, \n",
    "                           numerical_precision = 2e-8,\n",
    "                           ot_speed = 0.02, ot_stopping_rule = 0.02, ot_loop_max = 200,\n",
    "                           tensor_tolerance = 2e-8, global_loop_max = 100, local_loop_max = 100,\n",
    "                           init_grouping_index = None, init_grouping_rand = True,\n",
    "                           search_method = \"ex\", search_stopping_rule_err = 0.02, search_stopping_rule_rep = 20,\n",
    "                           main_show_info = True, main_drawing_graphs = False,\n",
    "                           sub_show_info = False, sub_drawing_graphs = False,\n",
    "                           info_func = (lambda info_args, txt: print(str(txt))),\n",
    "                           info_args = None,\n",
    "                           tensor_size_max = 4000, group_size_max = 20, loop_max_multiplier = 4,\n",
    "                           viz2d_x_value = None, viz2d_y_value = None):\n",
    "    data_points_nparray = np.array(df_cleaned.values)\n",
    "    if search_method == \"ex\":\n",
    "        info_func(info_args, \"Search for optimal values using the exchange algorithm.\") \n",
    "    elif search_method == \"hybrid\":\n",
    "        info_func(info_args, \"Search for optimal values using the hybrid algorithm.\")\n",
    "    else:\n",
    "        info_func(info_args, \"Search for optimal values at random.\")\n",
    "    ## N_size\n",
    "    data_size = len(data_points_nparray)\n",
    "    if N_size is None:\n",
    "        info_func(info_args, \"Warning: N_size is None.\")\n",
    "        N_size = tuple(data_size)\n",
    "    if (type(N_size) == int):\n",
    "        if data_size > N_size:\n",
    "            (quotient, remainder) = divmod(data_size, N_size)\n",
    "            N_size = np.full(N_size, quotient)\n",
    "            for i in range(remainder):\n",
    "                N_size[i] = N_size[i] + 1\n",
    "            N_size = tuple(N_size)\n",
    "        else:\n",
    "            N_size = tuple(data_size)\n",
    "    elif (type(N_size) == tuple) or (type(N_size) == list):\n",
    "        N_size = tuple(N_size)\n",
    "        if data_size != sum(N_size):\n",
    "            info_func(info_args, \"Warning: The sum of N_size does not match sample size.\")\n",
    "            N_size = tuple(data_size)\n",
    "    else:\n",
    "        info_func(info_args, \"Warning: N_size must be of type integer or tuple.\")\n",
    "        N_size = tuple(data_size)\n",
    "    (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "    ## Setting Parameters\n",
    "    res_calc_optimal_grouping = None\n",
    "    opt_grouping_indexes_list = None\n",
    "    opt_intergroup_P_tensor = None\n",
    "    print(\"ok1\")\n",
    "    if (N_size_prod > tensor_size_max) or (min(N_size) > group_size_max): ## If True, use \"approximate solution\".\n",
    "        ## Initial value settings\n",
    "        new_grouping_indexes_list = None\n",
    "        if init_grouping_index is None:\n",
    "            new_grouping_indexes_list = gen_grouping_indexes_list(N_size, rand=init_grouping_rand) ## True: Random grouping, False: Grouping in order\n",
    "        else:\n",
    "            new_grouping_indexes_list = copy.deepcopy(init_grouping_index)\n",
    "        if main_show_info:\n",
    "            info_func(info_args, \"---------- new_grouping_indexes_list (initial value): \" + str(new_grouping_indexes_list))\n",
    "        if main_drawing_graphs:\n",
    "            (viz2d_x_value, viz2d_y_value) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                        viz2d_x_value, viz2d_y_value, line_width = 1, f_size=(5,4,2), f_title=\"Initial value\")\n",
    "        for loop in range( loop_max_multiplier*N_rank ):\n",
    "            (group_1, group_2) = random.sample(list(range(N_rank)), 2)\n",
    "            sub_N_size = [N_size[group_1], N_size[group_2]]\n",
    "            group_1_sub_index = []\n",
    "            group_2_sub_index = []\n",
    "            if sub_N_size[0] > group_size_max:\n",
    "                group_1_sub_index = random.sample(list(range(sub_N_size[0])), group_size_max)\n",
    "                sub_N_size[0] = group_size_max\n",
    "            else:\n",
    "                group_1_sub_index = list(range(sub_N_size[0]))\n",
    "            if sub_N_size[1] > group_size_max:\n",
    "                group_2_sub_index = random.sample(list(range(sub_N_size[1])), group_size_max)\n",
    "                sub_N_size[1] = group_size_max\n",
    "            else:\n",
    "                group_2_sub_index = list(range(sub_N_size[1]))\n",
    "            sub_N_size = tuple(sub_N_size)\n",
    "            sub_data_index = list(np.array(new_grouping_indexes_list[group_1])[group_1_sub_index]) + list(np.array(new_grouping_indexes_list[group_2])[group_2_sub_index])\n",
    "            sub_data_points_nparray = data_points_nparray[sub_data_index]\n",
    "            (sub_N_rank, sub_N_accum, sub_N_size_prod) = get_N(sub_N_size)\n",
    "            res_calc_optimal_grouping = calc_optimal_grouping(\n",
    "                sub_data_points_nparray, sub_N_size,\n",
    "                sub_N_rank, sub_N_accum, sub_N_size_prod,\n",
    "                mean_penalty_weight, deviation_penalty_weight,\n",
    "                cost_type, order,\n",
    "                numerical_precision,\n",
    "                ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                None, True, ## init_grouping_index, init_grouping_rand,\n",
    "                search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                sub_show_info, sub_drawing_graphs,\n",
    "                info_func, info_args,\n",
    "                viz2d_x_value, viz2d_y_value)\n",
    "            sub_opt_grouping_indexes_list = res_calc_optimal_grouping[0]\n",
    "            group_1_sub_grouping_index = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[0]])\n",
    "            group_2_sub_grouping_index = list(np.array(sub_data_index)[sub_opt_grouping_indexes_list[1]])\n",
    "            for i, index in enumerate(group_1_sub_index):\n",
    "                new_grouping_indexes_list[group_1][index] = group_1_sub_grouping_index[i]\n",
    "            for i, index in enumerate(group_2_sub_index):\n",
    "                new_grouping_indexes_list[group_2][index] = group_2_sub_grouping_index[i]\n",
    "            if main_show_info:\n",
    "                info_func(info_args, \"---------- loop (partial optimization): \" + str(loop+1))\n",
    "                info_func(info_args, \"---------- new_grouping_indexes_list (partial optimization): \" + str(new_grouping_indexes_list))\n",
    "            if (main_drawing_graphs) and (loop == (2*N_rank-1)):\n",
    "                (viz2d_x_value, viz2d_y_value) = show_2d_data(is_umap_loaded, new_grouping_indexes_list, data_points_nparray,\n",
    "                                            viz2d_x_value, viz2d_y_value, line_width = 1, f_size=(5,4,2), f_title=\"Optimal value\")\n",
    "        opt_grouping_indexes_list = new_grouping_indexes_list\n",
    "    else:\n",
    "        res_calc_optimal_grouping = calc_optimal_grouping(data_points_nparray, N_size,\n",
    "                            N_rank, N_accum, N_size_prod,\n",
    "                            mean_penalty_weight, deviation_penalty_weight,\n",
    "                            cost_type, order,\n",
    "                            numerical_precision,\n",
    "                            ot_speed, ot_stopping_rule, ot_loop_max,\n",
    "                            tensor_tolerance, global_loop_max, local_loop_max,\n",
    "                            init_grouping_index, init_grouping_rand,\n",
    "                            search_method, search_stopping_rule_err, search_stopping_rule_rep,\n",
    "                            main_show_info, main_drawing_graphs,\n",
    "                            info_func, info_args,\n",
    "                            viz2d_x_value, viz2d_y_value)\n",
    "        opt_grouping_indexes_list = res_calc_optimal_grouping[0]\n",
    "        opt_intergroup_P_tensor = res_calc_optimal_grouping[1]\n",
    "    ###########################################\n",
    "    ## Output grouping results\n",
    "    output_data = copy.deepcopy(df_org)\n",
    "    group_labels_list = np.zeros(data_size)\n",
    "    group = 0\n",
    "    for members_list in opt_grouping_indexes_list:\n",
    "        for member in members_list:\n",
    "            group_labels_list[member] = int(group)\n",
    "        group = group + 1\n",
    "    output_data.insert(loc=0, column=\"Group\", value=group_labels_list.astype(int), allow_duplicates=True)\n",
    "    # output_data.insert(loc=1, column=\"viz2d_x_value\", value=viz2d_x_value.astype(float), allow_duplicates=True)\n",
    "    # output_data.insert(loc=2, column=\"viz2d_y_value\", value=viz2d_y_value.astype(float), allow_duplicates=True)\n",
    "    return (output_data, group_labels_list,\n",
    "            opt_grouping_indexes_list, opt_intergroup_P_tensor,\n",
    "            N_size, N_rank, N_accum, N_size_prod)\n",
    "\n",
    "def draw_graph_in_gradio(index_values,\n",
    "                         viz2d_x_value, viz2d_y_value,\n",
    "                         viz2d_x_label = \"x\", viz2d_y_label = \"y\",\n",
    "                         group_labels_list = None,\n",
    "                         grouping_indexes_list = None, patch_weight = None,\n",
    "                         N_size = None, N_rank = None, N_accum = None, N_size_prod = None):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.cla()\n",
    "    fig.set_facecolor(\"#C0C0C0\") ## silver=#C0C0C0, lightgray=#D3D3D3, whitesmoke=#F5F5F5, snow=#FFFAFA\n",
    "    ax.set_facecolor(\"#F5F5F5\") ## silver=#C0C0C0, lightgray=#D3D3D3, whitesmoke=#F5F5F5, snow=#FFFAFA\n",
    "    ax.set_xlabel(viz2d_x_label)\n",
    "    ax.set_ylabel(viz2d_y_label)\n",
    "    patch_weight_dataframe = None\n",
    "    if group_labels_list is None:\n",
    "        ax.plot(viz2d_x_value, viz2d_y_value, alpha=0.5, marker=\"o\", markersize=10, linewidth=0)\n",
    "        for i, lab in enumerate(index_values): ## labels\n",
    "            ax.annotate(lab, (viz2d_x_value[i], viz2d_y_value[i]))\n",
    "    else:\n",
    "        colors = cm.tab10 # cm.tab20\n",
    "        len_colors = 10\n",
    "        markers = [\"o\", \"^\", \"s\", \"p\", \"D\", \"H\", \"*\", \"v\", \"<\", \">\",  \n",
    "                        \"+\", \"x\", \".\", \",\", \"d\", \"h\", \"1\", \"2\", \"3\", \"4\", \"8\", \"|\", \"_\"]\n",
    "        for i, lab in enumerate(index_values):\n",
    "            p_color = colors(int(group_labels_list[i])%len_colors)\n",
    "            p_marker = markers[int(group_labels_list[i])%len(markers)]\n",
    "            ax.plot(viz2d_x_value[i], viz2d_y_value[i],\n",
    "                            color=p_color, marker=p_marker,\n",
    "                            alpha=0.5, markersize=10, linewidth=0)\n",
    "            ax.annotate(index_values[i], (viz2d_x_value[i], viz2d_y_value[i]))\n",
    "        if patch_weight is not None:\n",
    "            if (N_rank is None) or (N_accum is None) or (N_size_prod is None):\n",
    "                (N_rank, N_accum, N_size_prod) = get_N(N_size)\n",
    "            patch_weight_max = max(patch_weight)\n",
    "            patch_weight_dataframe_columns = [\"weight\"]\n",
    "            for group in range(N_rank):\n",
    "                patch_weight_dataframe_columns = patch_weight_dataframe_columns + [\"label_\"+str(group), \"x_\"+str(group), \"y_\"+str(group)]\n",
    "            patch_weight_dataframe = pd.DataFrame(columns=patch_weight_dataframe_columns)\n",
    "            for m_index in np.ndindex(N_size):\n",
    "                patch_weight_value = get_tensor_value_from_multi_index(patch_weight, m_index, N_rank, N_accum) / patch_weight_max\n",
    "                label_vec = []\n",
    "                x_vec = []\n",
    "                y_vec = []\n",
    "                patch_weight_label = \"(\"\n",
    "                for group in range(N_rank):\n",
    "                    temp_index = grouping_indexes_list[group][m_index[group]]\n",
    "                    label_vec.append(index_values[temp_index])\n",
    "                    x_vec.append(viz2d_x_value[temp_index])\n",
    "                    y_vec.append(viz2d_y_value[temp_index])\n",
    "                    patch_weight_label = patch_weight_label + str(index_values[temp_index])\n",
    "                    if group < (N_rank - 1):\n",
    "                        patch_weight_label = patch_weight_label + \", \"\n",
    "                    else:\n",
    "                        patch_weight_label = patch_weight_label + \")\"\n",
    "                label_x_y_vec = []\n",
    "                for label, x, y in zip(label_vec, x_vec, y_vec):\n",
    "                    label_x_y_vec = label_x_y_vec + [label, x, y]\n",
    "                patch_weight_new_row = [patch_weight_value] + label_x_y_vec\n",
    "                patch_weight_new_dataframe = pd.DataFrame(data=[patch_weight_new_row],\n",
    "                      index=[patch_weight_label],\n",
    "                      columns=patch_weight_dataframe.columns)\n",
    "                if patch_weight_dataframe.empty:\n",
    "                    patch_weight_dataframe = copy.deepcopy(patch_weight_new_dataframe)\n",
    "                else:\n",
    "                    patch_weight_dataframe = pd.concat([patch_weight_dataframe, patch_weight_new_dataframe])\n",
    "                alp = 0.5 * patch_weight_value / N_rank\n",
    "                if alp > 0.001:\n",
    "                    if N_rank > 2:\n",
    "                        points = get_points_list_in_non_intersecting_order(x_vec, y_vec)\n",
    "                        patch = patches.Polygon(xy=points, closed=True, alpha=alp, color='black')\n",
    "                        ax.add_patch(patch)\n",
    "                    elif N_rank == 2:\n",
    "                        ax.plot(x_vec, y_vec, alpha=alp, color='black',\n",
    "                                marker=None, linestyle='solid', linewidth=2)\n",
    "    plt.close()\n",
    "    return (fig, ax, patch_weight_dataframe)\n",
    "\n",
    "class GradioParameters:\n",
    "    standardization = True\n",
    "    input_filepath = \"./input.csv\"\n",
    "    input_filename = \"input.csv\"\n",
    "    input_filedirectory = \"./\"\n",
    "    input_index_col = None\n",
    "    df_org = None\n",
    "    df_cleaned = None\n",
    "    df_viz2d = None\n",
    "    fig = None\n",
    "    ax = None\n",
    "    output_filename = \"output_otg.csv\"\n",
    "    preprocessed_data_filename = \"preprocessed_data.csv\"\n",
    "    viz2d_data_filename = \"viz2d_data.csv\"\n",
    "    output_data = None\n",
    "    group_labels_list = None\n",
    "    opt_grouping_indexes_list = None\n",
    "    opt_intergroup_P_tensor = None\n",
    "    N_size = None ## Tuple consisting of the number of elements in each group. If the variable is an integer, the tuple is automatically generated close to equally divided.\n",
    "    N_rank = None\n",
    "    N_accum = None\n",
    "    N_size_prod = None\n",
    "    mean_penalty_weight = 0.1 ## Weight of mean_cost_value\n",
    "    deviation_penalty_weight = 0.1 ## Weight of deviation_cost_value\n",
    "    cost_type = \"mst\" ## \"mst\": minimum spanning tree, \"bc\": barycenter\n",
    "    order = None ## Norm order: order=1.0 is the Manhattan distance and order=2 is the Euclidean distance. (If order==None, then order = 1.0 when cost_type==\"mst\" and order = 2.0 when cost_type==\"bc\".)\n",
    "    numerical_precision = 2e-8 ## Values whose absolute value is less than or equal to numerical_precision are treated as 0.\n",
    "    ot_speed = 0.02 ## Bigger means faster, smaller means stricter\n",
    "    ot_stopping_rule = 0.02 ## Criteria to stop updating \"u\". If the relative error of \"u\" is smaller than the stop criterion, it is terminated.\n",
    "    ot_loop_max = 200 ## Maximum number of iterations in calc_multi_ot\n",
    "    tensor_tolerance = 2e-8 ## Tolerance of values when obtaining the tensor index from the value\n",
    "    global_loop_max = 100 ## Maximum number of iterations in calc_optimal_grouping\n",
    "    local_loop_max = 100 ## Upper bound on the number of enumerated patterns of local exchange\n",
    "    init_grouping_index = None ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    init_grouping_rand = True ## If initial value is None, randomly (if init_grouping_rand == True) generates an initial value\n",
    "    search_method = \"ex\" ## \"ex\": exchange algorithm, \"rand\": random search, \"hybrid\": Hybrid of exchange algorithm and random search.\n",
    "    search_stopping_rule_err = 0.02 ## Criteria to stop searching by exchange algprithm.\n",
    "    search_stopping_rule_rep = 20 ## It stops when the relative difference in the optimal cost is search_stopping_rule_err or less for search_stopping_rule_rep consecutive periods.\n",
    "    main_show_info = True ## Flag whether information is displayed or not\n",
    "    main_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "    sub_show_info = False ## Flag whether information is displayed or not\n",
    "    sub_drawing_graphs = False ## Flag whether or not to draw graphs\n",
    "    info_func = (lambda info_args, txt: print(str(txt))) ## Function for displaying information\n",
    "    info_args = None ## Arguments for info_func\n",
    "    tensor_size_max = 4000 ## Maximum number of elements in the cost tensor. If N_size_prod > tensor_size_max, use an \"approximate solution\". \n",
    "    group_size_max = 20 ## Maximum number of elements to be extracted if the group has a large number of elements. If min(N_size) > group_size_max, use an \"approximate solution\". \n",
    "    loop_max_multiplier = 4 ## Multiplier of the number of loops in the \"approximate solution\". \n",
    "    viz2d_x_value = None ## x-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    viz2d_y_value = None ## y-axis values for data visualization (If None, it is automatically calculated.)\n",
    "    viz2d_x_label = \"x\"\n",
    "    viz2d_y_label = \"y\"\n",
    "    patch_weight_dataframe = None\n",
    "    patch_weight_filename = \"weight_data_otg.csv\"\n",
    "\n",
    "def upload_file(file, standardization):\n",
    "    GradioParameters.patch_weight_dataframe = None\n",
    "    GradioParameters.standardization = standardization\n",
    "    GradioParameters.input_filepath = file\n",
    "    GradioParameters.input_index_col = 0\n",
    "    (GradioParameters.df_org, GradioParameters.df_cleaned,\n",
    "     GradioParameters.viz2d_x_value, GradioParameters.viz2d_y_value,\n",
    "     GradioParameters.viz2d_x_label, GradioParameters.viz2d_y_label) = load_csv(\n",
    "         GradioParameters.input_filepath, GradioParameters.input_index_col, standardization)\n",
    "    GradioParameters.df_viz2d = pd.DataFrame(data={GradioParameters.viz2d_x_label:GradioParameters.viz2d_x_value,\n",
    "                                                 GradioParameters.viz2d_y_label:GradioParameters.viz2d_y_value},\n",
    "                                                 index=GradioParameters.df_org.index.values)\n",
    "    (GradioParameters.fig, GradioParameters.ax, GradioParameters.patch_weight_dataframe) = draw_graph_in_gradio(GradioParameters.df_org.index.values,\n",
    "                                               GradioParameters.viz2d_x_value, GradioParameters.viz2d_y_value,\n",
    "                                               GradioParameters.viz2d_x_label, GradioParameters.viz2d_y_label)\n",
    "    return (\"\",\n",
    "            GradioParameters.df_org.reset_index(),\n",
    "            GradioParameters.df_cleaned.reset_index(),\n",
    "            GradioParameters.df_viz2d.reset_index(),\n",
    "            GradioParameters.fig,\n",
    "            gr.File(interactive=False, visible=False),\n",
    "            gr.File(interactive=False, visible=False),\n",
    "            gr.File(interactive=False, visible=False),\n",
    "            gr.File(interactive=False, visible=False),\n",
    "            gr.Button(value=\"Hide polygons and line segments\", visible=False))\n",
    "\n",
    "def apply_changes_to_data(members_dataframe, standardization):\n",
    "    GradioParameters.patch_weight_dataframe = None\n",
    "    GradioParameters.standardization = standardization\n",
    "    GradioParameters.df_org = members_dataframe\n",
    "    GradioParameters.df_org = GradioParameters.df_org.set_index(\"index\")\n",
    "    GradioParameters.df_org = GradioParameters.df_org.replace(\"\", np.nan).dropna(how='any')\n",
    "    (GradioParameters.df_cleaned,\n",
    "     GradioParameters.viz2d_x_value,\n",
    "     GradioParameters.viz2d_y_value,\n",
    "     GradioParameters.viz2d_x_label,\n",
    "     GradioParameters.viz2d_y_label) = get_cleaned_df_and_viz2d(GradioParameters.df_org,\n",
    "                                                              GradioParameters.standardization)\n",
    "    GradioParameters.df_viz2d = pd.DataFrame(data={GradioParameters.viz2d_x_label:GradioParameters.viz2d_x_value,\n",
    "                                                 GradioParameters.viz2d_y_label:GradioParameters.viz2d_y_value},\n",
    "                                                 index=GradioParameters.df_org.index.values)\n",
    "    (GradioParameters.fig, GradioParameters.ax, GradioParameters.patch_weight_dataframe) = draw_graph_in_gradio(GradioParameters.df_org.index.values,\n",
    "                                               GradioParameters.viz2d_x_value, GradioParameters.viz2d_y_value,\n",
    "                                               GradioParameters.viz2d_x_label, GradioParameters.viz2d_y_label)\n",
    "    return (\"\",\n",
    "            GradioParameters.df_org.reset_index(),\n",
    "            GradioParameters.df_cleaned.reset_index(),\n",
    "            GradioParameters.df_viz2d.reset_index(),\n",
    "            GradioParameters.fig,\n",
    "            gr.File(interactive=False, visible=False),\n",
    "            gr.File(interactive=False, visible=False),\n",
    "            gr.File(interactive=False, visible=False),\n",
    "            gr.File(interactive=False, visible=False),\n",
    "            gr.Button(value=\"Hide polygons and line segments\", visible=False))\n",
    "\n",
    "def start_grouping(number_of_divisions, speed_slider,\n",
    "                   m_weight_slider, d_weight_slider,\n",
    "                   method_dropdown, standardization,\n",
    "                   cost_type_dropdown,\n",
    "                   global_loop_max_slider, local_loop_max_slider,\n",
    "                   search_stopping_rule_err_slider, search_stopping_rule_rep_slider,\n",
    "                   tensor_size_max_slider, group_size_max_slider, loop_max_multiplier_slider,\n",
    "                   members_dataframe):\n",
    "    ## Members data\n",
    "    GradioParameters.patch_weight_dataframe = None\n",
    "    GradioParameters.standardization = standardization\n",
    "    GradioParameters.df_org = members_dataframe\n",
    "    GradioParameters.df_org = GradioParameters.df_org.set_index(\"index\")\n",
    "    GradioParameters.df_org = GradioParameters.df_org.replace(\"\", np.nan).dropna(how='any')\n",
    "    (GradioParameters.df_cleaned,\n",
    "     GradioParameters.viz2d_x_value,\n",
    "     GradioParameters.viz2d_y_value,\n",
    "     GradioParameters.viz2d_x_label,\n",
    "     GradioParameters.viz2d_y_label\n",
    "     ) = get_cleaned_df_and_viz2d(GradioParameters.df_org, GradioParameters.standardization)\n",
    "    GradioParameters.df_viz2d = pd.DataFrame(data={GradioParameters.viz2d_x_label:GradioParameters.viz2d_x_value,\n",
    "                                                 GradioParameters.viz2d_y_label:GradioParameters.viz2d_y_value},\n",
    "                                                 index=GradioParameters.df_org.index.values)\n",
    "    ## N_size\n",
    "    GradioParameters.N_size = str_to_int_list(number_of_divisions)\n",
    "    if len(GradioParameters.N_size) == 1:\n",
    "        GradioParameters.N_size = int(GradioParameters.N_size[0])\n",
    "    GradioParameters.ot_speed = float(speed_slider)\n",
    "    GradioParameters.mean_penalty_weight = float(m_weight_slider)\n",
    "    GradioParameters.deviation_penalty_weight = float(d_weight_slider)\n",
    "    GradioParameters.global_loop_max = int(global_loop_max_slider)\n",
    "    GradioParameters.local_loop_max = int(local_loop_max_slider)\n",
    "    GradioParameters.search_stopping_rule_err = float(search_stopping_rule_err_slider)\n",
    "    GradioParameters.search_stopping_rule_rep = int(search_stopping_rule_rep_slider)\n",
    "    GradioParameters.tensor_size_max = int(tensor_size_max_slider)\n",
    "    GradioParameters.group_size_max = int(group_size_max_slider)\n",
    "    GradioParameters.loop_max_multiplier = int(loop_max_multiplier_slider)\n",
    "    if cost_type_dropdown == \"Distance from barycenter\":\n",
    "        GradioParameters.cost_type = \"bc\"\n",
    "    elif cost_type_dropdown == \"Minimum spanning tree\":\n",
    "        GradioParameters.cost_type = \"mst\"\n",
    "    else:\n",
    "        GradioParameters.cost_type = \"mst\"\n",
    "    if method_dropdown == \"Heuristics\":\n",
    "        GradioParameters.search_method = \"ex\"\n",
    "    elif method_dropdown == \"Hybrid\":\n",
    "        GradioParameters.search_method = \"hybrid\"\n",
    "    else:\n",
    "        GradioParameters.search_method = \"rand\"\n",
    "    (GradioParameters.output_data, GradioParameters.group_labels_list,\n",
    "         GradioParameters.opt_grouping_indexes_list, GradioParameters.opt_intergroup_P_tensor,\n",
    "         GradioParameters.N_size, GradioParameters.N_rank,\n",
    "         GradioParameters.N_accum, GradioParameters.N_size_prod) = gen_grouping_in_gradio(\n",
    "            GradioParameters.df_org, GradioParameters.df_cleaned,\n",
    "            GradioParameters.N_size,\n",
    "            GradioParameters.mean_penalty_weight, GradioParameters.deviation_penalty_weight, \n",
    "            GradioParameters.cost_type, GradioParameters.order, \n",
    "            GradioParameters.numerical_precision,\n",
    "            GradioParameters.ot_speed, GradioParameters.ot_stopping_rule, GradioParameters.ot_loop_max,\n",
    "            GradioParameters.tensor_tolerance, GradioParameters.global_loop_max, GradioParameters.local_loop_max,\n",
    "            GradioParameters.init_grouping_index, GradioParameters.init_grouping_rand,\n",
    "            GradioParameters.search_method, GradioParameters.search_stopping_rule_err, GradioParameters.search_stopping_rule_rep,\n",
    "            GradioParameters.main_show_info, GradioParameters.main_drawing_graphs,\n",
    "            GradioParameters.sub_show_info, GradioParameters.sub_drawing_graphs,\n",
    "            GradioParameters.info_func,\n",
    "            None, ## info_args # [GradioParameters.info_address, GradioParameters.info_history],\n",
    "            GradioParameters.tensor_size_max, GradioParameters.group_size_max, GradioParameters.loop_max_multiplier,\n",
    "            GradioParameters.viz2d_x_value, GradioParameters.viz2d_y_value)\n",
    "    (GradioParameters.fig, GradioParameters.ax, GradioParameters.patch_weight_dataframe) = draw_graph_in_gradio(GradioParameters.df_org.index.values,\n",
    "                                                    GradioParameters.viz2d_x_value,\n",
    "                                                    GradioParameters.viz2d_y_value,\n",
    "                                                    GradioParameters.viz2d_x_label,\n",
    "                                                    GradioParameters.viz2d_y_label,\n",
    "                                                    GradioParameters.group_labels_list,\n",
    "                                                    GradioParameters.opt_grouping_indexes_list,\n",
    "                                                    GradioParameters.opt_intergroup_P_tensor,\n",
    "                                                    GradioParameters.N_size, GradioParameters.N_rank,\n",
    "                                                    GradioParameters.N_accum, GradioParameters.N_size_prod)\n",
    "    if GradioParameters.opt_intergroup_P_tensor is None:\n",
    "        show_polygons_button = gr.Button(value=\"\", visible=False)\n",
    "    else:\n",
    "        show_polygons_button = gr.Button(value=\"Hide polygons and line segments\", visible=True)\n",
    "    return (\"Group index: \"+str(GradioParameters.group_labels_list),\n",
    "            GradioParameters.df_org.reset_index(),\n",
    "            GradioParameters.df_cleaned.reset_index(),\n",
    "            GradioParameters.df_viz2d.reset_index(),\n",
    "            GradioParameters.fig, \n",
    "            gr.File(interactive=False, visible=False),\n",
    "            gr.File(interactive=False, visible=False),\n",
    "            gr.File(interactive=False, visible=False),\n",
    "            gr.File(interactive=False, visible=False),\n",
    "            show_polygons_button\n",
    "            )\n",
    "\n",
    "def export_output_csv_file(e):\n",
    "    GradioParameters.output_filename = \"output_otg.\" + (datetime.datetime.now()).strftime('%Y%m%d%H%M%S') + \".csv\"\n",
    "    GradioParameters.output_data.to_csv(GradioParameters.output_filename)\n",
    "    return gr.File(value=GradioParameters.output_filename, visible=True)\n",
    "\n",
    "def export_preprocessed_data_csv_file(e):\n",
    "    GradioParameters.preprocessed_data_filename = \"preprocessed_data_otg.\" + (datetime.datetime.now()).strftime('%Y%m%d%H%M%S') + \".csv\"\n",
    "    GradioParameters.df_cleaned.to_csv(GradioParameters.preprocessed_data_filename)\n",
    "    return gr.File(value=GradioParameters.preprocessed_data_filename, visible=True)\n",
    "\n",
    "def export_viz2d_data_csv_file(e):\n",
    "    GradioParameters.viz2d_data_filename = \"viz2d_data_otg.\" + (datetime.datetime.now()).strftime('%Y%m%d%H%M%S') + \".csv\"\n",
    "    GradioParameters.df_viz2d.to_csv(GradioParameters.viz2d_data_filename)\n",
    "    return gr.File(value=GradioParameters.viz2d_data_filename, visible=True)\n",
    "\n",
    "def export_patch_weight_data_csv_file(e):\n",
    "    if GradioParameters.patch_weight_dataframe is not None:\n",
    "        GradioParameters.patch_weight_filename = \"weight_data_otg.\" + (datetime.datetime.now()).strftime('%Y%m%d%H%M%S') + \".csv\"\n",
    "        GradioParameters.patch_weight_dataframe.to_csv(GradioParameters.patch_weight_filename)\n",
    "        return gr.File(value=GradioParameters.patch_weight_filename, visible=True)\n",
    "    else:\n",
    "        return gr.File(interactive=False, visible=False)\n",
    "\n",
    "GradioParameters.patch_weight_dataframe = None\n",
    "def show_polygons(show_polygons_button):\n",
    "    if show_polygons_button == \"Hide polygons and line segments\":\n",
    "        (GradioParameters.fig, GradioParameters.ax, GradioParameters.patch_weight_dataframe) = draw_graph_in_gradio(GradioParameters.df_org.index.values,\n",
    "                                                    GradioParameters.viz2d_x_value,GradioParameters.viz2d_y_value,\n",
    "                                                    GradioParameters.viz2d_x_label,GradioParameters.viz2d_y_label,\n",
    "                                                    GradioParameters.group_labels_list,\n",
    "                                                    GradioParameters.opt_grouping_indexes_list,\n",
    "                                                    None,\n",
    "                                                    GradioParameters.N_size, GradioParameters.N_rank,\n",
    "                                                    GradioParameters.N_accum, GradioParameters.N_size_prod)\n",
    "        return (GradioParameters.fig, \"Show polygons and line segments\")\n",
    "    else:\n",
    "        (GradioParameters.fig, GradioParameters.ax, GradioParameters.patch_weight_dataframe) = draw_graph_in_gradio(GradioParameters.df_org.index.values,\n",
    "                                                    GradioParameters.viz2d_x_value,GradioParameters.viz2d_y_value,\n",
    "                                                    GradioParameters.viz2d_x_label,GradioParameters.viz2d_y_label,\n",
    "                                                    GradioParameters.group_labels_list,\n",
    "                                                    GradioParameters.opt_grouping_indexes_list,\n",
    "                                                    GradioParameters.opt_intergroup_P_tensor,\n",
    "                                                    GradioParameters.N_size, GradioParameters.N_rank,\n",
    "                                                    GradioParameters.N_accum, GradioParameters.N_size_prod)\n",
    "        return (GradioParameters.fig, \"Hide polygons and line segments\")\n",
    "\n",
    "number_of_divisions_info = \"Enter an integer greater than 1 or an array consisting of integers\"\n",
    "number_of_divisions_info = number_of_divisions_info + \" (Example: entering \\\"3\\\" or \\\"[4,4,4]\\\" will divide 12 data into three equal parts;\"\n",
    "number_of_divisions_info = number_of_divisions_info + \" entering [2,2,8] will create an unbalanced division)\"\n",
    "## Variables\n",
    "df_init = pd.DataFrame(\n",
    "(np.array([1,1, 1,2, 1,3, 1,4,  2,1, 2,2, 2,3, 2,4,  3,1, 3,2, 3,3, 3,4,])).reshape(12, 2),\n",
    "    index=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\"],\n",
    "    columns=[\"x\", \"y\"])\n",
    "GradioParameters.df_org = copy.deepcopy(df_init)\n",
    "(GradioParameters.df_cleaned, \n",
    " GradioParameters.viz2d_x_value,\n",
    " GradioParameters.viz2d_y_value, \n",
    " GradioParameters.viz2d_x_label,\n",
    " GradioParameters.viz2d_y_label) = get_cleaned_df_and_viz2d(GradioParameters.df_org,\n",
    "                                                            GradioParameters.standardization)\n",
    "GradioParameters.df_viz2d = pd.DataFrame(data={GradioParameters.viz2d_x_label:GradioParameters.viz2d_x_value,\n",
    "                                                 GradioParameters.viz2d_y_label:GradioParameters.viz2d_y_value},\n",
    "                                           index=GradioParameters.df_org.index.values)\n",
    "GradioParameters.output_data = copy.deepcopy(GradioParameters.df_org)\n",
    "(GradioParameters.fig, GradioParameters.ax, GradioParameters.patch_weight_dataframe) = draw_graph_in_gradio(GradioParameters.df_org.index.values,\n",
    "                                               GradioParameters.viz2d_x_value,\n",
    "                                               GradioParameters.viz2d_y_value,\n",
    "                                               GradioParameters.viz2d_x_label,\n",
    "                                               GradioParameters.viz2d_y_label)\n",
    "\n",
    "with gr.Blocks(title=\"Grouping by Optimal Transport\") as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            upload_button = gr.UploadButton(\"Click to Upload a File\", file_types=[\"dataframe\"], file_count=\"single\")\n",
    "            with gr.Group():\n",
    "                number_of_divisions = gr.Text(value=2, \n",
    "                                            label=\"Number of groups\", \n",
    "                                            info=number_of_divisions_info,\n",
    "                                            interactive=True)\n",
    "                speed_slider = gr.Slider(minimum=0.0001, maximum=1.0, step=0.0001, value=0.02, \n",
    "                                    label=\"Speed\", info=\"Choose between 0.0001 and 1.0\", interactive=True)\n",
    "                m_weight_slider = gr.Slider(minimum=0.0, maximum=1.0, step=0.01, value=0.1, \n",
    "                                    label=\"Weight for balance of means\",\n",
    "                                    info=\"Set weight for balance of means in the range of 0.0 to 1.0\", interactive=True)\n",
    "                d_weight_slider = gr.Slider(minimum=0.0, maximum=1.0, step=0.01, value=0.1, \n",
    "                                    label=\"Weight for balance of deviations\",\n",
    "                                    info=\"Set weight for balance of deviations in the range of 0.0 to 1.0\", interactive=True)\n",
    "                method_dropdown = gr.Dropdown(choices=[\"Heuristics\", \"Hybrid\", \"Random search\"], value=\"Heuristics\",\n",
    "                                    label=\"Search method\", info=\"Choose search method\", interactive=True)\n",
    "                standardization_checkbox = gr.Checkbox(value=True, label=\"Standardization\")\n",
    "                with gr.Accordion(label=\"Advanced Settings\", open=False):\n",
    "                    cost_type_dropdown = gr.Dropdown(choices=[\"Distance from barycenter\", \"Minimum spanning tree\"], value=\"Minimum spanning tree\",\n",
    "                                    label=\"Type of cost\", info=\"Choose type of cost\", interactive=True)\n",
    "                    global_loop_max_slider = gr.Slider(minimum=1, maximum=10000, step=1, value=100, \n",
    "                                    label=\"Maximum number of loops in parent process\",\n",
    "                                    info=\"Set maximum number of loops in parent process in the range of 1 to 10000\",\n",
    "                                    interactive=True)\n",
    "                    local_loop_max_slider = gr.Slider(minimum=1, maximum=10000, step=1, value=100, \n",
    "                                    label=\"Maximum number of loops in child process\",\n",
    "                                    info=\"Set maximum number of loops in child process in the range of 1 to 10000\",\n",
    "                                    interactive=True)\n",
    "                    search_stopping_rule_err_slider = gr.Slider(minimum=0.0, maximum=1.0, step=0.0001, value=0.02, \n",
    "                                    label=\"Criteria for stopping rule\",\n",
    "                                    info=\"Set criteria for stopping rule in the range of 0.0 to 1.0\",\n",
    "                                    interactive=True)\n",
    "                    search_stopping_rule_rep_slider = gr.Slider(minimum=1, maximum=1000, step=1, value=20, \n",
    "                                    label=\"Number of checks for stopping rule\",\n",
    "                                    info=\"Set number of checks for stopping rule in the range of 1 to 1000\",\n",
    "                                    interactive=True)\n",
    "                    tensor_size_max_slider = gr.Slider(minimum=1, maximum=1000000, step=1, value=4000, \n",
    "                                    label=\"Upper limit of tensor size\",\n",
    "                                    info=\"Set upper limit of tensor size in the range of 1 to 1000000 (If tensor size exceeds upper limit, move to approximate computation)\",\n",
    "                                    interactive=True)\n",
    "                    group_size_max_slider = gr.Slider(minimum=1, maximum=1000, step=1, value=20, \n",
    "                                    label=\"Upper limit of number of groups\",\n",
    "                                    info=\"Set upper limit of number of groups in the range of 1 to 1000 (If number of groups exceeds upper limit, move to approximate computation)\",\n",
    "                                    interactive=True)\n",
    "                    loop_max_multiplier_slider = gr.Slider(minimum=1, maximum=1000, step=1, value=4, \n",
    "                                    label=\"Maximum number of loops in approximate computation\",\n",
    "                                    info=\"Set maximum number of loops in approximate computation in the range of 1 to 1000\",\n",
    "                                    interactive=True)\n",
    "                start_button = gr.Button(value=\"Run\")\n",
    "            with gr.Group():\n",
    "                progress_log_text = gr.Text(label=\"Output\")\n",
    "            with gr.Group():\n",
    "                export_output_button = gr.Button(\"Export\")\n",
    "                output_csv_file = gr.File(interactive=False, visible=False)\n",
    "        with gr.Column():\n",
    "            with gr.Group():\n",
    "                show_polygons_button = gr.Button(value=\"\", visible=False)\n",
    "                output_image = gr.Plot(value=GradioParameters.fig)\n",
    "            with gr.Group():\n",
    "                apply_changes_to_data_button = gr.Button(value=\"Apply changes to data\")\n",
    "                members_dataframe = gr.DataFrame(label=\"Members data\",\n",
    "                                                show_label=True,\n",
    "                                                value=GradioParameters.df_org.reset_index(),\n",
    "                                                interactive=True,\n",
    "                                                height=300)\n",
    "            with gr.Group():\n",
    "                preprocessed_dataframe = gr.DataFrame(label=\"Preprocessed data\",\n",
    "                                                show_label=True,\n",
    "                                                value=GradioParameters.df_cleaned.reset_index(),\n",
    "                                                interactive=False,\n",
    "                                                height=300)\n",
    "                export_preprocessed_data_button = gr.Button(\"Export \\\"Preprocessed data\\\"\")\n",
    "                preprocessed_data_csv_file = gr.File(interactive=False, visible=False)\n",
    "            with gr.Group():\n",
    "                viz2d_dataframe = gr.DataFrame(label=\"Data used for 2D visualization\",\n",
    "                                                show_label=True,\n",
    "                                                value=GradioParameters.df_viz2d.reset_index(),\n",
    "                                                interactive=False,\n",
    "                                                height=300)\n",
    "                export_viz2d_data_button = gr.Button(\"Export \\\"Data used for 2D visualization\\\"\")\n",
    "                viz2d_data_csv_file = gr.File(interactive=False, visible=False)\n",
    "            with gr.Group():\n",
    "                export_patch_weight_data_button = gr.Button(\"Export \\\"Weights for polygons and line segments\\\"\")\n",
    "                patch_weight_data_csv_file = gr.File(interactive=False, visible=False)\n",
    "    upload_button.upload(fn=upload_file,\n",
    "                            inputs=[upload_button, standardization_checkbox],\n",
    "                            outputs=[progress_log_text,\n",
    "                                     members_dataframe, preprocessed_dataframe, viz2d_dataframe,\n",
    "                                     output_image,\n",
    "                                     output_csv_file,\n",
    "                                     preprocessed_data_csv_file,\n",
    "                                     viz2d_data_csv_file,\n",
    "                                     patch_weight_data_csv_file,\n",
    "                                     show_polygons_button])\n",
    "    apply_changes_to_data_button.click(fn=apply_changes_to_data,\n",
    "                                       inputs=[members_dataframe, standardization_checkbox],\n",
    "                                       outputs=[progress_log_text,\n",
    "                                                members_dataframe, preprocessed_dataframe, viz2d_dataframe,\n",
    "                                                output_image,\n",
    "                                                output_csv_file,\n",
    "                                                preprocessed_data_csv_file,\n",
    "                                                patch_weight_data_csv_file,\n",
    "                                                viz2d_data_csv_file,\n",
    "                                                show_polygons_button])\n",
    "    start_button.click(fn=start_grouping,\n",
    "                        inputs=[number_of_divisions, speed_slider,\n",
    "                                m_weight_slider, d_weight_slider,\n",
    "                                method_dropdown, standardization_checkbox,\n",
    "                                cost_type_dropdown,\n",
    "                                global_loop_max_slider, local_loop_max_slider,\n",
    "                                search_stopping_rule_err_slider, search_stopping_rule_rep_slider,\n",
    "                                tensor_size_max_slider, group_size_max_slider, loop_max_multiplier_slider,\n",
    "                                members_dataframe],\n",
    "                        outputs=[progress_log_text,\n",
    "                                 members_dataframe, preprocessed_dataframe, viz2d_dataframe,\n",
    "                                 output_image,\n",
    "                                 output_csv_file,\n",
    "                                 preprocessed_data_csv_file,\n",
    "                                 viz2d_data_csv_file,\n",
    "                                 patch_weight_data_csv_file,\n",
    "                                 show_polygons_button])\n",
    "    export_output_button.click(fn=export_output_csv_file, inputs=[export_output_button], outputs=[output_csv_file])\n",
    "    export_preprocessed_data_button.click(fn=export_preprocessed_data_csv_file, inputs=[export_preprocessed_data_button], outputs=[preprocessed_data_csv_file])\n",
    "    export_viz2d_data_button.click(fn=export_viz2d_data_csv_file, inputs=[export_viz2d_data_button], outputs=[viz2d_data_csv_file])\n",
    "    export_patch_weight_data_button.click(fn=export_patch_weight_data_csv_file, inputs=[export_patch_weight_data_button], outputs=[patch_weight_data_csv_file])\n",
    "    show_polygons_button.click(fn=show_polygons,\n",
    "                                 inputs=[show_polygons_button],\n",
    "                                 outputs=[output_image, show_polygons_button])\n",
    "    \n",
    "demo.css = \"footer {visibility: hidden}\"\n",
    "demo.launch(inbrowser=True, show_api=False, favicon_path=\"favicon.ico\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
